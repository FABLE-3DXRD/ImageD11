{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 13/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook will help you to refine the experimental parameters (such as sample to detector distance etc).\n",
    "\n",
    "We do this by indexing a Z slice of a sample, refining the positions of the grains we find, then refining the parameters using the grain diffraction data\n",
    "\n",
    "This notebook has already been run to generate Fe_refined.par\n",
    "\n",
    "There's no need to run it again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a bug with the current version of ImageD11 in the site-wide Jupyter env.\n",
    "# This has been fixed here: https://github.com/FABLE-3DXRD/ImageD11/commit/4af88b886b1775585e868f2339a0eb975401468f\n",
    "# Until a new release has been made and added to the env, we need to get the latest version of ImageD11 from GitHub\n",
    "# Put it in your home directory\n",
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "username = os.environ.get(\"USER\")\n",
    "\n",
    "id11_code_path = f\"/home/esrf/{username}/Code/ImageD11\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os, glob, pprint\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "import ImageD11.grain\n",
    "import ImageD11.indexing\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms import properties, dataset\n",
    "\n",
    "from ImageD11.blobcorrector import eiger_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NEW DATASETS\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "base_dir = \"/data/visitor/ma5837/id11/20240208\"\n",
    "\n",
    "rawdata_path = os.path.join(base_dir, 'RAW_DATA')\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "processed_data_root_dir = os.path.join(base_dir, 'PROCESSED_DATA')  # USER: modify this to change the destination folder if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"S18\"\n",
    "dataset = \"FF_zeries_1\"\n",
    "\n",
    "# USER: specify path to detector mask\n",
    "\n",
    "mask_path = '/data/id11/inhouse1/ewoks/detectors/files/Frelon2k_C36/mask.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "\n",
    "# USER: specify the path to the parameter file\n",
    "\n",
    "parfile = 'Fe.par'\n",
    "spline_file = '/data/id11/inhouse1/ewoks/detectors/files/Frelon2k_C36/frelon36.spline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset from file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load 3d columnfile from disk\n",
    "\n",
    "cf_3d = ImageD11.columnfile.colfile_from_hdf(ds.col3dfile)\n",
    "\n",
    "cf_3d.parameters.loadparameters(parfile)\n",
    "cf_3d.updateGeometry()\n",
    "\n",
    "\n",
    "if \"index\" not in cf_3d.titles:\n",
    "    cf_3d.addcolumn(np.arange(cf_3d.nrows), \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the 3D peaks (fewer of them) as a cake (two-theta vs eta)\n",
    "# if the parameters in the par file are good, these should look like straight lines\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(cf_3d.ds, cf_3d.eta, s=1)\n",
    "\n",
    "ax.set_xlabel(\"D-star\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_2d) to select only the strongest ones for indexing purposes only!\n",
    "# dsmax is being set to limit rings given to the indexer\n",
    "# because we have so many 3d peaks, we will filter down to 3 rings\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until we have around 10,000 peaks for indexing\n",
    "# we may choose more for the full index in the next notebook, but for now we want to quickly index only our strong grains\n",
    "\n",
    "cf_strong = utils.selectpeaks(cf_3d, frac=0.35, dsmax=0.92, doplot=0.05, dstol=0.01)\n",
    "print(f\"Got {cf_strong.nrows} strong peaks for indexing\")\n",
    "cf_strong.writefile(f'{sample}_{dataset}_3d_peaks_strong.flt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will also export some additional strong peaks across all rings\n",
    "# this will be useful for grain refinement later (using makemap)\n",
    "\n",
    "cf_strong_allrings = utils.selectpeaks(cf_3d, frac=0.50, dsmax=cf_3d.ds.max(), doplot=0.05, dstol=0.01)\n",
    "print(f\"Got {cf_strong_allrings.nrows} strong peaks for makemap\")\n",
    "cf_strong_allrings_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt'\n",
    "cf_strong_allrings.writefile(cf_strong_allrings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can take a look at the intensities of the remaining peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cf_strong.ds, cf_strong.sum_intensity,',')\n",
    "ax.semilogy()\n",
    "\n",
    "ax.set_xlabel(\"D-star\")\n",
    "ax.set_ylabel(\"Intensity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can define a unit cell from our parameters\n",
    "\n",
    "Fe = ImageD11.unitcell.unitcell_from_parameters(cf_strong.parameters)\n",
    "Fe.makerings(cf_strong.ds.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's plot our peaks again, with the rings from the unitcell included, to check our lattice parameters are good\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "skip=1\n",
    "ax.scatter( cf_strong.ds[::skip], cf_strong.eta[::skip], s=0.5)\n",
    "ax.plot( Fe.ringds, [0,]*len(Fe.ringds), '|', ms=90, c='orange')\n",
    "ax.set_xlabel('1 / d ($\\AA$)')\n",
    "ax.set_ylabel('$\\\\eta$ (deg)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify our ImageD11 indexer with these peaks\n",
    "\n",
    "indexer = ImageD11.indexing.indexer_from_colfile(cf_strong)\n",
    "\n",
    "print(f\"Indexing {cf_strong.nrows} peaks\")\n",
    "\n",
    "# USER: set a tolerance in d-space (for assigning peaks to powder rings)\n",
    "\n",
    "indexer.ds_tol = 0.05\n",
    "\n",
    "# change the log level so we can see what the ring assigments look like\n",
    "\n",
    "ImageD11.indexing.loglevel = 1\n",
    "\n",
    "# assign peaks to powder rings\n",
    "\n",
    "indexer.assigntorings()\n",
    "\n",
    "# change log level back again\n",
    "\n",
    "ImageD11.indexing.loglevel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we want to index low multiplicity rings\n",
    "# choose max_multiplicity such that we get 2-3 low-multiplicity rings\n",
    "# in this case, we will find orientations on 2 rings (faster for many peaks) and include the third ring for minpeaks calculations\n",
    "\n",
    "max_multiplicity = 13\n",
    "\n",
    "min_counts_on_ring = 0\n",
    "\n",
    "n_peaks_expected = 0\n",
    "rings = []\n",
    "for i, dstar in enumerate(indexer.unitcell.ringds):\n",
    "    multiplicity = len(indexer.unitcell.ringhkls[indexer.unitcell.ringds[i]])\n",
    "    counts_on_this_ring = (indexer.ra == i).sum()\n",
    "    if counts_on_this_ring > min_counts_on_ring:\n",
    "        n_peaks_expected += multiplicity\n",
    "        if multiplicity < max_multiplicity:\n",
    "            rings.append((counts_on_this_ring, multiplicity, i))\n",
    "        \n",
    "rings.sort()\n",
    "\n",
    "print(f\"{n_peaks_expected} peaks expected\")\n",
    "print(f\"Trying these rings (counts, multiplicity, ring number): {rings}\")\n",
    "\n",
    "# USER: specify the HKL tolerances you want to use for indexing\n",
    "# hkl_tols_seq = [0.02, 0.03, 0.04, 0.05, 0.1]   # BEST\n",
    "hkl_tols_seq = [0.01, 0.02, 0.03, 0.04]\n",
    "\n",
    "# USER: specify the fraction of the total expected peaks\n",
    "# fracs = [0.9, 0.75]  # BEST\n",
    "fracs = [0.9, 0.75]\n",
    "\n",
    "# ImageD11.cImageD11.cimaged11_omp_set_num_threads(1)\n",
    "ImageD11.indexing.loglevel=3\n",
    "\n",
    "# indexer.uniqueness = 0.3\n",
    "indexer.cosine_tol = np.cos(np.radians(90.25))\n",
    "\n",
    "# iterate over HKL tolerances\n",
    "for frac in fracs:\n",
    "    for tol in hkl_tols_seq:\n",
    "        indexer.minpks = n_peaks_expected*frac\n",
    "        indexer.hkl_tol = tol\n",
    "        \n",
    "        # iterate over rings\n",
    "        \n",
    "        for i in range(len(rings)):\n",
    "            for j in range(i, len(rings)):\n",
    "                indexer.ring_1 = rings[i][2]\n",
    "                indexer.ring_2 = rings[j][2]\n",
    "    \n",
    "                indexer.find()\n",
    "                indexer.scorethem()                \n",
    "\n",
    "        print(frac, tol, len(indexer.ubis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create grain objects\n",
    "grains = [ImageD11.grain.grain(ubi, translation=np.array([0., 0., 0.])) for ubi in indexer.ubis]\n",
    "\n",
    "# set grain GIDs (useful if we ever delete a grain)\n",
    "for i, g in enumerate(grains):\n",
    "    g.gid = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_ubi_path = f'{sample}_{dataset}_grains.ubi'\n",
    "tmp_map_path = f'{sample}_{dataset}_grains.map'\n",
    "\n",
    "new_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.new'  # flt file containing assignments from makemap\n",
    "unindexed_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.unindexed'  # remaining unassigned peaks from makemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ImageD11.grain.write_grain_file(tmp_ubi_path, grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omegas_sorted = np.sort(ds.omega)[0]\n",
    "omega_slop = np.round(np.diff(omegas_sorted).mean(), 3)\n",
    "\n",
    "makemap_hkl_tol_seq = [0.05, 0.025, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for inc, makemap_tol in enumerate(makemap_hkl_tol_seq):\n",
    "    print(f\"Running makemap {inc+1}/{len(makemap_hkl_tol_seq)}\")\n",
    "    if inc == 0:  # ubi into map\n",
    "        makemap_output = !makemap.py -p {parfile} -u {tmp_ubi_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort\n",
    "    else:  # map into map\n",
    "        makemap_output = !makemap.py -p {parfile} -u {tmp_map_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grains_refined_positions = ImageD11.grain.read_grain_file(tmp_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist([np.mean(g.unitcell[0:3]) for g in grains_refined_positions], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refine_output = !refine_em.py {new_flt_path} {tmp_map_path} {parfile} --omega_slop={omega_slop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# work out how many parameter files are missing\n",
    "# check the missing .par files, and copy to cover the missing files\n",
    "import shutil\n",
    "print(f'Total number of files expected = {len(grains_refined_positions)}')\n",
    "\n",
    "for i in range(len(grains_refined_positions)):\n",
    "    filename =  f\"{i}.par\"\n",
    "    if not (os.path.isfile(filename)):\n",
    "        print(f'Missing {filename}')\n",
    "        print(f'Copying {i-1}.par to {filename}')\n",
    "        shutil.copy(str(i-1) + '.par', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refined_parfile = 'Fe_refined.par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_par_output = !avg_par.py {refined_parfile} {len(grains_refined_positions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up temporary files\n",
    "for i in range(len(grains_refined_positions)):\n",
    "    pfile = str(i) + '.par'\n",
    "    ffile = str(i) + '.flt'\n",
    "    ufile = str(i) + '.ubi'\n",
    "    for filename in [pfile, ffile, ufile]:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined parameter file has now been created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "xx = [grain.translation[0] for grain in grains2]\n",
    "yy = [grain.translation[1] for grain in grains2]\n",
    "zz = [grain.translation[2] for grain in grains2]\n",
    "# col = [utils.grain_to_rgb(grain) for grain in grains2]\n",
    "col = [float(grain.npks) for grain in grains2]\n",
    "sizes = [0.01*(float(grain.intensity_info.split(\"mean = \")[1].split(\" , \")[0].replace(\"'\", \"\"))) for grain in grains2]\n",
    "scatterplot = ax.scatter(xx-np.mean(xx), yy-np.mean(yy), zz, c=col, s=sizes)\n",
    "ax.set_xlim(-200,200)\n",
    "ax.set_ylim(-200,200)\n",
    "ax.set_zlim(-200,200)\n",
    "plt.colorbar(scatterplot)\n",
    "ax.set_title(\"Grains coloured by n peaks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
