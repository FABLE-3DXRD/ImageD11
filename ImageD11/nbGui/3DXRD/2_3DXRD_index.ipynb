{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 27/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have good experimental parameters, we can index more grains!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "home_dir = !echo $HOME\n",
    "home_dir = str(home_dir[0])\n",
    "\n",
    "# USER: You can change this location if you want\n",
    "\n",
    "id11_code_path = os.path.join(home_dir, \"Code/ImageD11\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os, glob, pprint\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import utils\n",
    "from ImageD11.nbGui import nb_utils as utils\n",
    "\n",
    "import ImageD11.grain\n",
    "import ImageD11.indexing\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms import properties, dataset\n",
    "\n",
    "from ImageD11.blobcorrector import eiger_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = {'compression':'gzip',\n",
    "       'compression_opts': 2,\n",
    "       'shuffle' : True }\n",
    "\n",
    "def save_array(grp, name, ary):\n",
    "    hds = grp.require_dataset(name, \n",
    "                              shape=ary.shape,\n",
    "                              dtype=ary.dtype,\n",
    "                              **cmp)\n",
    "    hds[:] = ary\n",
    "    return hds\n",
    "\n",
    "def save_grains(grains, ds):\n",
    "    with h5py.File(ds.grainsfile, 'w') as hout:\n",
    "        grn = hout.create_group('grains')\n",
    "        for g in tqdm(grains):\n",
    "            gg = grn.create_group(str(g.gid))\n",
    "            save_array(gg, 'peaks_3d_indexing', g.peaks_3d).attrs['description'] = \"Strong 3D peaks that were assigned to this grain during indexing\"\n",
    "            gg.attrs.update({'ubi':g.ubi,\n",
    "                            'translation':g.translation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/RAW_DATA\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240226\"  # USER: modify this to change the destination folder if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR\"\n",
    "dataset = \"ff1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "\n",
    "# USER: specify the path to the parameter file\n",
    "\n",
    "parfile = '/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240226/Fe_tdxrd_refined.par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset from file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load 3d columnfile from disk\n",
    "\n",
    "cf_3d = ImageD11.columnfile.colfile_from_hdf(ds.col3dfile)\n",
    "\n",
    "cf_3d.parameters.loadparameters(parfile)\n",
    "cf_3d.updateGeometry()\n",
    "\n",
    "if \"index\" not in cf_3d.titles:\n",
    "    cf_3d.addcolumn(np.arange(cf_3d.nrows), \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the 3D peaks (fewer of them) as a cake (two-theta vs eta)\n",
    "# if the parameters in the par file are good, these should look like straight lines\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(cf_3d.ds, cf_3d.eta, s=1)\n",
    "\n",
    "ax.set_xlabel(\"D-star\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_3d) to select only the strongest ones for indexing purposes only!\n",
    "# dsmax is being set to limit rings given to the indexer - 6-8 rings is normally good\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until the orange dot sits nicely on the \"elbow\" of the blue line\n",
    "# this indicates the fractional intensity cutoff we will select\n",
    "# if the blue line does not look elbow-shaped in the logscale plot, try changing the \"doplot\" parameter (the y scale of the logscale plot) until it does\n",
    "\n",
    "cf_strong = utils.selectpeaks(cf_3d, frac=0.9837, dsmax=0.92, doplot=0.8, dstol=0.01)\n",
    "print(f\"Got {cf_strong.nrows} strong peaks for indexing\")\n",
    "cf_strong.writefile(f'{sample}_{dataset}_3d_peaks_strong.flt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will also export some additional strong peaks across all rings\n",
    "# this will be useful for grain refinement later (using makemap)\n",
    "\n",
    "cf_strong_allrings = utils.selectpeaks(cf_3d, frac=0.95, dsmax=cf_3d.ds.max(), doplot=0.8, dstol=0.01)\n",
    "print(f\"Got {cf_strong_allrings.nrows} strong peaks for makemap\")\n",
    "cf_strong_allrings_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt'\n",
    "cf_strong_allrings.writefile(cf_strong_allrings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can take a look at the intensities of the remaining peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cf_strong.ds, cf_strong.sum_intensity,',')\n",
    "ax.semilogy()\n",
    "\n",
    "ax.set_xlabel(\"D-star\")\n",
    "ax.set_ylabel(\"Intensity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can define a unit cell from our parameters\n",
    "\n",
    "Fe = ImageD11.unitcell.unitcell_from_parameters(cf_strong.parameters)\n",
    "Fe.makerings(cf_strong.ds.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's plot our peaks again, with the rings from the unitcell included, to check our lattice parameters are good\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "skip=1\n",
    "ax.scatter( cf_strong.ds[::skip], cf_strong.eta[::skip], s=0.5)\n",
    "ax.plot( Fe.ringds, [0,]*len(Fe.ringds), '|', ms=90, c='orange')\n",
    "ax.set_xlabel('1 / d ($\\AA$)')\n",
    "ax.set_ylabel('$\\\\eta$ (deg)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify our ImageD11 indexer with these peaks\n",
    "\n",
    "indexer = ImageD11.indexing.indexer_from_colfile(cf_strong)\n",
    "\n",
    "print(f\"Indexing {cf_strong.nrows} peaks\")\n",
    "\n",
    "# USER: set a tolerance in d-space (for assigning peaks to powder rings)\n",
    "\n",
    "indexer.ds_tol = 0.05\n",
    "\n",
    "# change the log level so we can see what the ring assigments look like\n",
    "\n",
    "ImageD11.indexing.loglevel = 1\n",
    "\n",
    "# assign peaks to powder rings\n",
    "\n",
    "indexer.assigntorings()\n",
    "\n",
    "# change log level back again\n",
    "\n",
    "ImageD11.indexing.loglevel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we are indexing!\n",
    "# indexing will select all rings with a multiplicity below max_multiplity to search\n",
    "max_multiplicity = 13\n",
    "# the minimum number of peaks on a ring for a ring to be indexed on\n",
    "min_counts_on_ring = 0\n",
    "# the sequence of hkl tolerances the indexer will iterate through\n",
    "hkl_tols_seq = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "# the sequence of minpks fractions the indexer will iterate through\n",
    "fracs = [0.9, 0.75]\n",
    "# the tolerance in g-vector angle\n",
    "cosine_tol = np.cos(np.radians(90 - 0.25))\n",
    "# the max number of UBIs we can find per pair of rings\n",
    "max_grains = 1000\n",
    "\n",
    "grains, indexer = utils.do_index(cf=cf_strong,\n",
    "                                dstol=indexer.ds_tol,\n",
    "                                max_mult=max_multiplicity,\n",
    "                                min_ring_count=min_counts_on_ring,\n",
    "                                hkl_tols=hkl_tols_seq,\n",
    "                                fracs=fracs,\n",
    "                                cosine_tol=cosine_tol,\n",
    "                                max_grains=max_grains\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create grain objects\n",
    "grains = [ImageD11.grain.grain(ubi, translation=np.array([0., 0., 0.])) for ubi in indexer.ubis]\n",
    "\n",
    "# set grain GIDs (useful if we ever delete a grain)\n",
    "for i, g in enumerate(grains):\n",
    "    g.gid = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pole figures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_ubi_path = f'{sample}_{dataset}_grains.ubi'\n",
    "tmp_map_path = f'{sample}_{dataset}_grains.map'\n",
    "\n",
    "new_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.new'  # flt file containing assignments from makemap\n",
    "unindexed_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.unindexed'  # remaining unassigned peaks from makemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ImageD11.grain.write_grain_file(tmp_ubi_path, grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omegas_sorted = np.sort(ds.omega)[0]\n",
    "omega_slop = np.round(np.diff(omegas_sorted).mean(), 3)\n",
    "\n",
    "makemap_hkl_tol_seq = [0.05, 0.025, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for inc, makemap_tol in enumerate(makemap_hkl_tol_seq):\n",
    "    print(f\"Running makemap {inc+1}/{len(makemap_hkl_tol_seq)}\")\n",
    "    if inc == 0:  # ubi into map\n",
    "        makemap_output = !makemap.py -p {parfile} -u {tmp_ubi_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort\n",
    "    else:  # map into map\n",
    "        makemap_output = !makemap.py -p {parfile} -u {tmp_map_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-import our refined grains from the makemap procedure\n",
    "\n",
    "grains2 = ImageD11.grain.read_grain_file(tmp_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove grains with no peaks\n",
    "\n",
    "grains2 = [grain for grain in grains2 if \"no peaks\" not in grain.intensity_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centre_plot = False\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "xx = [grain.translation[0] for grain in grains2]\n",
    "yy = [grain.translation[1] for grain in grains2]\n",
    "zz = [grain.translation[2] for grain in grains2]\n",
    "# col = [utils.grain_to_rgb(grain) for grain in grains2]  # IPF-Z colour instead\n",
    "col = [float(grain.npks) for grain in grains2]\n",
    "sizes = [0.01*(float(grain.intensity_info.split(\"mean = \")[1].split(\" , \")[0].replace(\"'\", \"\"))) for grain in grains2]\n",
    "if centre_plot:\n",
    "    scatterplot = ax.scatter(xx-np.mean(xx), yy-np.mean(yy), zz, c=col, s=sizes)\n",
    "else:\n",
    "    scatterplot = ax.scatter(xx, yy, zz, c=col, s=sizes)\n",
    "ax.set_xlim(-200,200)\n",
    "ax.set_ylim(-200,200)\n",
    "ax.set_zlim(-200,200)\n",
    "plt.colorbar(scatterplot)\n",
    "ax.set_title(\"Grains coloured by n peaks\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist([float(grain.npks) for grain in grains2], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find the spike\n",
    "absolute_minpks = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter out grains with fewer than 15 peaks\n",
    "grains_filtered = [grain for grain in grains2 if float(grain.npks) > absolute_minpks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centre_plot = False\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "xx = [grain.translation[0] for grain in grains_filtered]\n",
    "yy = [grain.translation[1] for grain in grains_filtered]\n",
    "zz = [grain.translation[2] for grain in grains_filtered]\n",
    "# col = [utils.grain_to_rgb(grain) for grain in grains_filtered]  # IPF-Z colour instead\n",
    "col = [float(grain.npks) for grain in grains_filtered]\n",
    "sizes = [0.01*(float(grain.intensity_info.split(\"mean = \")[1].split(\" , \")[0].replace(\"'\", \"\"))) for grain in grains_filtered]\n",
    "if centre_plot:\n",
    "    scatterplot = ax.scatter(xx-np.mean(xx), yy-np.mean(yy), zz, c=col, s=sizes)\n",
    "else:\n",
    "    scatterplot = ax.scatter(xx, yy, zz, c=col, s=sizes)\n",
    "ax.set_xlim(-200,200)\n",
    "ax.set_ylim(-200,200)\n",
    "ax.set_zlim(-200,200)\n",
    "plt.colorbar(scatterplot)\n",
    "ax.set_title(\"Grains coloured by n peaks\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for grain in grains_filtered:\n",
    "    grain.gid = int(grain.name.split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will assign all our 3D peaks to our grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tol = 0.05\n",
    "\n",
    "utils.assign_peaks_to_grains(grains_filtered, cf_3d, tol)\n",
    "\n",
    "print(\"Storing peak data in grains\")\n",
    "# iterate through all the grains\n",
    "for g in tqdm(grains_filtered):\n",
    "    # store this grain's peak indices so we know which 3D peaks we used for indexing\n",
    "    g.peaks_3d = cf_3d.index[cf_3d.grain_id == g.gid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist([np.mean(grain.unitcell[0:3]) for grain in grains_filtered], bins=25)\n",
    "plt.show()\n",
    "\n",
    "print(np.mean([np.mean(grain.unitcell[0:3]) for grain in grains_filtered]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save grain data\n",
    "\n",
    "save_grains(grains_filtered, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up\n",
    "\n",
    "if os.path.exists(cf_strong_allrings_path):\n",
    "    os.remove(cf_strong_allrings_path)\n",
    "\n",
    "if os.path.exists(tmp_ubi_path):\n",
    "    os.remove(tmp_ubi_path)\n",
    "\n",
    "if os.path.exists(tmp_map_path):\n",
    "    os.remove(tmp_map_path)\n",
    "\n",
    "if os.path.exists(new_flt_path):\n",
    "    os.remove(new_flt_path)\n",
    "\n",
    "if os.path.exists(unindexed_flt_path):\n",
    "    os.remove(unindexed_flt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to 0 to allow all cells to be run automatically\n",
    "if 1:\n",
    "    raise ValueError(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR\": []\n",
    "}\n",
    "\n",
    "dset_prefix = \"ff\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "\n",
    "parfile = '/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240226/Fe_tdxrd_refined.par'\n",
    "\n",
    "cf_strong_frac = 0.95\n",
    "cf_strong_dsmax = 0.92\n",
    "cf_strong_dstol = 0.01\n",
    "\n",
    "cf_strong_allrings_frac = 0.95\n",
    "cf_strong_allrings_dstol = 0.01\n",
    "\n",
    "indexer_dstol = 0.05\n",
    "indexer_max_mult = 13\n",
    "indexer_hkl_tols = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "indexer_fracs = [0.9, 0.75]\n",
    "indexer_cosine_tol = np.cos(np.radians(90 - 0.25))\n",
    "indexer_max_grains = 1000\n",
    "indexer_min_ring_count = 0\n",
    "\n",
    "makemap_hkl_tol_seq = [0.05, 0.025, 0.01]\n",
    "makemap_import_minpks = 25\n",
    "\n",
    "peak_assignment_hkl_tol = 0.05\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        print(\"Importing DataSet object\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if os.path.exists(ds.grainsfile):\n",
    "            print(f\"Found existing grains file for {dataset} in {sample}, skipping\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        print(\"Loading 3D peaks\")\n",
    "        cf_3d = ImageD11.columnfile.colfile_from_hdf(ds.col3dfile)\n",
    "        cf_3d.parameters.loadparameters(parfile)\n",
    "        cf_3d.updateGeometry()\n",
    "        if \"index\" not in cf_3d.titles:\n",
    "            cf_3d.addcolumn(np.arange(cf_3d.nrows), \"index\")\n",
    "\n",
    "        print(\"Filtering 3D peaks\")\n",
    "        cf_strong = utils.selectpeaks(cf_3d, frac=cf_strong_frac, dsmax=cf_strong_dsmax, doplot=None, dstol=cf_strong_dstol)\n",
    "        print(f\"Got {cf_strong.nrows} strong peaks for indexing\")\n",
    "        cf_strong_path = f'{sample}_{dataset}_3d_peaks_strong.flt'\n",
    "        cf_strong.writefile(cf_strong_path)\n",
    "\n",
    "        cf_strong_allrings = utils.selectpeaks(cf_3d, frac=cf_strong_allrings_frac, dsmax=cf_3d.ds.max(), doplot=None, dstol=cf_strong_allrings_dstol)\n",
    "        print(f\"Got {cf_strong_allrings.nrows} strong peaks for makemap\")\n",
    "        cf_strong_allrings_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt'\n",
    "        cf_strong_allrings.writefile(cf_strong_allrings_path)\n",
    "        \n",
    "        grains, indexer = utils.do_index(cf=cf_strong,\n",
    "                                dstol=indexer_dstol,\n",
    "                                max_mult=indexer_max_mult,\n",
    "                                min_ring_count=indexer_min_ring_count,\n",
    "                                hkl_tols=indexer_hkl_tols,\n",
    "                                fracs=indexer_fracs,\n",
    "                                cosine_tol=indexer_cosine_tol,\n",
    "                                max_grains=indexer_max_grains\n",
    "                                )\n",
    "\n",
    "        grains = [ImageD11.grain.grain(ubi, translation=np.array([0., 0., 0.])) for ubi in indexer.ubis]\n",
    "\n",
    "        for i, g in enumerate(grains):\n",
    "            g.gid = i\n",
    "\n",
    "        tmp_ubi_path = f'{sample}_{dataset}_grains.ubi'\n",
    "        tmp_map_path = f'{sample}_{dataset}_grains.map'\n",
    "\n",
    "        new_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.new'  # flt file containing assignments from makemap\n",
    "        unindexed_flt_path = f'{sample}_{dataset}_3d_peaks_strong_all_rings.flt.unindexed'  # remaining unassigned peaks from makemap\n",
    "\n",
    "        ImageD11.grain.write_grain_file(tmp_ubi_path, grains)\n",
    "\n",
    "        omegas_sorted = np.sort(ds.omega)[0]\n",
    "        omega_slop = np.round(np.diff(omegas_sorted).mean(), 3)\n",
    "\n",
    "        makemap_hkl_tol_seq = makemap_hkl_tol_seq\n",
    "\n",
    "        for inc, makemap_tol in enumerate(makemap_hkl_tol_seq):\n",
    "            print(f\"Running makemap {inc+1}/{len(makemap_hkl_tol_seq)}\")\n",
    "            if inc == 0:  # ubi into map\n",
    "                makemap_output = !makemap.py -p {parfile} -u {tmp_ubi_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort\n",
    "            else:  # map into map\n",
    "                makemap_output = !makemap.py -p {parfile} -u {tmp_map_path} -U {tmp_map_path} -f {cf_strong_allrings_path} -F {unindexed_flt_path} -s cubic -t {makemap_hkl_tol_seq[inc]} --omega_slop={omega_slop} --no_sort\n",
    "\n",
    "        grains2 = ImageD11.grain.read_grain_file(tmp_map_path)\n",
    "        \n",
    "        # remove grains with no peaks\n",
    "        grains2 = [grain for grain in grains2 if \"no peaks\" not in grain.intensity_info]\n",
    "        \n",
    "        absolute_minpks = makemap_import_minpks\n",
    "        grains_filtered = [grain for grain in grains2 if float(grain.npks) > absolute_minpks]\n",
    "\n",
    "        for grain in grains_filtered:\n",
    "            grain.gid = int(grain.name.split(\":\")[0])\n",
    "\n",
    "        tol = peak_assignment_hkl_tol\n",
    "\n",
    "        utils.assign_peaks_to_grains(grains_filtered, cf_3d, tol)\n",
    "\n",
    "        print(\"Storing peak data in grains\")\n",
    "        # iterate through all the grains\n",
    "        for g in tqdm(grains_filtered):\n",
    "            # store this grain's peak indices so we know which 3D peaks we used for indexing\n",
    "            g.peaks_3d = cf_3d.index[cf_3d.grain_id == g.gid]\n",
    "\n",
    "        print(\"Saving grains\")\n",
    "        save_grains(grains_filtered, ds)\n",
    "\n",
    "        if os.path.exists(cf_strong_path):\n",
    "            os.remove(cf_strong_path)\n",
    "\n",
    "        if os.path.exists(cf_strong_allrings_path):\n",
    "            os.remove(cf_strong_allrings_path)\n",
    "\n",
    "        if os.path.exists(tmp_ubi_path):\n",
    "            os.remove(tmp_ubi_path)\n",
    "\n",
    "        if os.path.exists(tmp_map_path):\n",
    "            os.remove(tmp_map_path)\n",
    "\n",
    "        if os.path.exists(new_flt_path):\n",
    "            os.remove(new_flt_path)\n",
    "\n",
    "        if os.path.exists(unindexed_flt_path):\n",
    "            os.remove(unindexed_flt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
