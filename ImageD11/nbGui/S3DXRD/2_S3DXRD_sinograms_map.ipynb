{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 28/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ImageD11.columnfile\n",
    "import ImageD11.sinograms.dataset\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11.peakselect import select_ring_peaks_by_intensity\n",
    "from ImageD11.sinograms.sinogram import GrainSinogram, build_slice_arrays, write_slice_recon, read_h5, write_h5, get_2d_peaks_from_4d_peaks\n",
    "from ImageD11.sinograms.roi_iradon import run_iradon\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import convex_hull_image\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the sinograms are only half-sinograms (we scanned dty across half the sample rather than the full sample), set the below to true:\n",
    "is_half_scan = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_half_scan:\n",
    "    ds.correct_bins_for_half_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 4D peaks\n",
    "\n",
    "cf_4d = ds.get_cf_4d_from_disk()\n",
    "\n",
    "cf_4d.parameters.loadparameters(ds.parfile)\n",
    "cf_4d.updateGeometry()\n",
    "\n",
    "print(f\"Read {cf_4d.nrows} 4D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_4d) to select only the strongest ones\n",
    "# this time as opposed to indexing, our frac is slightly weaker but we are NOT filtering in dstar!!!!!\n",
    "# this means many more peaks per grain = stronger sinograms\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until the orange dot sits nicely on the \"elbow\" of the blue line\n",
    "# this indicates the fractional intensity cutoff we will select\n",
    "# if the blue line does not look elbow-shaped in the logscale plot, try changing the \"doplot\" parameter (the y scale of the logscale plot) until it does\n",
    "\n",
    "cf_strong_frac = 1\n",
    "cf_strong_dstol = 0.005\n",
    "\n",
    "cf_strong = select_ring_peaks_by_intensity(cf_4d, frac=cf_strong_frac, dstol=cf_strong_dstol, dsmax=cf_4d.ds.max(), doplot=0.9)\n",
    "print(cf_4d.nrows)\n",
    "cf_strong.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the grains from disk\n",
    "\n",
    "grains = ds.get_grains_from_disk()\n",
    "print(f\"{len(grains)} grains imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign peaks to the grains\n",
    "\n",
    "peak_assign_tol = 0.25\n",
    "utils.assign_peaks_to_grains(grains, cf_strong, peak_assign_tol)\n",
    "\n",
    "for grain_label, g in enumerate(grains):\n",
    "    g.npks_4d = np.sum(cf_strong.grain_id == grain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's make a GrainSinogram object for each grain\n",
    "\n",
    "grainsinos = [GrainSinogram(g, ds) for g in grains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's determine the positions of each grain from the 4D peaks\n",
    "\n",
    "for grain_label, gs in enumerate(grainsinos):\n",
    "    gs.update_lab_position_from_peaks(cf_strong, grain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can also determine the RGB IPF colours of the grains which will be useful for plotting\n",
    "# To do this, we first need to set a reference unitcell for each grain\n",
    "# This will be used to determine the Orix Phase and therefore Orix Orientation\n",
    "\n",
    "cf_pars = cf_strong.parameters.get_parameters()\n",
    "spacegroup = 227  # spacegroup for Si\n",
    "cf_pars[\"cell_lattice_[P,A,B,C,I,F,R]\"] = spacegroup\n",
    "\n",
    "ref_ucell = ImageD11.unitcell.unitcell_from_parameters(cf_pars)\n",
    "\n",
    "for g in grains:\n",
    "    g.ref_unitcell = ref_ucell\n",
    "\n",
    "# Now colours should work\n",
    "\n",
    "utils.get_rgbs_for_grains(grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.plot_all_ipfs(grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we can plot our grain positions and RGB colours:\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.translation[0] for g in grains]\n",
    "y = [g.translation[1] for g in grains]\n",
    "s = [g.npks_4d/10 for g in grains]\n",
    "a[0].scatter(y, x, c=[g.rgb_z for g in grains], s=s)\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(y, x, c=[g.rgb_y for g in grains], s=s)\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(y, x, c=[g.rgb_x for g in grains], s=s)\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(y, x, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"<- Lab y (transverse)\")\n",
    "fig.supylabel(\"Lab x (beam) ->\")\n",
    "\n",
    "for a in ax.ravel():\n",
    "    a.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to determine what the value of dty is where the rotation axis intercepts the beam\n",
    "# we'll call this y0\n",
    "# should be the result of the centre-of-mass fit\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sample_y0s = [gs.recon_y0 for gs in grainsinos]\n",
    "\n",
    "ax.plot(sample_y0s)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "y0 = np.median(sample_y0s)\n",
    "\n",
    "print('y0 is', y0)\n",
    "\n",
    "# update the y0 for each grain with the median y0:\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(y0=y0)\n",
    "\n",
    "# the shift we have to apply to the reconstructions is equal to -y0/ystep (in integer coords)\n",
    "\n",
    "shift = -y0/ds.ystep\n",
    "\n",
    "print('shift is', shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's do a whole-sample tomographic reconstruction\n",
    "# generate sinogram for whole sample\n",
    "\n",
    "whole_sample_sino, xedges, yedges = np.histogram2d(cf_4d.dty, cf_4d.omega, bins=[ds.ybinedges, ds.obinedges])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(whole_sample_sino, interpolation=\"nearest\", vmin=0, aspect='auto', norm='log')\n",
    "#ax.set_aspect(4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"quick\" whole-sample reconstruction\n",
    "\n",
    "pad = 0\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "whole_sample_recon = run_iradon(whole_sample_sino, ds.obincens, pad, shift, workers=nthreads, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# without a mask, MLEM can introduce artifacts in the corners\n",
    "# so we can manually mask those out\n",
    "\n",
    "# we can incoporate our own mask too\n",
    "# by modifying the below function\n",
    "\n",
    "def apply_manual_mask(mask_in):\n",
    "    mask_out = mask_in.copy()\n",
    "    \n",
    "    # mask_out[200:, 250:] = 0\n",
    "    \n",
    "    return mask_out\n",
    "\n",
    "# we should be able to easily segment this using scikit-image\n",
    "recon_man_mask = apply_manual_mask(whole_sample_recon)\n",
    "\n",
    "# we can also override the threshold if we don't like it:\n",
    "# manual_threshold = 0.006\n",
    "manual_threshold = None\n",
    "\n",
    "if manual_threshold is None:\n",
    "    thresh = threshold_otsu(recon_man_mask)\n",
    "else:\n",
    "    thresh = manual_threshold\n",
    "\n",
    "binary = recon_man_mask > thresh\n",
    "\n",
    "chull = convex_hull_image(binary)\n",
    "\n",
    "whole_sample_mask = chull\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0].imshow(recon_man_mask, vmin=0, origin=\"lower\")\n",
    "axs[1].imshow(binary, origin=\"lower\")\n",
    "axs[2].imshow(chull, origin=\"lower\")\n",
    "\n",
    "axs[0].set_title(\"Reconstruction\")\n",
    "axs[1].set_title(\"Binarised threshold\")\n",
    "axs[2].set_title(\"Convex hull\")\n",
    "\n",
    "fig.supxlabel(\"<-- Y axis\")\n",
    "fig.supylabel(\"Beam >\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we have a whole-sample reconstruction we can use as a sample mask\n",
    "# let's build the sinograms for our grains\n",
    "# before we do this, we need to determine our 2D peaks that will be used for the sinogram\n",
    "# here we can get them from the 4D peaks:\n",
    "\n",
    "hkltol = 0.25\n",
    "\n",
    "gord, inds = get_2d_peaks_from_4d_peaks(ds.pk2d, cf_strong)\n",
    "\n",
    "for grain_label, gs in enumerate(tqdm(grainsinos)):\n",
    "    gs.prepare_peaks_from_4d(cf_strong, gord, inds, grain_label, hkltol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can actually generate the sinograms\n",
    "\n",
    "for gs in tqdm(grainsinos):\n",
    "    gs.build_sinogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally correct the halfmask:\n",
    "\n",
    "if is_half_scan:\n",
    "    for gs in grainsinos:\n",
    "        gs.correct_halfmask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(gs.ssino, aspect='auto')\n",
    "ax.set_title(\"ssino\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can optionally correct each row of the sinogram by the ring current of that rotation\n",
    "# This helps remove artifacts in the reconstruction\n",
    "\n",
    "correct_sinos_with_ring_current = True\n",
    "if correct_sinos_with_ring_current:\n",
    "    ds.get_ring_current_per_scan()\n",
    "    \n",
    "    for gs in grainsinos:\n",
    "        gs.correct_ring_current(is_half_scan=is_half_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(gs.ssino, aspect='auto')\n",
    "ax.set_title(\"ssino\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's try out an iradon reconstruction\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "# update the parameters used for the iradon reconstruction\n",
    "\n",
    "gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, y0=y0)\n",
    "\n",
    "# perform the reconstruction\n",
    "\n",
    "gs.recon()\n",
    "\n",
    "if is_half_scan:\n",
    "    halfmask_radius = 25\n",
    "    gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)\n",
    "\n",
    "# view the result\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].imshow(gs.ssino, aspect='auto')\n",
    "axs[0].set_title(\"ssino\")\n",
    "axs[1].imshow(gs.recons[\"iradon\"], vmin=0, origin=\"lower\")\n",
    "axs[1].set_title(\"ID11 iradon\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# once you're happy with the reconstruction parameters used, set them for all the grains\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, y0=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reconstruct all grains in parallel\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1,nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(GrainSinogram.recon, grainsinos), total=len(grainsinos)):\n",
    "        pass\n",
    "\n",
    "if is_half_scan:\n",
    "    for gs in grainsinos:\n",
    "        gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# once you're happy with the reconstruction parameters used, set them for all the grains\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, y0=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(1,2,figsize=(10,5))\n",
    "rec = a[0].imshow(grainsinos[0].recons[\"iradon\"], vmin=0, origin=\"lower\")\n",
    "sin = a[1].imshow(grainsinos[0].ssino, aspect='auto')\n",
    "\n",
    "# Function to update the displayed image based on the selected frame\n",
    "def update_frame(i):\n",
    "    rec.set_array(grainsinos[i].recons[\"iradon\"])\n",
    "    sin.set_array(grainsinos[i].ssino)\n",
    "    a[0].set(title=str(i))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# Create a slider widget to select the frame number\n",
    "frame_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(grains) - 1,\n",
    "    step=1,\n",
    "    description='Grain:'\n",
    ")\n",
    "\n",
    "interact(update_frame, i=frame_slider)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's assemble all the recons into one map\n",
    "\n",
    "rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = build_slice_arrays(grainsinos, cutoff_level=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot initial output\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(rgb_z_array, origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(grain_labels_array, origin=\"lower\")  # originally 1,2,0\n",
    "ax.set_title(\"Grain label map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(raw_intensity_array, origin=\"lower\")\n",
    "ax.set_title(\"Raw intensity array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can clean up these reconstructions using an MLEM iterative recon\n",
    "# we will carry this out using ASTRA on the GPU on the cluster\n",
    "# the ASTRA EM_CUDA method will be used\n",
    "# note that the mask will not be applied - normally not needed for ASTRA EM_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose the number of iterations\n",
    "# experience shows 500 is good, and pretty quick on the GPU\n",
    "\n",
    "niter = 500\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, niter=niter, y0=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the GrainSinogram objects to disk\n",
    "\n",
    "write_h5(ds.grainsfile, grainsinos, write_grains_too=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare ASTRA bash scripts to run it on the cluster\n",
    "\n",
    "bash_script_path = utils.prepare_astra_bash(ds, ds.grainsfile, PYTHONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submit ASTRA jobs to cluster\n",
    "\n",
    "utils.slurm_submit_and_wait(bash_script_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-import our reconstructed grains\n",
    "\n",
    "grainsinos = read_h5(ds.grainsfile, ds)\n",
    "# re-associate grainsino grain objects to existing grain objects\n",
    "\n",
    "for gs, g in zip(grainsinos, grains):\n",
    "    gs.grain = g\n",
    "    gs.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at all our ASTRA recons in a grid\n",
    "\n",
    "n_grains_to_plot = 25\n",
    "\n",
    "grains_step = len(grainsinos)//n_grains_to_plot\n",
    "\n",
    "grid_size = np.ceil(np.sqrt(len(grainsinos[::grains_step]))).astype(int)\n",
    "nrows = (len(grainsinos[::grains_step])+grid_size-1)//grid_size\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, nrows, figsize=(10,10), layout=\"constrained\", sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    if i < len(grainsinos[::grains_step]):\n",
    "    # get corresponding grain for this axis\n",
    "        gs = grainsinos[::grains_step][i]\n",
    "        ax.imshow(gs.recons[\"astra\"], vmin=0, origin=\"lower\")\n",
    "        # ax.invert_yaxis()\n",
    "        ax.set_title(i)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_level = 0.05\n",
    "\n",
    "slice_arrays = build_slice_arrays(grainsinos, cutoff_level=cutoff_level, method=\"astra\")\n",
    "rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = slice_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(rgb_z_array, origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(raw_intensity_array, origin=\"lower\")\n",
    "ax.set_title(\"Sinogram raw intensity map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(grain_labels_array, origin=\"lower\")\n",
    "ax.set_title(\"Grain label map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write our results to disk\n",
    "\n",
    "write_h5(ds.grainsfile, grainsinos, write_grains_too=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the slice maps to disk too\n",
    "\n",
    "write_slice_recon(ds.grainsfile, slice_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if not os.path.exists(ds.grainsfile):\n",
    "            print(f\"Missing grains file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        # check grains file for existance of slice_recon, skip if it's there\n",
    "        with h5py.File(ds.grainsfile, \"r\") as hin:\n",
    "            if \"slice_recon\" in hin.keys():\n",
    "                print(f\"Already reconstructed {dataset} in {sample}, skipping\")\n",
    "                continue\n",
    "                \n",
    "        if is_half_scan:\n",
    "            ds.correct_bins_for_half_scan()\n",
    "        \n",
    "        print(\"Peaks\")\n",
    "        cf_4d = ds.get_cf_4d_from_disk()\n",
    "        cf_4d.parameters.loadparameters(ds.parfile)\n",
    "        cf_4d.updateGeometry()\n",
    "        \n",
    "        cf_strong = select_ring_peaks_by_intensity(cf_4d, frac=cf_strong_frac, dstol=cf_strong_dstol, dsmax=cf_4d.ds.max())\n",
    "        \n",
    "        print(\"Grains\")\n",
    "        grains = ds.get_grains_from_disk()\n",
    "        utils.assign_peaks_to_grains(grains, cf_strong, peak_assign_tol)\n",
    "        \n",
    "        grainsinos = [GrainSinogram(g, ds) for g in grains]\n",
    "        \n",
    "        print(\"Fitting grain positions\")\n",
    "        for grain_label, gs in enumerate(grainsinos):\n",
    "            gs.update_lab_position_from_peaks(cf_strong, grain_label)\n",
    "        \n",
    "        sample_y0s = [gs.recon_y0 for gs in grainsinos]\n",
    "        y0 = np.median(sample_y0s)\n",
    "        shift = -y0/ds.ystep\n",
    "        \n",
    "        cf_pars = cf_strong.parameters.get_parameters()\n",
    "        cf_pars[\"cell_lattice_[P,A,B,C,I,F,R]\"] = spacegroup\n",
    "        ref_ucell = ImageD11.unitcell.unitcell_from_parameters(cf_pars)\n",
    "\n",
    "        for g in grains:\n",
    "            g.ref_unitcell = ref_ucell\n",
    "        \n",
    "        print(\"Determining RGB colours\")\n",
    "        utils.get_rgbs_for_grains(grains)\n",
    "        \n",
    "        print(\"Whole sample mask recon\")\n",
    "        whole_sample_sino, xedges, yedges = np.histogram2d(cf_4d.dty, cf_4d.omega, bins=[ds.ybinedges, ds.obinedges])\n",
    "        whole_sample_recon = run_iradon(whole_sample_sino, ds.obincens, pad, shift, workers=nthreads, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)\n",
    "        \n",
    "        recon_man_mask = apply_manual_mask(whole_sample_recon)\n",
    "        \n",
    "        if manual_threshold is None:\n",
    "            thresh = threshold_otsu(recon_man_mask)\n",
    "        else:\n",
    "            thresh = manual_threshold\n",
    "            \n",
    "        binary = recon_man_mask > thresh\n",
    "        whole_sample_mask = convex_hull_image(binary)\n",
    "        \n",
    "        gord, inds = get_2d_peaks_from_4d_peaks(ds.pk2d, cf_strong)\n",
    "        \n",
    "        print(\"Building sinograms\")\n",
    "        for grain_label, gs in enumerate(tqdm(grainsinos)):\n",
    "            gs.prepare_peaks_from_4d(cf_strong, gord, inds, grain_label, hkltol)\n",
    "            gs.build_sinogram()\n",
    "            \n",
    "            if is_half_scan:\n",
    "                gs.correct_halfmask()\n",
    "            \n",
    "        if correct_sinos_with_ring_current:\n",
    "            print(\"Correcting for ring current\")\n",
    "            ds.get_ring_current_per_scan()\n",
    "            for gs in grainsinos:\n",
    "                gs.correct_ring_current(is_half_scan=is_half_scan)\n",
    "        \n",
    "        for gs in grainsinos:\n",
    "            gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, niter=niter, y0=y0)\n",
    "        \n",
    "        print(\"Running iradon\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max(1,nthreads-1)) as pool:\n",
    "            for i in tqdm(pool.map(GrainSinogram.recon, grainsinos), total=len(grainsinos)):\n",
    "                pass\n",
    "        \n",
    "        if is_half_scan:\n",
    "            for gs in grainsinos:\n",
    "                gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)\n",
    "        \n",
    "        print(\"Preparing SLURM ASTRA\")\n",
    "        write_h5(ds.grainsfile, grainsinos, write_grains_too=True)\n",
    "        bash_script_path = utils.prepare_astra_bash(ds, ds.grainsfile, PYTHONPATH) \n",
    "        utils.slurm_submit_and_wait(bash_script_path, 10)\n",
    "        \n",
    "        print(\"Loading ASTRA results\")\n",
    "        grainsinos = read_h5(ds.grainsfile, ds)\n",
    "        \n",
    "        for gs, g in zip(grainsinos, grains):\n",
    "            gs.grain = g\n",
    "            gs.ds = ds\n",
    "        \n",
    "        if is_half_scan:\n",
    "            for gs in grainsinos:\n",
    "                gs.mask_central_zingers(\"astra\", radius=halfmask_radius)\n",
    "        \n",
    "        print(\"Final save\")\n",
    "        slice_arrays = build_slice_arrays(grainsinos, cutoff_level=cutoff_level, method=\"astra\")\n",
    "        write_h5(ds.grainsfile, grainsinos, write_grains_too=True)\n",
    "        write_slice_recon(ds.grainsfile, slice_arrays)\n",
    "        \n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
