{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 12/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook will try to perform a point-by-point strain refinement of your pbp index results.  \n",
    "As with the pbp index, the results of this process are multi-valued.  \n",
    "You can run 4_visualise to convert the refinement results to an accurate single-valued map.  \n",
    "\n",
    "### NOTE: It is highly recommended to run this notebook on a Jupyter server with many cores and a lot of RAM.  \n",
    "The compute_origins() function in particular runs locally and can be compute-intensive for large datasets.  \n",
    "If this is a big scan (e.g 100 million + 2D peaks), you should definitely refine on the cluster rather than locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import unitcell\n",
    "import ImageD11.sinograms.dataset\n",
    "from ImageD11.sinograms.point_by_point import PBPMap, nb_inv, PBPRefine\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.nbGui import nb_utils as utils\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's select a phase to index from our parameters json\n",
    "phase_str = 'Fe'\n",
    "\n",
    "ref_ucell = ds.phases.unitcells[phase_str]\n",
    "\n",
    "print(ref_ucell.lattice_parameters, ref_ucell.spacegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's load our point-by-point map from disk\n",
    "\n",
    "pmap = PBPMap(ds.pbpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot a histogram of unique peaks per ubi\n",
    "\n",
    "pmap.plot_nuniq_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose the minimum number of peaks you want a pixel to have to be counted\n",
    "\n",
    "min_unique = 20\n",
    "\n",
    "pmap.choose_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's plot the result of your choice\n",
    "\n",
    "pmap.plot_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the 2D peaks from disk\n",
    "\n",
    "cf_2d = ds.get_cf_2d()\n",
    "ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "print(cf_2d.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a refinement manager object\n",
    "\n",
    "y0 = 0.0\n",
    "fpks = 0.95\n",
    "hkl_tol_origins = 0.05\n",
    "hkl_tol_refine = 0.1\n",
    "hkl_tol_refine_merged = 0.05\n",
    "ds_tol = 0.006\n",
    "ifrac = 6e-3\n",
    "\n",
    "refine = PBPRefine(dset=ds, y0=y0, fpks=fpks, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tell it which point-by-point map we are refining\n",
    "\n",
    "refine.setmap(pmap)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose 2D peaks to refine with\n",
    "\n",
    "refine.setpeaks(cf_2d)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadpeaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the peaks you selected\n",
    "\n",
    "refine.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set whole-sample mask to choose where to refine\n",
    "\n",
    "manual_threshold = None\n",
    "\n",
    "refine.setmask(manual_threshold=manual_threshold, doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate a single-valued map to refine on\n",
    "\n",
    "refine.setsingle(refine.pbpmap, minpeaks=min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute diffraction origins - these will be added as a column to refine.icolf\n",
    "# will then save the new column to disk to avoid re-computation\n",
    "\n",
    "refine.get_origins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the refinement\n",
    "# if compute_origins took more than a couple of minutes to run, I suggest setting use_cluster=True below\n",
    "# otherwise if you asked for lots of cores and RAM on this Jupyter instance, you can run it locally (use_cluster=False)\n",
    "\n",
    "use_cluster = False\n",
    "\n",
    "refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure refinement is saved to disk\n",
    "\n",
    "refine.to_h5()\n",
    "\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(ds.dataroot, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        if os.path.exists(ds.refoutfile):\n",
    "            print(f\"Already have PBP refinement output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        if not os.path.exists(ds.pbpfile):\n",
    "            print(f\"Can't find PBP indexing file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        cf_2d = ds.get_cf_2d()\n",
    "        ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "        if not os.path.exists(ds.col2dfile):\n",
    "            ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)\n",
    "            \n",
    "        pmap = PBPMap(ds.pbpfile)\n",
    "        pmap.choose_best(min_unique)\n",
    "        \n",
    "        refine = PBPRefine(dset=ds, y0=y0, fpks=fpks, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str)\n",
    "        \n",
    "        refine.setmap(pmap)\n",
    "        refine.setpeaks(cf_2d)\n",
    "        refine.setmask(manual_threshold=manual_threshold, doplot=False)\n",
    "        refine.setsingle(refine.pbpmap, minpeaks=min_unique)\n",
    "        refine.get_origins()\n",
    "        refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)\n",
    "        if not use_cluster:\n",
    "            # wait to complete locally, then save\n",
    "            refine.to_h5()\n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
