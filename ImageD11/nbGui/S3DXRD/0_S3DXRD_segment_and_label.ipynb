{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8deabe5b",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 26/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc9a47-acd9-4174-9aef-a7c27e7534bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NOTE: These notebooks are under active development\n",
    "They require the latest version of ImageD11 from Git to run.\n",
    "\n",
    "If you don't have this set up yet, you can run the below cell.\n",
    "\n",
    "It will automatically download and install ImageD11 to your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3f4e7-08a2-4826-b098-c941a667642e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "home_dir = !echo $HOME\n",
    "home_dir = str(home_dir[0])\n",
    "\n",
    "# USER: You can change this location if you want\n",
    "\n",
    "id11_code_path = os.path.join(home_dir, \"Code/ImageD11\")\n",
    "\n",
    "# check whether we already have ImageD11 here\n",
    "\n",
    "if os.path.exists(id11_code_path):\n",
    "    raise FileExistsError(\"ImageD11 already present! Giving up\")\n",
    "\n",
    "!git clone https://github.com/FABLE-3DXRD/ImageD11 {id11_code_path}\n",
    "output = !cd {id11_code_path} && python setup.py build_ext --inplace\n",
    "\n",
    "if not os.path.exists(os.path.join(id11_code_path, \"build\")):\n",
    "    raise FileNotFoundError(f\"Can't find build folder in {id11_code_path}, compilation went wrong somewhere\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)\n",
    "\n",
    "# if this works, we installed ImageD11 properly!\n",
    "try:\n",
    "    import ImageD11.cImageD11\n",
    "except:\n",
    "    raise FileNotFoundError(\"Couldn't import cImageD11, there's a problem with your Git install!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fcab9-7631-439f-885c-438bcefeac84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "home_dir = !echo $HOME\n",
    "home_dir = str(home_dir[0])\n",
    "\n",
    "# USER: You can change this location if you want\n",
    "\n",
    "id11_code_path = os.path.join(home_dir, \"Code/ImageD11\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c1db6-5a32-4294-abef-cfc2150d24de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import glob, pprint\n",
    "import fabio\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.sinograms.lima_segmenter\n",
    "import ImageD11.sinograms.assemble_label\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import fabio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from skimage import filters, measure, morphology\n",
    "from ipywidgets import interact, interactive, widgets, fixed, Layout\n",
    "import h5py\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e3647-2e1b-4a31-b5de-01adbd4d7573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that we're importing ImageD11 from the home directory rather than from the Jupyter kernel\n",
    "\n",
    "?ImageD11.sinograms.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb520f-cb00-4eeb-b740-fc7b407f1f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: For old datasets before the new directory layout structure, we don't distinguish between RAW_DATA and PROCESSED_DATA\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/RAW_DATA\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "### USER: specify where you want your processed data to go\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240304\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187950bd-18b5-4bd4-80da-2a0c7a984b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR_nscope\"\n",
    "dataset = \"top_100um\"\n",
    "\n",
    "# USER: specify path to detector mask\n",
    "\n",
    "# mask_path = '/data/id11/inhouse1/ewoks/detectors/files/eiger_E-08-0173/mask_with_gaps_E-08-0173.edf'  # temporary eiger mask (Nov 2023)\n",
    "# mask_path = '/data/id11/inhouse1/ewoks/detectors/files/eiger_E-08-0144/mask.edf'  # normal eiger mask\n",
    "\n",
    "mask_path = '/data/id11/inhouse1/ewoks/detectors/files/eiger_E-08-0173/mask_with_gaps_E-08-0173.edf'  # temporary eiger mask (Nov 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad077c4b-39cc-4b90-9637-33c32f12e364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create ImageD11 dataset object\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.DataSet(dataroot=rawdata_path,\n",
    "                                        analysisroot=processed_data_root_dir,\n",
    "                                        sample=sample,\n",
    "                                        dset=dataset)\n",
    "ds.import_all()\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20a5bf-b3b9-489a-81d3-4b8e6c792d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define the initial parameters\n",
    "start_pars = {#\"bgfile\": bg_path,\n",
    "              \"maskfile\": mask_path,\n",
    "              \"cut\": 1,\n",
    "              \"pixels_in_spot\": 3,\n",
    "               \"howmany\": 100000}\n",
    "\n",
    "def segment_frame_from_options( ds, options, image_file_num=None):\n",
    "    opts = ImageD11.sinograms.lima_segmenter.OPTIONS = ImageD11.sinograms.lima_segmenter.SegmenterOptions(**options)\n",
    "    opts.setup()\n",
    "    if image_file_num is None:\n",
    "        image_file_num = len(ds.imagefiles)//2\n",
    "    hfile = ImageD11.sinograms.lima_segmenter.os.path.join( ds.datapath, ds.imagefiles[ image_file_num ] )\n",
    "    with h5py.File( hfile, 'r' ) as hin:\n",
    "        frms = hin[ds.limapath]\n",
    "        for i, spf in enumerate( ImageD11.sinograms.lima_segmenter.reader( frms, opts.mask, opts.cut ) ): \n",
    "            ref = frms[i]\n",
    "            break\n",
    "    \n",
    "    spi = spf.to_dense('intensity')\n",
    "    \n",
    "    if opts.mask is not None:\n",
    "        rshow = ref * opts.mask\n",
    "        sshow = spi * opts.mask\n",
    "    else:\n",
    "        rshow = ref\n",
    "        sshow = spi\n",
    "    \n",
    "    return rshow, sshow\n",
    "\n",
    "cut_slider = widgets.IntSlider(value=start_pars[\"cut\"], min=1, max=20, step=1, description='Cut:')\n",
    "pixels_in_spot_slider = widgets.IntSlider(value=start_pars[\"pixels_in_spot\"], min=1, max=20, step=1, description='Pixels in Spot:')\n",
    "howmany_slider = widgets.IntSlider(value=np.log10(start_pars[\"howmany\"]), min=1, max=15, step=1, description='log(howmany):')\n",
    "\n",
    "# Display the image initially\n",
    "fig, axs = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16, 9))\n",
    "raw_image, segmented_image = segment_frame_from_options(ds, start_pars)\n",
    "im1 = axs[0].imshow(raw_image, cmap=\"viridis\", norm=LogNorm(vmin=1, vmax=1000), interpolation=\"nearest\")\n",
    "im2 = axs[1].imshow(segmented_image, cmap=\"viridis\", norm=LogNorm(vmin=1, vmax=1000), interpolation=\"nearest\")\n",
    "axs[0].set_title(\"Raw image\")\n",
    "axs[1].set_title(\"Segmented image\")\n",
    "labels, nblobs = measure.label(segmented_image, connectivity=2, return_num=True)\n",
    "plt.suptitle(f\"{nblobs} peaks found\\n cut={cut_slider.value}, pixels_in_spot={pixels_in_spot_slider.value}, howmany={10**howmany_slider.value}\")\n",
    "plt.show()\n",
    "\n",
    "def update_image(cut, pixels_in_spot, howmany):\n",
    "    howmany_exp = 10**howmany\n",
    "    these_opts = start_pars.copy()\n",
    "    these_opts[\"cut\"] = cut\n",
    "    these_opts[\"pixels_in_spot\"] = pixels_in_spot\n",
    "    these_opts[\"howmany\"] = howmany_exp\n",
    "    raw_image, segmented_image = segment_frame_from_options(ds, these_opts)\n",
    "    labels, nblobs = measure.label(segmented_image, connectivity=2, return_num=True)\n",
    "    im1.set_data(raw_image)\n",
    "    im2.set_data(segmented_image)\n",
    "    plt.suptitle(f\"{nblobs} peaks found\\n cut={cut}, pixels_in_spot={pixels_in_spot}, howmany={howmany_exp}\")\n",
    "    plt.draw()\n",
    "\n",
    "interactive_plot = widgets.interactive(update_image, cut=cut_slider, pixels_in_spot=pixels_in_spot_slider, howmany=howmany_slider)\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9c9ec-5301-4bf0-a7ba-2957afcc4db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_pars = {# \"bgfile\": bg_path,\n",
    "              \"maskfile\": mask_path,\n",
    "              \"cut\": cut_slider.value,\n",
    "              \"pixels_in_spot\": pixels_in_spot_slider.value,\n",
    "              \"howmany\": 10**howmany_slider.value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81929009-7445-434a-b19e-57bcd9e3e6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create batch file to send to SLURM cluster\n",
    "\n",
    "sbat = ImageD11.sinograms.lima_segmenter.setup(ds.dsfile, **end_pars)\n",
    "if sbat is None:\n",
    "    raise ValueError(\"This scan has already been segmented!\")\n",
    "print(sbat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827f616-bfae-45c1-969c-24da93886a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.slurm_submit_and_wait(sbat, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de23264-4c22-43fe-8be6-8cc54039ea2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label sparse peaks\n",
    "\n",
    "ImageD11.sinograms.assemble_label.main(ds.dsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb029cd-7f66-4c91-abee-5f1723303360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate peaks table\n",
    "\n",
    "ImageD11.sinograms.properties.main(ds.dsfile, options={'algorithm': 'lmlabel', 'wtmax': 70000, 'save_overlaps': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d215f-0ec9-4014-a49f-76e7c8167cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a new subfolder called \"sparse\" that holds all the individual \"scan______sparse.h5\" files\n",
    "\n",
    "sparse_folder_path = os.path.join(ds.analysispath, \"sparse\")\n",
    "\n",
    "if not os.path.exists(sparse_folder_path):\n",
    "    os.mkdir(sparse_folder_path)\n",
    "    \n",
    "scan_sparse_files = glob.glob(os.path.join(ds.analysispath, \"scan*_sparse.h5\"))\n",
    "\n",
    "for scan_sparse_file in scan_sparse_files:\n",
    "    shutil.move(scan_sparse_file, sparse_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e6575-bb8e-47ac-88e1-0ff5350ab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: incorporate DATA/visitor/ma5839/id11/20240118/SCRIPTS/0_S3DXRD_segment_and_label_single_dset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d22d0-ef82-4e08-8087-c57e76e16de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03508f-29f8-41d3-bad2-c78055010cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70bb5-035b-48b2-9acd-39c6e3ea8666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "\n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "\n",
    "print(samples_dict)\n",
    "\n",
    "# now we have our samples_dict, we can process our data:\n",
    "mask_path = '/data/id11/inhouse1/ewoks/detectors/files/eiger_E-08-0173/mask_with_gaps_E-08-0173.edf'\n",
    "\n",
    "# you can change these if needed, but they will default to those you selected with the widget\n",
    "\n",
    "try:\n",
    "    seg_pars = {\"maskfile\": mask_path,\n",
    "                \"cut\": cut_slider.value,\n",
    "                \"pixels_in_spot\": pixels_in_spot_slider.value,\n",
    "                \"howmany\": 10**howmany_slider.value}\n",
    "except NameError:\n",
    "    seg_pars = {\"maskfile\": mask_path}\n",
    "\n",
    "\n",
    "sbats = []\n",
    "dataset_objects = []\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.DataSet(dataroot=rawdata_path,\n",
    "                                                analysisroot=processed_data_root_dir,\n",
    "                                                sample=sample,\n",
    "                                                dset=dataset)\n",
    "        \n",
    "        if os.path.exists(ds.sparsefile):\n",
    "            print(f\"Found existing Sparse file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        try:\n",
    "            ds.import_all()\n",
    "        except ValueError:\n",
    "            print(f\"Very dodgy scan! Skipping\")\n",
    "            continue\n",
    "        except KeyError:\n",
    "            print(f\"Very dodgy scan! Skipping\")\n",
    "            continue\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        ds.save()\n",
    "        \n",
    "        print(\"Segmenting\")\n",
    "        sbat = ImageD11.sinograms.lima_segmenter.setup(ds.dsfile, **seg_pars)\n",
    "        \n",
    "        if sbat is None:\n",
    "            print(f\"{dataset} in sample {sample} already segmented, skipping\")\n",
    "            continue\n",
    "            \n",
    "        sbats.append(sbat)\n",
    "        dataset_objects.append(ds)\n",
    "\n",
    "        \n",
    "utils.slurm_submit_many_and_wait(sbats, wait_time_sec=60)\n",
    "\n",
    "for ds in dataset_objects:\n",
    "    print(\"Labelling sparse peaks\")\n",
    "    ImageD11.sinograms.assemble_label.main(ds.dsfile)\n",
    "\n",
    "    print(\"Generating peaks table\")\n",
    "    ImageD11.sinograms.properties.main(ds.dsfile, options={'algorithm': 'lmlabel', 'wtmax': 70000, 'save_overlaps': False})\n",
    "\n",
    "    print(\"Cleaning up sparse files\")\n",
    "    sparse_folder_path = os.path.join(ds.analysispath, \"sparse\")\n",
    "\n",
    "    if not os.path.exists(sparse_folder_path):\n",
    "        os.mkdir(sparse_folder_path)\n",
    "\n",
    "    scan_sparse_files = glob.glob(os.path.join(ds.analysispath, \"scan*_sparse.h5\"))\n",
    "\n",
    "    for scan_sparse_file in scan_sparse_files:\n",
    "        shutil.move(scan_sparse_file, sparse_folder_path)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efe8f8-4226-45fc-9df7-d916e61ecb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
