{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8deabe5b",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 26/02/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fcab9-7631-439f-885c-438bcefeac84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a bug with the current version of ImageD11 in the site-wide Jupyter env.\n",
    "# This has been fixed here: https://github.com/FABLE-3DXRD/ImageD11/commit/4af88b886b1775585e868f2339a0eb975401468f\n",
    "# Until a new release has been made and added to the env, we need to get the latest version of ImageD11 from GitHub\n",
    "# Put it in your home directory\n",
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "username = os.environ.get(\"USER\")\n",
    "\n",
    "id11_code_path = f\"/home/esrf/{username}/Code/ImageD11\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c1db6-5a32-4294-abef-cfc2150d24de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import glob, pprint\n",
    "import fabio\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.sinograms.lima_segmenter\n",
    "import ImageD11.sinograms.assemble_label\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import fabio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from skimage import filters, measure, morphology\n",
    "from ipywidgets import interact, interactive, widgets, fixed, Layout\n",
    "import h5py\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e3647-2e1b-4a31-b5de-01adbd4d7573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that we're importing ImageD11 from the home directory rather than from the Jupyter kernel\n",
    "\n",
    "?ImageD11.sinograms.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c0244-49dd-425e-a9b1-90f20e91a066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Write a detector function to check whether it's an old-style data format or a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb520f-cb00-4eeb-b740-fc7b407f1f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: For old datasets before the new directory layout structure, we don't distinguish between RAW_DATA and PROCESSED_DATA\n",
    "# In this case, use this cell to specify where your experimental folder is, and do not run the cell below\n",
    "# e.g /data/visitor/ma4752/id11/20210513\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/RAW_DATA\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "### USER: specify where you want your processed data to go\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240226\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187950bd-18b5-4bd4-80da-2a0c7a984b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR_nscope\"\n",
    "dataset = \"top_100um\"\n",
    "\n",
    "# USER: specify path to detector mask\n",
    "\n",
    "mask_path = '/data/id11/nanoscope/Eiger/eiger_mask_E-08-0173_20231127.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad077c4b-39cc-4b90-9637-33c32f12e364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create ImageD11 dataset object\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.DataSet(dataroot=rawdata_path,\n",
    "                                        analysisroot=processed_data_root_dir,\n",
    "                                        sample=sample,\n",
    "                                        dset=dataset)\n",
    "ds.import_all()\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c52da1-1948-4de7-b80b-d735bf8e8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: autodetect eiger/frelon (get from ds object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20a5bf-b3b9-489a-81d3-4b8e6c792d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define the initial parameters\n",
    "start_pars = {#\"bgfile\": bg_path,\n",
    "              \"maskfile\": mask_path,\n",
    "              \"cut\": 1,\n",
    "              \"pixels_in_spot\": 3}\n",
    "\n",
    "mask = fabio.open(start_pars[\"maskfile\"]).data\n",
    "#bgimage = fabio.open(start_pars[\"bgfile\"]).data\n",
    "\n",
    "# no background\n",
    "bgimage = np.zeros_like(mask)\n",
    "\n",
    "with h5py.File(ds.masterfile, 'r') as h5In:\n",
    "    image = h5In['31.1/measurement/eiger'][150].astype('uint16')\n",
    "\n",
    "def segment_image(image, cut, pixels_in_spot, bgimage):\n",
    "    cut_image = (image - bgimage)*(mask) > cut\n",
    "    labeled_image = measure.label(cut_image)\n",
    "    blob_properties = measure.regionprops(labeled_image)\n",
    "    blob_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    spot_count = 0\n",
    "    for prop in blob_properties:\n",
    "        if prop.area >= pixels_in_spot:\n",
    "            blob_mask[labeled_image == prop.label] = 1\n",
    "            spot_count += 1\n",
    "    filtered_image = (image-bgimage) * blob_mask\n",
    "    return filtered_image, spot_count\n",
    "\n",
    "\n",
    "cut_slider = widgets.IntSlider(value=start_pars[\"cut\"], min=1, max=20, step=1, description='Cut:')\n",
    "pixels_in_spot_slider = widgets.IntSlider(value=start_pars[\"pixels_in_spot\"], min=1, max=20, step=1, description='Pixels in Spot:')\n",
    "\n",
    "# Display the image initially\n",
    "plt.figure()\n",
    "\n",
    "filtered_image, nspots = segment_image(image, cut=cut_slider.value, pixels_in_spot=pixels_in_spot_slider.value, bgimage=bgimage)\n",
    "filtered_image[filtered_image == 65535] = 0\n",
    "im = plt.imshow(filtered_image, cmap=\"viridis\", norm=LogNorm(vmin=1, vmax=1000), interpolation=\"nearest\")\n",
    "plt.title(f\"cut={cut_slider.value}, pixels_in_spot={pixels_in_spot_slider.value}, nspots={nspots}\")\n",
    "plt.show()\n",
    "\n",
    "def update_image(cut, pixels_in_spot):\n",
    "    filtered_image, nspots = segment_image(image, cut, pixels_in_spot, bgimage)\n",
    "    \n",
    "    filtered_image[filtered_image == 65535] = 0\n",
    "    \n",
    "    im.set_data(filtered_image)\n",
    "    plt.title(f\"cut={cut}, pixels_in_spot={pixels_in_spot}, nspots={nspots}\")\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "\n",
    "interactive_plot = widgets.interactive(update_image, cut=cut_slider, pixels_in_spot=pixels_in_spot_slider)\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9c9ec-5301-4bf0-a7ba-2957afcc4db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_pars = {# \"bgfile\": bg_path,\n",
    "              \"maskfile\": mask_path,\n",
    "              \"cut\": cut_slider.value,\n",
    "              \"pixels_in_spot\": pixels_in_spot_slider.value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81929009-7445-434a-b19e-57bcd9e3e6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create batch file to send to SLURM cluster\n",
    "\n",
    "sbat = ImageD11.sinograms.lima_segmenter.setup(ds.dsfile, **end_pars)\n",
    "sbat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827f616-bfae-45c1-969c-24da93886a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.slurm_submit_and_wait(sbat, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de23264-4c22-43fe-8be6-8cc54039ea2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label sparse peaks\n",
    "\n",
    "ImageD11.sinograms.assemble_label.main(ds.dsfile, ds.sparsefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb029cd-7f66-4c91-abee-5f1723303360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate peaks table\n",
    "\n",
    "ImageD11.sinograms.properties.main(ds.dsfile, ds.sparsefile, ds.pksfile, options={'algorithm': 'lmlabel', 'wtmax': 70000, 'save_overlaps': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d215f-0ec9-4014-a49f-76e7c8167cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a new subfolder called \"sparse\" that holds all the individual \"scan______sparse.h5\" files\n",
    "\n",
    "sparse_folder_path = os.path.join(ds.analysispath, \"sparse\")\n",
    "\n",
    "if not os.path.exists(sparse_folder_path):\n",
    "    os.mkdir(sparse_folder_path)\n",
    "    \n",
    "scan_sparse_files = glob.glob(os.path.join(ds.analysispath, \"scan*_sparse.h5\"))\n",
    "\n",
    "for scan_sparse_file in scan_sparse_files:\n",
    "    shutil.move(scan_sparse_file, sparse_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e6575-bb8e-47ac-88e1-0ff5350ab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: incorporate DATA/visitor/ma5839/id11/20240118/SCRIPTS/0_S3DXRD_segment_and_label_single_dset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d22d0-ef82-4e08-8087-c57e76e16de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70bb5-035b-48b2-9acd-39c6e3ea8666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our segmentation parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "mask_path = '/data/id11/nanoscope/Eiger/eiger_mask_E-08-0173_20231127.edf'\n",
    "\n",
    "# you can change these if needed, but they will default to those you selected with the widget\n",
    "seg_pars = {\"maskfile\": mask_path,\n",
    "            \"cut\": cut_slider.value,\n",
    "            \"pixels_in_spot\": pixels_in_spot_slider.value}\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.DataSet(dataroot=rawdata_path,\n",
    "                                                analysisroot=processed_data_root_dir,\n",
    "                                                sample=sample,\n",
    "                                                dset=dataset)\n",
    "        if os.path.exists(ds.sparsefile):\n",
    "            print(f\"Found existing Sparse file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        ds.import_all()\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        ds.save()\n",
    "        \n",
    "        print(\"Segmenting\")\n",
    "        sbat = ImageD11.sinograms.lima_segmenter.setup(ds.dsfile, **seg_pars)\n",
    "        utils.slurm_submit_and_wait(sbat, 60)\n",
    "        \n",
    "        print(\"Labelling sparse peaks\")\n",
    "        ImageD11.sinograms.assemble_label.main(ds.dsfile, ds.sparsefile)\n",
    "        \n",
    "        print(\"Generating peaks table\")\n",
    "        ImageD11.sinograms.properties.main(ds.dsfile, ds.sparsefile, ds.pksfile, options={'algorithm': 'lmlabel', 'wtmax': 70000, 'save_overlaps': False})\n",
    "        \n",
    "        print(\"Cleaning up sparse files\")\n",
    "        sparse_folder_path = os.path.join(ds.analysispath, \"sparse\")\n",
    "\n",
    "        if not os.path.exists(sparse_folder_path):\n",
    "            os.mkdir(sparse_folder_path)\n",
    "\n",
    "        scan_sparse_files = glob.glob(os.path.join(ds.analysispath, \"scan*_sparse.h5\"))\n",
    "\n",
    "        for scan_sparse_file in scan_sparse_files:\n",
    "            shutil.move(scan_sparse_file, sparse_folder_path)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee80e4-d426-46a9-b635-a28ded5039e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
