{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 12/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will try to reconstruct grain shapes and positions from the grain orientations you found in the first notebook.  \n",
    "This notebook (and the tomo route in general) works best for low levels of deformation.  \n",
    "If it doesn't seem to work well, try the point-by-point route instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import convex_hull_image\n",
    "\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11.peakselect import select_ring_peaks_by_intensity\n",
    "from ImageD11.sinograms.sinogram import GrainSinogram, build_slice_arrays, write_slice_recon, read_h5, write_h5, get_2d_peaks_from_4d_peaks\n",
    "from ImageD11.sinograms.roi_iradon import run_iradon\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.sinograms.geometry import sino_shift\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick a phase\n",
    "phase_str = 'Fe'\n",
    "\n",
    "ucell = ds.phases.unitcells[phase_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the sinograms are only half-sinograms (we scanned dty across half the sample rather than the full sample), set the below to true:\n",
    "is_half_scan = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_half_scan:\n",
    "    ds.correct_bins_for_half_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 4D peaks\n",
    "\n",
    "cf_4d = ds.get_cf_4d_from_disk()\n",
    "\n",
    "ds.update_colfile_pars(cf_4d, phase_name=phase_str)\n",
    "\n",
    "print(f\"Read {cf_4d.nrows} 4D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_4d) to select only the strongest ones\n",
    "# this time as opposed to indexing, our frac is slightly weaker but we are NOT filtering in dstar!!!!!\n",
    "# this means many more peaks per grain = stronger sinograms\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until the orange dot sits nicely on the \"elbow\" of the blue line\n",
    "# this indicates the fractional intensity cutoff we will select\n",
    "# if the blue line does not look elbow-shaped in the logscale plot, try changing the \"doplot\" parameter (the y scale of the logscale plot) until it does\n",
    "\n",
    "cf_strong_frac = 0.993\n",
    "cf_strong_dstol = 0.005\n",
    "\n",
    "cf_strong = select_ring_peaks_by_intensity(cf_4d, frac=cf_strong_frac, dstol=cf_strong_dstol, dsmax=cf_4d.ds.max(), doplot=0.9)\n",
    "print(cf_4d.nrows)\n",
    "cf_strong.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can take a look at the intensities of the remaining peaks\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "ucell.makerings(cf_4d.ds.max())\n",
    "\n",
    "ax.plot(cf_4d.ds, cf_4d.sum_intensity,',', label='cf_4d')\n",
    "ax.plot(cf_strong.ds, cf_strong.sum_intensity,',', label='cf_strong')\n",
    "ax.plot(ucell.ringds, [1e4,]*len(ucell.ringds), '|', ms=90, c=\"red\")\n",
    "\n",
    "ax.semilogy()\n",
    "\n",
    "ax.set_xlabel(\"Dstar\")\n",
    "ax.set_ylabel(\"Intensity\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the grains from disk\n",
    "\n",
    "grains = ds.get_grains_from_disk(phase_str)\n",
    "print(f\"{len(grains)} grains imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign peaks to the grains\n",
    "\n",
    "peak_assign_tol = 0.25\n",
    "utils.assign_peaks_to_grains(grains, cf_strong, peak_assign_tol)\n",
    "\n",
    "for grain_label, g in enumerate(grains):\n",
    "    g.npks_4d = np.sum(cf_strong.grain_id == grain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's make a GrainSinogram object for each grain\n",
    "\n",
    "grainsinos = [GrainSinogram(g, ds) for g in grains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's determine the positions of each grain from the 4D peaks\n",
    "\n",
    "for grain_label, gs in enumerate(grainsinos):\n",
    "    gs.update_lab_position_from_peaks(cf_strong, grain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can also determine the RGB IPF colours of the grains which will be useful for plotting\n",
    "\n",
    "utils.get_rgbs_for_grains(grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.plot_all_ipfs(grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we can plot our grain positions and RGB colours:\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.translation[0] for g in grains]\n",
    "y = [g.translation[1] for g in grains]\n",
    "s = [g.npks_4d/10 for g in grains]\n",
    "a[0].scatter(y, x, c=[g.rgb_z for g in grains], s=s)\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(y, x, c=[g.rgb_y for g in grains], s=s)\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(y, x, c=[g.rgb_x for g in grains], s=s)\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(y, x, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"<- Sample y (transverse)\")\n",
    "fig.supylabel(\"Sample x (beam) ->\")\n",
    "\n",
    "for a in ax.ravel():\n",
    "    a.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to determine what the value of dty is where the rotation axis intercepts the beam\n",
    "# we'll call this y0\n",
    "# should be the result of the centre-of-mass fit\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sample_y0s = [gs.recon_y0 for gs in grainsinos]\n",
    "\n",
    "ax.plot(sample_y0s)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "y0 = np.median(sample_y0s)\n",
    "\n",
    "print('y0 is', y0)\n",
    "\n",
    "# to determine the shift we apply to the sinograms for good reconstructions\n",
    "# we have to know where the beam -should- be according to the dty axis\n",
    "# for NSCOPE measurements, this is typically 0 um\n",
    "# for TDXRD measurements, this is typically 14 mm = 14000 um\n",
    "\n",
    "# ybeam = 14 * 1000  # um, for TDXRD station\n",
    "ybeam = 0  # um, for NSCOPE station\n",
    "    \n",
    "# the shift we have to apply to the reconstructions is equal to -y0/ystep (in integer coords)\n",
    "\n",
    "shift = sino_shift(y0, ybeam, ds.ystep)\n",
    "\n",
    "print('shift is', shift)\n",
    "\n",
    "# update the grainsinogram parameters accordingly:\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(y0=y0, shift=shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's do a whole-sample tomographic reconstruction\n",
    "# generate sinogram for whole sample\n",
    "\n",
    "whole_sample_sino, xedges, yedges = np.histogram2d(cf_4d.dty, cf_4d.omega, bins=[ds.ybinedges, ds.obinedges])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(whole_sample_sino, interpolation=\"nearest\", vmin=0, aspect='auto', norm='log')\n",
    "#ax.set_aspect(4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"quick\" whole-sample reconstruction\n",
    "\n",
    "pad = 30\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "whole_sample_recon = run_iradon(whole_sample_sino, ds.obincens, pad, shift, workers=nthreads, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# without a mask, MLEM can introduce artifacts in the corners\n",
    "# so we can manually mask those out\n",
    "\n",
    "# we can incoporate our own mask too\n",
    "# by modifying the below function\n",
    "\n",
    "def apply_manual_mask(mask_in):\n",
    "    mask_out = mask_in.copy()\n",
    "    \n",
    "    # mask_out[200:, 250:] = 0\n",
    "    \n",
    "    return mask_out\n",
    "\n",
    "# we should be able to easily segment this using scikit-image\n",
    "recon_man_mask = apply_manual_mask(whole_sample_recon)\n",
    "\n",
    "# we can also override the threshold if we don't like it:\n",
    "# manual_threshold = 0.006\n",
    "manual_threshold = None\n",
    "\n",
    "if manual_threshold is None:\n",
    "    thresh = threshold_otsu(recon_man_mask)\n",
    "else:\n",
    "    thresh = manual_threshold\n",
    "\n",
    "binary = recon_man_mask > thresh\n",
    "\n",
    "chull = convex_hull_image(binary)\n",
    "\n",
    "whole_sample_mask = chull\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0].imshow(recon_man_mask, vmin=0, origin=\"lower\")\n",
    "axs[1].imshow(binary, origin=\"lower\")\n",
    "axs[2].imshow(chull, origin=\"lower\")\n",
    "\n",
    "axs[0].set_title(\"Reconstruction\")\n",
    "axs[1].set_title(\"Binarised threshold\")\n",
    "axs[2].set_title(\"Convex hull\")\n",
    "\n",
    "fig.supxlabel(\"<-- Sample Y axis\")\n",
    "fig.supylabel(\"Sample x axis (Beam) >\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we have a whole-sample reconstruction we can use as a sample mask\n",
    "# let's build the sinograms for our grains\n",
    "# before we do this, we need to determine our 2D peaks that will be used for the sinogram\n",
    "# here we can get them from the 4D peaks:\n",
    "\n",
    "hkltol = 0.25\n",
    "\n",
    "gord, inds = get_2d_peaks_from_4d_peaks(ds.pk2d, cf_strong)\n",
    "\n",
    "for grain_label, gs in enumerate(tqdm(grainsinos)):\n",
    "    gs.prepare_peaks_from_4d(cf_strong, gord, inds, grain_label, hkltol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can actually generate the sinograms\n",
    "\n",
    "for gs in tqdm(grainsinos):\n",
    "    gs.build_sinogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optionally correct the halfmask:\n",
    "\n",
    "if is_half_scan:\n",
    "    for gs in grainsinos:\n",
    "        gs.correct_halfmask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(gs.ssino, aspect='auto')\n",
    "ax.set_title(\"ssino\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can optionally correct each row of the sinogram by the ring current of that rotation\n",
    "# This helps remove artifacts in the reconstruction\n",
    "\n",
    "correct_sinos_with_ring_current = True\n",
    "if correct_sinos_with_ring_current:\n",
    "    ds.get_ring_current_per_scan()\n",
    "    \n",
    "    for gs in grainsinos:\n",
    "        gs.correct_ring_current(is_half_scan=is_half_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(gs.ssino, aspect='auto')\n",
    "ax.set_title(\"ssino\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's try out an iradon reconstruction\n",
    "\n",
    "gs = grainsinos[0]\n",
    "\n",
    "# update the parameters used for the iradon reconstruction\n",
    "\n",
    "gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, y0=y0)\n",
    "\n",
    "# perform the reconstruction\n",
    "\n",
    "gs.recon()\n",
    "\n",
    "if is_half_scan:\n",
    "    halfmask_radius = 25\n",
    "    gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)\n",
    "\n",
    "# view the result\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].imshow(gs.ssino, aspect='auto')\n",
    "axs[0].set_title(\"ssino\")\n",
    "axs[1].imshow(gs.recons[\"iradon\"], vmin=0, origin=\"lower\")\n",
    "axs[1].set_title(\"ID11 iradon\")\n",
    "axs[1].set_xlabel(\"<-- Sample Y\")\n",
    "axs[1].set_ylabel(\"Sample X\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# once you're happy with the reconstruction parameters used, set them for all the grains\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, y0=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reconstruct all grains in parallel\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1,nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(GrainSinogram.recon, grainsinos), total=len(grainsinos)):\n",
    "        pass\n",
    "\n",
    "if is_half_scan:\n",
    "    for gs in grainsinos:\n",
    "        gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(1,2,figsize=(10,5))\n",
    "rec = a[0].imshow(grainsinos[0].recons[\"iradon\"], vmin=0, origin=\"lower\")\n",
    "sin = a[1].imshow(grainsinos[0].ssino, aspect='auto')\n",
    "a[0].set_xlabel(\"<-- Sample Y\")\n",
    "a[0].set_ylabel(\"Sample X\")\n",
    "\n",
    "# Function to update the displayed image based on the selected frame\n",
    "def update_frame(i):\n",
    "    rec.set_array(grainsinos[i].recons[\"iradon\"])\n",
    "    sin.set_array(grainsinos[i].ssino)\n",
    "    a[0].set(title=str(i))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# Create a slider widget to select the frame number\n",
    "frame_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(grains) - 1,\n",
    "    step=1,\n",
    "    description='Grain:'\n",
    ")\n",
    "\n",
    "interact(update_frame, i=frame_slider)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's assemble all the recons together into a TensorMap\n",
    "\n",
    "tensor_map = TensorMap.from_grainsinos(grainsinos, cutoff_level=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot initial output\n",
    "\n",
    "tensor_map.plot(\"ipf_z\")\n",
    "tensor_map.plot(\"labels\")\n",
    "tensor_map.plot(\"intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can clean up these reconstructions using an MLEM iterative recon\n",
    "# we will carry this out using ASTRA on the GPU on the cluster\n",
    "# the ASTRA EM_CUDA method will be used\n",
    "# note that the mask will not be applied - normally not needed for ASTRA EM_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose the number of iterations\n",
    "# experience shows 500 is good, and pretty quick on the GPU\n",
    "\n",
    "niter = 500\n",
    "\n",
    "for gs in grainsinos:\n",
    "    gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, niter=niter, y0=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the GrainSinogram objects to disk\n",
    "\n",
    "write_h5(ds.grainsfile, grainsinos, overwrite_grains=True, group_name=phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare ASTRA bash scripts to run it on the cluster\n",
    "\n",
    "bash_script_path = utils.prepare_astra_bash(ds, ds.grainsfile, PYTHONPATH, group_name=phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submit ASTRA jobs to cluster\n",
    "\n",
    "utils.slurm_submit_and_wait(bash_script_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-import our reconstructed grains\n",
    "\n",
    "grainsinos = read_h5(ds.grainsfile, ds, group_name=phase_str)\n",
    "# re-associate grainsino grain objects to existing grain objects\n",
    "\n",
    "for gs, g in zip(grainsinos, grains):\n",
    "    gs.grain = g\n",
    "    gs.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at all our ASTRA recons in a grid\n",
    "\n",
    "n_grains_to_plot = 25\n",
    "\n",
    "grains_step = len(grainsinos)//n_grains_to_plot\n",
    "\n",
    "grid_size = np.ceil(np.sqrt(len(grainsinos[::grains_step]))).astype(int)\n",
    "nrows = (len(grainsinos[::grains_step])+grid_size-1)//grid_size\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, nrows, figsize=(10,10), layout=\"constrained\", sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    if i < len(grainsinos[::grains_step]):\n",
    "    # get corresponding grain for this axis\n",
    "        gs = grainsinos[::grains_step][i]\n",
    "        ax.imshow(gs.recons[\"astra\"], vmin=0, origin=\"lower\")\n",
    "        # ax.invert_yaxis()\n",
    "        ax.set_title(i)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_level = 0.05\n",
    "\n",
    "tensor_map_astra = TensorMap.from_grainsinos(grainsinos, cutoff_level=cutoff_level, method=\"astra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map_astra.plot(\"ipf_z\")\n",
    "tensor_map_astra.plot(\"labels\")\n",
    "tensor_map_astra.plot(\"intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write our results to disk\n",
    "\n",
    "write_h5(ds.grainsfile, grainsinos, overwrite_grains=True, group_name=phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the TensorMap to disk too\n",
    "\n",
    "tensor_map_astra.to_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can also write an XDMF file so you can visualise the TensorMap with ParaView\n",
    "\n",
    "tensor_map_astra.to_paraview(ds.grainsfile, h5group='TensorMap_' + phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if not os.path.exists(ds.grainsfile):\n",
    "            print(f\"Missing grains file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        # check grains file for existance of output, skip if it's there\n",
    "        with h5py.File(ds.grainsfile, \"r\") as hin:\n",
    "            if 'TensorMap_' + phase_str in hin.keys():\n",
    "                print(f\"Already reconstructed {dataset} in {sample}, skipping\")\n",
    "                continue\n",
    "        \n",
    "        ds.phases = ds.get_phases_from_disk()\n",
    "        if is_half_scan:\n",
    "            ds.correct_bins_for_half_scan()\n",
    "        \n",
    "        print(\"Peaks\")\n",
    "        # cf_4d = ds.get_cf_4d_from_disk()\n",
    "        cf_4d = ds.get_cf_4d()\n",
    "        ds.update_colfile_pars(cf_4d, phase_name=phase_str)\n",
    "        \n",
    "        cf_strong = select_ring_peaks_by_intensity(cf_4d, frac=cf_strong_frac, dstol=cf_strong_dstol, dsmax=cf_4d.ds.max())\n",
    "        \n",
    "        print(\"Grains\")\n",
    "        grains = ds.get_grains_from_disk(phase_str)\n",
    "        utils.assign_peaks_to_grains(grains, cf_strong, peak_assign_tol)\n",
    "        \n",
    "        grainsinos = [GrainSinogram(g, ds) for g in grains]\n",
    "        \n",
    "        print(\"Fitting grain positions\")\n",
    "        for grain_label, gs in enumerate(grainsinos):\n",
    "            gs.update_lab_position_from_peaks(cf_strong, grain_label)\n",
    "        \n",
    "        sample_y0s = [gs.recon_y0 for gs in grainsinos]\n",
    "        y0 = np.median(sample_y0s)\n",
    "        shift = sino_shift(y0, ybeam, ds.ystep)\n",
    "        \n",
    "        print(\"Determining RGB colours\")\n",
    "        utils.get_rgbs_for_grains(grains)\n",
    "        \n",
    "        print(\"Whole sample mask recon\")\n",
    "        whole_sample_sino, xedges, yedges = np.histogram2d(cf_4d.dty, cf_4d.omega, bins=[ds.ybinedges, ds.obinedges])\n",
    "        whole_sample_recon = run_iradon(whole_sample_sino, ds.obincens, pad, shift, workers=nthreads, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)\n",
    "        \n",
    "        recon_man_mask = apply_manual_mask(whole_sample_recon)\n",
    "        \n",
    "        if manual_threshold is None:\n",
    "            thresh = threshold_otsu(recon_man_mask)\n",
    "        else:\n",
    "            thresh = manual_threshold\n",
    "            \n",
    "        binary = recon_man_mask > thresh\n",
    "        whole_sample_mask = convex_hull_image(binary)\n",
    "        \n",
    "        gord, inds = get_2d_peaks_from_4d_peaks(ds.pk2d, cf_strong)\n",
    "        \n",
    "        print(\"Building sinograms\")\n",
    "        for grain_label, gs in enumerate(tqdm(grainsinos)):\n",
    "            gs.prepare_peaks_from_4d(cf_strong, gord, inds, grain_label, hkltol)\n",
    "            gs.build_sinogram()\n",
    "            \n",
    "            if is_half_scan:\n",
    "                gs.correct_halfmask()\n",
    "            \n",
    "        if correct_sinos_with_ring_current:\n",
    "            print(\"Correcting for ring current\")\n",
    "            ds.get_ring_current_per_scan()\n",
    "            for gs in grainsinos:\n",
    "                gs.correct_ring_current(is_half_scan=is_half_scan)\n",
    "        \n",
    "        for gs in grainsinos:\n",
    "            gs.update_recon_parameters(pad=pad, shift=shift, mask=whole_sample_mask, niter=niter, y0=y0)\n",
    "        \n",
    "        print(\"Running iradon\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max(1,nthreads-1)) as pool:\n",
    "            for i in tqdm(pool.map(GrainSinogram.recon, grainsinos), total=len(grainsinos)):\n",
    "                pass\n",
    "        \n",
    "        if is_half_scan:\n",
    "            for gs in grainsinos:\n",
    "                gs.mask_central_zingers(\"iradon\", radius=halfmask_radius)\n",
    "        \n",
    "        print(\"Preparing SLURM ASTRA\")\n",
    "        write_h5(ds.grainsfile, grainsinos, overwrite_grains=True, group_name=phase_str)\n",
    "        bash_script_path = utils.prepare_astra_bash(ds, ds.grainsfile, PYTHONPATH, group_name=phase_str)\n",
    "        utils.slurm_submit_and_wait(bash_script_path, 10)\n",
    "        \n",
    "        print(\"Loading ASTRA results\")\n",
    "        grainsinos = read_h5(ds.grainsfile, ds, group_name=phase_str)\n",
    "        \n",
    "        for gs, g in zip(grainsinos, grains):\n",
    "            gs.grain = g\n",
    "            gs.ds = ds\n",
    "        \n",
    "        if is_half_scan:\n",
    "            for gs in grainsinos:\n",
    "                gs.mask_central_zingers(\"astra\", radius=halfmask_radius)\n",
    "        \n",
    "        print(\"Final save\")\n",
    "        write_h5(ds.grainsfile, grainsinos, overwrite_grains=True, group_name=phase_str)\n",
    "        \n",
    "        tensor_map_astra = TensorMap.from_grainsinos(grainsinos, cutoff_level=cutoff_level, method=\"astra\")\n",
    "        tensor_map_astra.to_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)\n",
    "        tensor_map_astra.to_paraview(ds.grainsfile, h5group='TensorMap_' + phase_str)\n",
    "        \n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
