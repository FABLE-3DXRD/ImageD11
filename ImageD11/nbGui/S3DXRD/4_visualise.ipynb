{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 12/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will convert the (potentially) multi-valued results of a point-by-point strain refinement process to a single-valued 'TensorMap' with many useful export formats, like H5, Paraview XDMF, and MTEX CTF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import unitcell\n",
    "import ImageD11.sinograms.dataset\n",
    "from ImageD11.sinograms.point_by_point import PBPMap, nb_inv, PBPRefine\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.nbGui import nb_utils as utils\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's select a phase to index from our parameters json\n",
    "phase_str = 'Fe'\n",
    "\n",
    "ref_ucell = ds.phases.unitcells[phase_str]\n",
    "\n",
    "print(ref_ucell.lattice_parameters, ref_ucell.spacegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import refinement manager\n",
    "\n",
    "refine = PBPRefine.from_h5(ds.refmanfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we inspect the results of the refined map\n",
    "\n",
    "# plot a histogram of unique peaks per ubi\n",
    "\n",
    "refine.refinedmap.plot_nuniq_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose the minimum number of peaks you want a pixel to have to be counted\n",
    "\n",
    "min_unique = 400\n",
    "\n",
    "refine.refinedmap.choose_best(min_unique)\n",
    "\n",
    "# refine.refinedmap.choose_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's plot the result of your choice\n",
    "\n",
    "refine.refinedmap.plot_best(min_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at the fancy strain results\n",
    "# this is from refine.refinedmap.best_eps\n",
    "\n",
    "fig, axs = plt.subplots(3,3, sharex=True, sharey=True, layout='constrained', figsize=(10,10))\n",
    "\n",
    "cmap = cm.get_cmap('RdBu_r')\n",
    "normalizer = Normalize(-1e-3, 1e-3)\n",
    "im = cm.ScalarMappable(norm=normalizer, cmap=cmap)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i,j].imshow(refine.refinedmap.best_eps[:, :, i, j], origin=\"lower\", cmap=cmap, norm=normalizer)\n",
    "        axs[i,j].set_title(f'eps_{i+1}{j+1}')\n",
    "fig.supxlabel('< Lab Y axis')\n",
    "fig.supylabel('Lab X axis')\n",
    "fig.colorbar(im, ax=axs.ravel().tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now make a TensorMap from our refined map so we can plot and export\n",
    "\n",
    "# first let's work out what phase we have\n",
    "phases = {0: ref_ucell}\n",
    "\n",
    "# let's make a phase id map from our pbpmap\n",
    "phase_ids = TensorMap.recon_order_to_map_order(np.where(refine.refinedmap.best_nuniq > min_unique, 0, -1))\n",
    "\n",
    "# reshape the fancy strain map too\n",
    "eps_sample = TensorMap.recon_order_to_map_order(refine.refinedmap.best_eps)\n",
    "\n",
    "tmap = TensorMap.from_pbpmap(refine.refinedmap, steps=(1, ds.ystep, ds.ystep), phases=phases)\n",
    "tmap['phase_ids'] = phase_ids\n",
    "tmap['eps_sample'] = eps_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the tensormap unique peaks\n",
    "\n",
    "tmap.plot('nuniq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the IPF colours from the UBIs and phase\n",
    "\n",
    "tmap.get_ipf_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmap.plot('ipf_x')\n",
    "tmap.plot('ipf_y')\n",
    "tmap.plot('ipf_z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3, sharex=True, sharey=True, layout='constrained', figsize=(10,10))\n",
    "\n",
    "cmap = cm.get_cmap('RdBu_r')\n",
    "normalizer = Normalize(-1e-3, 1e-3)\n",
    "im = cm.ScalarMappable(norm=normalizer, cmap=cmap)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i,j].imshow(tmap.eps_sample[0, ..., i, j], origin=\"lower\", cmap=cmap, norm=normalizer)\n",
    "        axs[i,j].set_title(f'eps_{i+1}{j+1}')\n",
    "fig.supxlabel('Lab X axis --->')\n",
    "fig.supylabel('Lab Y axis --->')\n",
    "fig.colorbar(im, ax=axs.ravel().tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at unit cells - mean of a, b, c for cubic for now\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(tmap.unitcell[0, :, :, :3].mean(axis=-1).ravel(), bins=1000)\n",
    "ax.set_xlabel('unitcell of pixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean unitcell?\n",
    "\n",
    "print(np.nanmean(tmap.unitcell[0, :, :, :3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trigger calculation of all the maps\n",
    "\n",
    "eul = tmap.euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the refined TensorMap to disk\n",
    "\n",
    "tmap.to_h5(os.path.join(ds.analysispath, 'pbp_tensormap_refined.h5'))\n",
    "tmap.to_paraview(os.path.join(ds.analysispath, 'pbp_tensormap_refined.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can also do an MTEX export if you like:\n",
    "\n",
    "ctf_path = os.path.join(ds.analysispath, 'pbp_tensormap_refined.ctf')\n",
    "\n",
    "tmap.to_ctf_mtex(ctf_path, z_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(ds.dataroot, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        if not os.path.exists(ds.refoutfile):\n",
    "            print(f\"Couldn't find PBP refinement output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(os.path.join(ds.analysispath, 'pbp_tensormap_refined.h5')):\n",
    "            print(f\"Already have refined TensorMap output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        refine = PBPRefine.from_h5(ds.refmanfile)\n",
    "        refine.refinedmap.choose_best(min_unique)\n",
    "        \n",
    "        # first let's work out what phase we have\n",
    "        phases = {0: ref_ucell}\n",
    "\n",
    "        # let's make a phase id map from our pbpmap\n",
    "        phase_ids = TensorMap.recon_order_to_map_order(np.where(refine.refinedmap.best_nuniq > min_unique, 0, -1))\n",
    "\n",
    "        # reshape the fancy strain map too\n",
    "        eps_sample = TensorMap.recon_order_to_map_order(refine.refinedmap.best_eps)\n",
    "\n",
    "        tmap = TensorMap.from_pbpmap(refine.refinedmap, steps=(1, ds.ystep, ds.ystep), phases=phases)\n",
    "        tmap['phase_ids'] = phase_ids\n",
    "        tmap['eps_sample'] = eps_sample\n",
    "        \n",
    "        tmap.get_ipf_maps()\n",
    "        eul = tmap.euler\n",
    "        \n",
    "        tmap.to_h5(os.path.join(ds.analysispath, 'pbp_tensormap_refined.h5'))\n",
    "        tmap.to_paraview(os.path.join(ds.analysispath, 'pbp_tensormap_refined.h5'))\n",
    "        ctf_path = os.path.join(ds.analysispath, 'pbp_tensormap_refined.ctf')\n",
    "        tmap.to_ctf_mtex(ctf_path, z_index=0)\n",
    "\n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
