{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc4bc96-cbc7-436a-a174-c99388869cbb",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 12/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831932fc-8a7f-4509-8042-47a8b542a68c",
   "metadata": {},
   "source": [
    "This notebook will try to perform a point-by-point strain refinement from your tomographic-derived grain shapes.  \n",
    "\n",
    "### NOTE: It is highly recommended to run this notebook on a Jupyter server with many cores and a lot of RAM.  \n",
    "The compute_origins() function in particular runs locally and can be compute-intensive for large datasets.  \n",
    "If this is a big scan (e.g 100 million + 2D peaks), you should definitely refine on the cluster rather than locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b89030-fdb2-47d2-bc26-3e5cfb0d6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b91e0-7a83-462b-85cb-27f65721ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import timeit\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib ipympl\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from xfab.symmetry import Umis\n",
    "\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms.tensor_map import TensorMap\n",
    "from ImageD11.sinograms.point_by_point import PBPRefine\n",
    "from ImageD11.peakselect import select_ring_peaks_by_intensity\n",
    "from ImageD11.sinograms import properties, roi_iradon\n",
    "from ImageD11.sinograms.sinogram import GrainSinogram, build_slice_arrays, write_slice_recon, read_slice_recon, write_h5, read_h5, write_pbp_strain\n",
    "from ImageD11.grain import grain\n",
    "from ImageD11 import cImageD11\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff052b-cca8-4310-8b29-4c82e0e513c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "   \n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b9af4-89a7-4dff-b258-cc2f77db5ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load phases from parameter file\n",
    "\n",
    "ds.phases = ds.get_phases_from_disk()\n",
    "ds.phases.unitcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722e04a-a23f-4af3-8530-a90874e27e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's select a phase to index from our parameters json\n",
    "phase_str = 'Si'\n",
    "\n",
    "ucell = ds.phases.unitcells[phase_str]\n",
    "\n",
    "print(ucell.lattice_parameters, ucell.spacegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2b143-ed90-4817-92ac-bd78dea2c73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 2D peaks\n",
    "\n",
    "cf_2d = ds.get_cf_2d()\n",
    "ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "print(f\"Read {cf_2d.nrows} 2D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf5dc8-a25d-4b09-b1d8-e55b1c6d07b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import grainsinos\n",
    "\n",
    "grainsinos = read_h5(ds.grainsfile, ds, phase_str)\n",
    "grains = [gs.grain for gs in grainsinos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ff57a-0a7f-44cd-b437-eb4cc4e2ea25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import slice reconstructions\n",
    "\n",
    "tensor_map = TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fef49-3c33-4d23-8f6e-8605b72f1b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_map.plot('phase_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08715524-4a8e-41bb-9d67-165523980f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a PBPMap from our TensorMap\n",
    "\n",
    "pmap = tensor_map.to_pbpmap(z_layer=0, default_npks=20, default_nuniq=20)\n",
    "# fills voxels that have grains with npks = 20 and nuniq = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33282e98-4e2c-4805-a2b2-468d6949e554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pmap.choose_best(1)\n",
    "pmap.plot_best(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8feef60-367b-478a-9ce4-8a94e3cedd60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a refinement manager object\n",
    "\n",
    "y0 = grainsinos[0].recon_y0\n",
    "hkl_tol_origins = 0.05\n",
    "hkl_tol_refine = 0.1\n",
    "hkl_tol_refine_merged = 0.05\n",
    "ds_tol = 0.004\n",
    "ifrac = 7e-3\n",
    "\n",
    "refine = PBPRefine(dset=ds, y0=y0, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fe817-5794-459b-9974-9d70624af3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tell it which point-by-point map we are refining\n",
    "\n",
    "refine.setmap(pmap)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372bfa0-4dfc-4727-a927-0d3b55c46875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the mask from minimum peak values\n",
    "# anything greater than 0 should be accepted\n",
    "\n",
    "refine.mask = pmap.best_npks > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ddf32-a6eb-46c5-8725-d1b400acc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate a single-valued map to refine on\n",
    "\n",
    "refine.setsingle(refine.pbpmap, minpeaks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c33da-97be-434a-b68a-05477814f42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose 2D peaks to refine with\n",
    "\n",
    "refine.setpeaks(cf_2d)\n",
    "\n",
    "# or load from disk:\n",
    "# refine.loadpeaks()\n",
    "\n",
    "refine.icolf.titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166325e-2716-492c-a39d-a0ea3b8680b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the peaks you selected\n",
    "\n",
    "refine.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5c297-a8b9-4d89-9f86-366cb7144adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute diffraction origins - these will be added as a column to refine.icolf\n",
    "# will then save the new column to disk to avoid re-computation\n",
    "\n",
    "refine.get_origins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde5eb5-ce0f-49b5-a6cb-4761f16cee32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the refinement\n",
    "# if compute_origins took more than a couple of minutes to run, I suggest setting use_cluster=True below\n",
    "# otherwise if you asked for lots of cores and RAM on this Jupyter instance, you can run it locally (use_cluster=False)\n",
    "\n",
    "use_cluster = True\n",
    "\n",
    "refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd5197-268c-48ab-b676-ac0c186b4533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save refinement results to disk\n",
    "\n",
    "if not use_cluster:\n",
    "    refine.to_h5()\n",
    "\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c559091-97bd-4b2d-9dc6-d99eb1b6e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f475c8-968b-48b6-9840-83ef517144ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our refinement parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(ds.dataroot, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_150um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        if os.path.exists(ds.refoutfile):\n",
    "            print(f\"Already have PBP refinement output file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        if not os.path.exists(ds.pbpfile):\n",
    "            print(f\"Can't find PBP indexing file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        cf_2d = ds.get_cf_2d()\n",
    "        ds.update_colfile_pars(cf_2d, phase_name=phase_str)\n",
    "\n",
    "        if not os.path.exists(ds.col2dfile):\n",
    "            ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)\n",
    "            \n",
    "        grainsinos = read_h5(ds.grainsfile, ds, phase_str)\n",
    "        y0 = grainsinos[0].recon_y0\n",
    "        \n",
    "        tensor_map = TensorMap.from_h5(ds.grainsfile, h5group='TensorMap_' + phase_str)\n",
    "        pmap = tensor_map.to_pbpmap(z_layer=0, default_npks=20, default_nuniq=20)\n",
    "        pmap.choose_best(1)\n",
    "\n",
    "        refine = PBPRefine(dset=ds, y0=y0, ybeam=ybeam, hkl_tol_origins=hkl_tol_origins, hkl_tol_refine=hkl_tol_refine, hkl_tol_refine_merged=hkl_tol_refine_merged, ds_tol=ds_tol, ifrac=ifrac, phase_name=phase_str)\n",
    "        \n",
    "        refine.setmap(pmap)\n",
    "        refine.setpeaks(cf_2d)\n",
    "        refine.mask = pmap.best_npks > 0\n",
    "        refine.setsingle(refine.pbpmap, minpeaks=1)\n",
    "        refine.get_origins()\n",
    "        refine.run_refine(use_cluster=use_cluster, pythonpath=PYTHONPATH)\n",
    "        if not use_cluster:\n",
    "            # wait to complete locally, then save\n",
    "            refine.to_h5()\n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebe56b-916c-4a57-a0ae-4471c09b80a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
