{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 21/02/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a bug with the current version of ImageD11 in the site-wide Jupyter env.\n",
    "# This has been fixed here: https://github.com/FABLE-3DXRD/ImageD11/commit/4af88b886b1775585e868f2339a0eb975401468f\n",
    "# Until a new release has been made and added to the env, we need to get the latest version of ImageD11 from GitHub\n",
    "# Put it in your home directory\n",
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "username = os.environ.get(\"USER\")\n",
    "\n",
    "id11_code_path = f\"/home/esrf/{username}/Code/ImageD11\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import glob, pprint\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib ipympl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import ImageD11.grain\n",
    "import ImageD11.indexing\n",
    "import ImageD11.columnfile\n",
    "from ImageD11.sinograms import properties, dataset\n",
    "\n",
    "from ImageD11.blobcorrector import eiger_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: For old datasets before the new directory layout structure, we don't distinguish between RAW_DATA and PROCESSED_DATA\n",
    "# In this case, use this cell to specify where your experimental folder is, and do not run the cell below\n",
    "# e.g /data/visitor/ma4752/id11/20210513\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/RAW_DATA\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "### USER: specify where you want your processed data to go\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240221\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR_nscope\"\n",
    "dataset = \"top_100um\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "\n",
    "# USER: specify the path to the parameter file\n",
    "\n",
    "par_path = os.path.join(processed_data_root_dir, 'Fe_refined.par')\n",
    "\n",
    "e2dx_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dx_E-08-0173_20231127.edf')\n",
    "e2dy_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dy_E-08-0173_20231127.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset from file\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we already have the 2D and 4D peaks, we could just load them from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cf_2d = ImageD11.columnfile.colfile_from_hdf(ds.col2dfile)\n",
    "# cf_2d.parameters.loadparameters(par_path)\n",
    "# cf_2d.updateGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cf_4d = ImageD11.columnfile.colfile_from_hdf(ds.col4dfile)\n",
    "# cf_4d.parameters.loadparameters(par_path)\n",
    "# cf_4d.updateGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherwise load them from the peaks table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 2D peaks, make a spatially corrected columnfile, save it\n",
    "\n",
    "peaks_table = ImageD11.sinograms.properties.pks_table.load(ds.pksfile)\n",
    "\n",
    "# Grab the 2d peak centroids\n",
    "peaks_2d = peaks_table.pk2d(ds.omega, ds.dty)\n",
    "cf_2d = utils.tocolf(peaks_2d, par_path, e2dx_path, e2dy_path)\n",
    "\n",
    "if os.path.exists(ds.col2dfile):\n",
    "    os.remove(ds.col2dfile)\n",
    "\n",
    "# save the 2D peaks to file so we don't have to spatially correct them again\n",
    "ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will now generate a cf (columnfile) object for the 4D peaks.\n",
    "# Will be corrected for detector spatial distortion\n",
    "\n",
    "peaks_4d = peaks_table.pk2dmerge(ds.omega, ds.dty)\n",
    "cf_4d = utils.tocolf(peaks_4d, par_path, e2dx_path, e2dy_path)  # spatial correction\n",
    "\n",
    "# uncomment below if you don't want spatial correction for some reason\n",
    "# cf_4d = ImageD11.columnfile.colfile_from_dict(peaks_4d)\n",
    "# cf_4d.addcolumn(cf_4d.s_raw, \"sc\")\n",
    "# cf_4d.addcolumn(cf_4d.f_raw, \"fc\")\n",
    "# cf_4d.parameters.loadparameters(par_path)\n",
    "# cf_4d.updateGeometry()\n",
    "\n",
    "# the first thing we should do is create an index column for our 4D peaks\n",
    "index_column = np.arange(cf_4d.nrows)\n",
    "cf_4d.addcolumn(index_column, 'index')\n",
    "\n",
    "# Delete the columnfile output file if it exists\n",
    "\n",
    "if os.path.exists(ds.col4dfile):\n",
    "    os.remove(ds.col4dfile)\n",
    "    \n",
    "# save the 4D peaks to file so we don't have to spatially correct them again\n",
    "ImageD11.columnfile.colfile_to_hdf(cf_4d, ds.col4dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a mask that selects only 4D peaks greater than 25 pixels in size\n",
    "\n",
    "m = cf_4d['Number_of_pixels'] > 25\n",
    "\n",
    "# then plot omega vs dty for all peaks - should look sinusoidal\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "counts, xedges, yedges, im = ax.hist2d(cf_4d['omega'][m], cf_4d['dty'][m], weights=np.sqrt(cf_4d['sum_intensity'][m]), bins=(ds.obinedges, ds.ybinedges), norm=matplotlib.colors.LogNorm())\n",
    "ax.set_xlabel(\"Omega angle\")\n",
    "ax.set_ylabel(\"dty\")\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the 4D peaks (fewer of them) as a cake (two-theta vs eta)\n",
    "# if the parameters in the par file are good, these should look like straight lines\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(cf_4d.ds, cf_4d.eta, s=1)\n",
    "\n",
    "ax.set_xlabel(\"dstar\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: export CF to an flt so we can play with it with ImageD11_gui\n",
    "# uncomment the below line\n",
    "\n",
    "# cf_4d.writefile(f'{sample}_{dataset}_4d_peaks.flt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are filtering our peaks (cf_4d) to select only the strongest ones for indexing purposes only!\n",
    "# dsmax is being set to limit rings given to the indexer - 6-8 rings is normally good\n",
    "\n",
    "# USER: modify the \"frac\" parameter below and re-run the cell until the orange dot sits nicely on the \"elbow\" of the blue line\n",
    "# this indicates the fractional intensity cutoff we will select\n",
    "# if the blue line does not look elbow-shaped in the logscale plot, try changing the \"doplot\" parameter (the y scale of the logscale plot) until it does\n",
    "\n",
    "cf_strong = utils.selectpeaks(cf_4d, frac=0.994, dsmax=1.4, doplot=0.95)\n",
    "print(cf_4d.nrows)\n",
    "print(cf_strong.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: export CF to an flt so we can play with it with ImageD11_gui\n",
    "# uncomment the below line\n",
    "\n",
    "# cf_strong.writefile(f'{sample}_{dataset}_strong_4d_peaks.flt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can take a look at the intensities of the remaining peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cf_strong.ds, cf_strong.sum_intensity,',')\n",
    "ax.semilogy()\n",
    "\n",
    "ax.set_xlabel(\"Dstar\")\n",
    "ax.set_ylabel(\"Intensity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can define a unit cell from our parameters\n",
    "\n",
    "Fe = ImageD11.unitcell.unitcell_from_parameters(cf_strong.parameters)\n",
    "Fe.makerings(cf_strong.ds.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's plot our peaks again, with the rings from the unitcell included, to check our lattice parameters are good\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "skip=1\n",
    "ax.plot( cf_strong.ds[::skip], cf_strong.eta[::skip],',',alpha=0.5)\n",
    "ax.plot( Fe.ringds, [0,]*len(Fe.ringds), '|', ms=90 )\n",
    "ax.set_xlabel('1 / d ($\\AA$)')\n",
    "ax.set_ylabel('$\\\\eta$ (deg)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify our ImageD11 indexer with these peaks\n",
    "# we're aiming to index around 3_000 to 10_000 peaks\n",
    "\n",
    "indexer = ImageD11.indexing.indexer_from_colfile(cf_strong)\n",
    "\n",
    "print(f\"Indexing {cf_strong.nrows} peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: set a tolerance in d-space (for assigning peaks to powder rings)\n",
    "\n",
    "indexer.ds_tol = 0.01\n",
    "\n",
    "# change the log level so we can see what the ring assigments look like\n",
    "\n",
    "ImageD11.indexing.loglevel = 1\n",
    "\n",
    "# assign peaks to powder rings\n",
    "\n",
    "indexer.assigntorings()\n",
    "\n",
    "# change log level back again\n",
    "\n",
    "ImageD11.indexing.loglevel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's plot the assigned peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# indexer.ra is the ring assignments\n",
    "\n",
    "ax.scatter(cf_strong.ds, cf_strong.eta, c=indexer.ra, cmap='tab20', s=1)\n",
    "ax.set_xlabel(\"d-star\")\n",
    "ax.set_ylabel(\"eta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we are indexing!\n",
    "# indexing will select all rings with a multiplicity below max_multiplity to search\n",
    "max_multiplicity = 11\n",
    "# the minimum number of peaks on a ring for a ring to be indexed on\n",
    "min_counts_on_ring = 0\n",
    "# the sequence of hkl tolerances the indexer will iterate through\n",
    "hkl_tols_seq = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1]\n",
    "# the sequence of minpks fractions the indexer will iterate through\n",
    "fracs = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "# the tolerance in g-vector angle\n",
    "cosine_tol = np.cos(np.radians(90.25))\n",
    "# the max number of UBIs we can find per pair of rings\n",
    "max_grains = 1000\n",
    "\n",
    "grains, indexer = utils.do_index(cf=cf_strong,\n",
    "                                dstol=indexer.ds_tol,\n",
    "                                max_mult=max_multiplicity,\n",
    "                                min_ring_count=min_counts_on_ring,\n",
    "                                hkl_tols=hkl_tols_seq,\n",
    "                                fracs=fracs,\n",
    "                                cosine_tol=cosine_tol,\n",
    "                                max_grains=max_grains\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set grain GIDs (useful if we ever delete a grain)\n",
    "for i, g in enumerate(grains):\n",
    "    g.gid = i\n",
    "    \n",
    "    g.a = np.cbrt(np.linalg.det(g.ubi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_unit_cell_lengths = [grain.a for grain in grains]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_unit_cell_lengths)\n",
    "ax.set_xlabel(\"Grain ID\")\n",
    "ax.set_ylabel(\"Unit cell length\")\n",
    "plt.show()\n",
    "\n",
    "a0 = np.median(mean_unit_cell_lengths)\n",
    "    \n",
    "print(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign peaks to grains\n",
    "\n",
    "tol = 0.05\n",
    "\n",
    "utils.assign_peaks_to_grains(grains, cf_strong, tol=tol)\n",
    "\n",
    "print(\"Storing peak data in grains\")\n",
    "# iterate through all the grains\n",
    "for g in tqdm(grains):\n",
    "    # store this grain's peak indices so we know which 4D peaks we used for indexing\n",
    "    g.mask_4d = cf_strong.grain_id == g.gid\n",
    "    g.peaks_4d = cf_strong.index[cf_strong.grain_id == g.gid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.plot_index_results(indexer, cf_strong, 'First attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.plot_grain_sinograms(grains, cf_strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = {'compression':'gzip',\n",
    "       'compression_opts': 2,\n",
    "       'shuffle' : True }\n",
    "\n",
    "def save_array(grp, name, ary):\n",
    "    hds = grp.require_dataset(name, \n",
    "                              shape=ary.shape,\n",
    "                              dtype=ary.dtype,\n",
    "                              **cmp)\n",
    "    hds[:] = ary\n",
    "    return hds\n",
    "\n",
    "def save_grains(grains, ds):\n",
    "    with h5py.File(ds.grainsfile, 'w') as hout:\n",
    "        grn = hout.create_group('grains')\n",
    "        for g in tqdm(grains):\n",
    "            gg = grn.create_group(str(g.gid))\n",
    "            save_array(gg, 'peaks_4d_indexing', g.peaks_4d).attrs['description'] = \"Strong 4D peaks that were assigned to this grain during indexing\"\n",
    "            gg.attrs.update({'ubi':g.ubi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save grain data\n",
    "\n",
    "save_grains(grains, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
