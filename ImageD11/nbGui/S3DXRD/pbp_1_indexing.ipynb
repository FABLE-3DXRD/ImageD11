{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "import ImageD11.sinograms.point_by_point\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.columnfile\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Pass path to dataset file\n",
    "\n",
    "dset_file = 'si_cube_test/processed/Si_cube/Si_cube_S3DXRD_nt_moves_dty/Si_cube_S3DXRD_nt_moves_dty_dataset.h5'\n",
    "\n",
    "ds = ImageD11.sinograms.dataset.load(dset_file)\n",
    "\n",
    "sample = ds.sample\n",
    "dataset = ds.dsname\n",
    "rawdata_path = ds.dataroot\n",
    "processed_data_root_dir = ds.analysisroot\n",
    "\n",
    "print(ds)\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This assumes you've only just segmented, so we need to add these things to the dataset:\n",
    "\n",
    "# USER: specify the path to the parameter file\n",
    "\n",
    "par_file = os.path.join(processed_data_root_dir, 'Si_refined.par')\n",
    "\n",
    "# add them to the dataset\n",
    "\n",
    "ds.parfile = par_file\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the 2D columnfile, or make it if it doesn't exist\n",
    "\n",
    "if os.path.exists(ds.col2dfile):\n",
    "    cf_2d = ds.get_cf_2d_from_disk()\n",
    "    cf_2d.parameters.loadparameters(ds.parfile)\n",
    "    cf_2d.updateGeometry()\n",
    "else:\n",
    "    cf_2d = ds.get_cf_2d()\n",
    "\n",
    "    # save the 2D peaks to file so we don't have to spatially correct them again\n",
    "    ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter the columnfile to discard weak peaks\n",
    "\n",
    "cf_2d.filter(cf_2d.Number_of_pixels > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pbp_object = ImageD11.sinograms.point_by_point.PBP(ds.parfile,\n",
    "                                                    ds,\n",
    "                                                    hkl_tol=0.025,\n",
    "                                                    fpks=0.9,\n",
    "                                                    ds_tol=0.005,\n",
    "                                                    etacut=0.1,\n",
    "                                                    ifrac=5e-3,\n",
    "                                                    cosine_tol=np.cos(np.radians(90 - ds.ostep)),\n",
    "                                                    y0=0.0,\n",
    "                                                    symmetry=\"cubic\",\n",
    "                                                    foridx=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "                                                    forgen=[0, 1, 4],\n",
    "                                                    uniqcut=0.85)\n",
    "\n",
    "pbp_object.setpeaks(cf_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pbp_object.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cluster = True\n",
    "\n",
    "if use_cluster:\n",
    "    bash_script_path = utils.prepare_pbp_bash(pbp_object, PYTHONPATH, 5)\n",
    "    utils.slurm_submit_and_wait(bash_script_path, 15)\n",
    "else:\n",
    "    pbp_object.point_by_point(ds.pbpfile, loglevel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(ds.dataroot, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "first_pbp_object = pbp_object\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(ds.analysisroot, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        if os.path.exists(ds.pbpfile):\n",
    "            print(f\"Already have PBP file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        ds.parfile = par_file\n",
    "        ds.save()\n",
    "        \n",
    "        if os.path.exists(ds.col2dfile):\n",
    "            cf_2d = ds.get_cf_2d_from_disk()\n",
    "            cf_2d.parameters.loadparameters(ds.parfile)\n",
    "            cf_2d.updateGeometry()\n",
    "        else:\n",
    "            cf_2d = ds.get_cf_2d()\n",
    "\n",
    "            # save the 2D peaks to file so we don't have to spatially correct them again\n",
    "            ImageD11.columnfile.colfile_to_hdf(cf_2d, ds.col2dfile)\n",
    "            \n",
    "        cf_2d.filter(cf_2d.Number_of_pixels > 10)\n",
    "        \n",
    "        pbp_object = ImageD11.sinograms.point_by_point.PBP(ds.parfile,\n",
    "                                                            ds,\n",
    "                                                            hkl_tol=first_pbp_object.hkl_tol,\n",
    "                                                            fpks=first_pbp_object.fpks,\n",
    "                                                            ds_tol=first_pbp_object.ds_tol,\n",
    "                                                            etacut=first_pbp_object.etacut,\n",
    "                                                            ifrac=first_pbp_object.ifrac,\n",
    "                                                            cosine_tol=first_pbp_object.cosine_tol,\n",
    "                                                            y0=first_pbp_object.y0,\n",
    "                                                            symmetry=first_pbp_object.symmetry,\n",
    "                                                            foridx=first_pbp_object.foridx,\n",
    "                                                            forgen=first_pbp_object.forgen,\n",
    "                                                            uniqcut=first_pbp_object.uniqcut)\n",
    "        \n",
    "        pbp_object.setpeaks(cf_2d)\n",
    "\n",
    "        if use_cluster:\n",
    "            bash_script_path = utils.prepare_pbp_bash(pbp_object, PYTHONPATH, 5)\n",
    "            utils.slurm_submit_and_wait(bash_script_path, 15)\n",
    "        else:\n",
    "            pbp_object.point_by_point(ds.pbpfile, loglevel=3)\n",
    "        \n",
    "        ds.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
