{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 26/02/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "home_dir = !echo $HOME\n",
    "home_dir = str(home_dir[0])\n",
    "\n",
    "# USER: You can change this location if you want\n",
    "\n",
    "id11_code_path = os.path.join(home_dir, \"Code/ImageD11\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import timeit\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "\n",
    "from skimage.feature import blob_log\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numba\n",
    "import pprint\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import ImageD11.nbGui.nb_utils as utils\n",
    "\n",
    "import ImageD11.refinegrains\n",
    "import ImageD11.columnfile\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.sinograms.roi_iradon\n",
    "from ImageD11.blobcorrector import eiger_spatial\n",
    "from ImageD11.grain import grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define our functions\n",
    "\n",
    "def read_grains_minor_phase(ds):\n",
    "    with h5py.File(ds.grainsfile_minor_phase, 'r') as hin:      \n",
    "        grains_group = 'grains'\n",
    "        \n",
    "        grains = []\n",
    "        for gid_string in tqdm(sorted(hin[grains_group].keys(), key=lambda x: int(x))):\n",
    "            gg = hin[grains_group][gid_string]\n",
    "            ubi = gg.attrs['ubi'][:]\n",
    "            g = ImageD11.grain.grain(ubi)\n",
    "            g.gid = int(gid_string)\n",
    "            g.peaks_4d = gg['peaks_4d_indexing'][:]\n",
    "            grains.append(g)\n",
    "    \n",
    "    return grains\n",
    "\n",
    "\n",
    "\n",
    "def read_grains_main_phase(ds):\n",
    "    with h5py.File(ds.grainsfile, 'r') as hin:      \n",
    "        grains_group = 'grains'\n",
    "        \n",
    "        grains = []\n",
    "        for gid_string in tqdm(sorted(hin[grains_group].keys(), key=lambda x: int(x))):\n",
    "            gg = hin[grains_group][gid_string]\n",
    "            ubi = gg.attrs['ubi'][:]\n",
    "\n",
    "            g = ImageD11.grain.grain(ubi)\n",
    "            g.gid = int(gid_string)\n",
    "            g.y0 = gg.attrs['y0'][()]\n",
    "            g.sample_mask = gg['circle_mask'][:]\n",
    "            g.recon = gg['recon'][:]\n",
    "            g.ssino = gg['ssino'][:]\n",
    "            grains.append(g)\n",
    "    \n",
    "    return grains\n",
    "\n",
    "\n",
    "def map_grain_from_peaks(g, flt, ds):\n",
    "    \"\"\"\n",
    "    Computes sinogram\n",
    "    flt is already the peaks for this grain\n",
    "    Returns angles, sino\n",
    "    \"\"\"   \n",
    "    NY = len(ds.ybincens)  # number of y translations\n",
    "    iy = np.round((flt.dty - ds.ybincens[0]) / (ds.ybincens[1]-ds.ybincens[0])).astype(int)  # flt column for y translation index\n",
    "\n",
    "    # The problem is to assign each spot to a place in the sinogram\n",
    "    hklmin = g.hkl_2d_strong.min(axis=1)  # Get minimum integer hkl (e.g -10, -9, -10)\n",
    "    dh = g.hkl_2d_strong - hklmin[:,np.newaxis]  # subtract minimum hkl from all integer hkls\n",
    "    de = (g.etasigns_2d_strong.astype(int) + 1)//2  # something signs related\n",
    "    #   4D array of h,k,l,+/-\n",
    "    # pkmsk is whether a peak has been observed with this HKL or not\n",
    "    pkmsk = np.zeros(list(dh.max(axis=1) + 1 )+[2,], int)  # make zeros-array the size of (max dh +1) and add another axis of length 2\n",
    "    pkmsk[ dh[0], dh[1], dh[2], de ] = 1  # we found these HKLs for this grain\n",
    "    #   sinogram row to hit\n",
    "    pkrow = np.cumsum(pkmsk.ravel()).reshape(pkmsk.shape) - 1  #\n",
    "    # counting where we hit an HKL position with a found peak\n",
    "    # e.g (-10, -9, -10) didn't get hit, but the next one did, so increment\n",
    "\n",
    "    npks = pkmsk.sum( )\n",
    "    destRow = pkrow[ dh[0], dh[1], dh[2], de ] \n",
    "    sino = np.zeros( ( npks, NY ), 'f' )\n",
    "    hits = np.zeros( ( npks, NY ), 'f' )\n",
    "    angs = np.zeros( ( npks, NY ), 'f' )\n",
    "    adr = destRow * NY + iy \n",
    "    # Just accumulate \n",
    "    sig = flt.sum_intensity\n",
    "    ImageD11.cImageD11.put_incr64( sino, adr, sig )\n",
    "    ImageD11.cImageD11.put_incr64( hits, adr, np.ones(len(de),dtype='f'))\n",
    "    ImageD11.cImageD11.put_incr64( angs, adr, flt.omega)\n",
    "    \n",
    "    sinoangles = angs.sum( axis = 1) / hits.sum( axis = 1 )\n",
    "    # Normalise:\n",
    "    sino = (sino.T/sino.max( axis=1 )).T\n",
    "    # Sort (cosmetic):\n",
    "    order = np.lexsort((np.arange(npks), sinoangles))\n",
    "    sinoangles = sinoangles[order]\n",
    "    ssino = sino[order].T\n",
    "    \n",
    "    return sinoangles, ssino, hits[order].T\n",
    "\n",
    "def do_sinos(g, hkltol=0.25):\n",
    "    flt = utils.tocolf({p:p2d[p][g.peaks_2d] for p in p2d}, par_path, dxfile=e2dx_path, dyfile=e2dy_path)  # convert it to a columnfile and spatially correct\n",
    "    \n",
    "    hkl_real = np.dot(g.ubi, (flt.gx, flt.gy, flt.gz))  # calculate hkl of all assigned peaks\n",
    "    hkl_int = np.round(hkl_real).astype(int) # round to nearest integer\n",
    "    dh = ((hkl_real - hkl_int)**2).sum(axis = 0)  # calculate square of difference\n",
    "\n",
    "    # g.dherrall = dh.mean()  # mean hkl error across all assigned peaks\n",
    "    # g.npksall = flt.nrows  # total number of assigned peaks\n",
    "    flt.filter(dh < hkltol*hkltol)  # filter all assigned peaks to be less than hkltol squared\n",
    "    hkl_real = np.dot(g.ubi, (flt.gx, flt.gy, flt.gz))  # recalculate error after filtration\n",
    "    hkl_int = np.round(hkl_real).astype(int)\n",
    "    dh = ((hkl_real - hkl_int)**2).sum(axis = 0)\n",
    "    # g.dherr = dh.mean()  # dherr is mean hkl error across assigned peaks after hkltol filtering\n",
    "    # g.npks = flt.nrows  # total number of assigned peaks after hkltol filtering\n",
    "    g.etasigns_2d_strong = np.sign(flt.eta)\n",
    "    g.hkl_2d_strong = hkl_int  # integer hkl of assigned peaks after hkltol filtering\n",
    "    g.sinoangles, g.ssino, g.hits = map_grain_from_peaks(g, flt, ds)\n",
    "    return i,g\n",
    "\n",
    "\n",
    "def run_iradon_id11(grain, pad=20, y0=0, workers=1, sample_mask=None, apply_halfmask=False, mask_central_zingers=False):\n",
    "    outsize = grain.ssino.shape[0] + pad\n",
    "    \n",
    "    if apply_halfmask:\n",
    "        halfmask = np.zeros_like(grain.ssino)\n",
    "\n",
    "        halfmask[:len(halfmask)//2-1, :] = 1\n",
    "        halfmask[len(halfmask)//2-1, :] = 0.5\n",
    "        \n",
    "        ssino_to_recon = grain.ssino * halfmask\n",
    "    else:\n",
    "        ssino_to_recon = grain.ssino\n",
    "        \n",
    "    # # pad the sample mask\n",
    "    # sample_mask_padded = np.pad(sample_mask, pad//2)\n",
    "\n",
    "    \n",
    "    # Perform iradon transform of grain sinogram, store result (reconstructed grain shape) in g.recon\n",
    "    grain.recon = ImageD11.sinograms.roi_iradon.iradon(ssino_to_recon, \n",
    "                                                       theta=grain.sinoangles, \n",
    "                                                       mask=sample_mask,\n",
    "                                                       output_size=outsize,\n",
    "                                                       projection_shifts=np.full(grain.ssino.shape, -y0),\n",
    "                                                       filter_name='hamming',\n",
    "                                                       interpolation='linear',\n",
    "                                                       workers=workers)\n",
    "    \n",
    "    if mask_central_zingers:\n",
    "        grs = grain.recon.shape[0]\n",
    "        xpr, ypr = -grs//2 + np.mgrid[:grs, :grs]\n",
    "        inner_mask_radius = 25\n",
    "        outer_mask_radius = inner_mask_radius + 2\n",
    "\n",
    "        inner_circle_mask = (xpr ** 2 + ypr ** 2) < inner_mask_radius ** 2\n",
    "        outer_circle_mask = (xpr ** 2 + ypr ** 2) < outer_mask_radius ** 2\n",
    "\n",
    "        mask_ring = inner_circle_mask & outer_circle_mask\n",
    "        # we now have a mask to apply\n",
    "        fill_value = np.median(grain.recon[mask_ring])\n",
    "        grain.recon[inner_circle_mask] = fill_value\n",
    "    \n",
    "    return grain\n",
    "\n",
    "\n",
    "def find_cens_from_recon(grain):\n",
    "    grain.bad_recon = False\n",
    "    blobs = blob_log(grain.recon, min_sigma=1, max_sigma=10, num_sigma=10, threshold=.01)\n",
    "    blobs_sorted = sorted(blobs, key=lambda x: x[2], reverse=True)\n",
    "    try:\n",
    "        largest_blob = blobs_sorted[0]\n",
    "        \n",
    "        # we now have the blob position in recon space\n",
    "        # we need to go back to microns\n",
    "        \n",
    "        # first axis (vertical) is x\n",
    "        # second axis (horizontal) is y\n",
    "        \n",
    "        x_recon_space = largest_blob[0]\n",
    "        y_recon_space = largest_blob[1]\n",
    "        \n",
    "        # centre of the recon image is centre of space\n",
    "        \n",
    "        x_microns = (x_recon_space - grain.recon.shape[0]//2) * ds.ystep + y0\n",
    "        y_microns = -(y_recon_space - grain.recon.shape[1]//2) * ds.ystep + y0\n",
    "        \n",
    "        grain.x_blob = x_microns\n",
    "        grain.y_blob = y_microns\n",
    "    except IndexError:\n",
    "        # didn't find any blobs\n",
    "        # for small grains like these, if we didn't find a blob, normally indicates recon is bad\n",
    "        # we will exclude it from maps and export\n",
    "        grain.bad_recon = True\n",
    "\n",
    "        \n",
    "cmp = {'compression':'gzip',\n",
    "'compression_opts': 2,\n",
    "'shuffle' : True }\n",
    "\n",
    "def save_array(grp, name, ary):\n",
    "    hds = grp.require_dataset(name, \n",
    "                              shape=ary.shape,\n",
    "                              dtype=ary.dtype,\n",
    "                              **cmp)\n",
    "    hds[:] = ary\n",
    "    return hds\n",
    "\n",
    "def save_grains_minor_phase(grains, ds):\n",
    "\n",
    "    # delete existing file, because our grain numbers have changed\n",
    "    if os.path.exists(ds.grainsfile_minor_phase):\n",
    "        os.remove(ds.grainsfile_minor_phase)\n",
    "    \n",
    "    with h5py.File(ds.grainsfile_minor_phase, 'w-') as hout:  # fail if exists\n",
    "        try:\n",
    "            grp = hout.create_group('peak_assignments')\n",
    "        except ValueError:\n",
    "            grp = hout['peak_assignments']\n",
    "\n",
    "        ds_gord = save_array( grp, 'gord', gord )\n",
    "        ds_gord.attrs['description'] = 'Grain ordering: g[i].pks = gord[ inds[i] : inds[i+1] ]'\n",
    "        ds_inds = save_array( grp, 'inds', inds )\n",
    "        ds_inds.attrs['description'] = 'Grain indices: g[i].pks = gord[ inds[i] : inds[i+1] ]'\n",
    "        \n",
    "        try:\n",
    "            grp = hout.create_group('slice_recon')\n",
    "        except ValueError:\n",
    "            grp = hout['slice_recon']\n",
    "        save_array(grp, 'intensity', raw_intensity_array).attrs['description'] = 'Raw intensity array for all grains'\n",
    "        save_array(grp, 'labels', grain_labels_array).attrs['description'] = 'Grain labels array for all grains'\n",
    "        \n",
    "        ipfxdset = save_array(grp, 'ipf_x_col_map', rgb_x_array)\n",
    "        ipfxdset.attrs['description'] = 'IPF X color at each pixel'\n",
    "        ipfxdset.attrs['CLASS'] = 'IMAGE'\n",
    "        ipfydset = save_array(grp, 'ipf_y_col_map', rgb_y_array)\n",
    "        ipfydset.attrs['description'] = 'IPF Y color at each pixel'\n",
    "        ipfydset.attrs['CLASS'] = 'IMAGE'\n",
    "        ipfzdset = save_array(grp, 'ipf_z_col_map', rgb_z_array)\n",
    "        ipfzdset.attrs['description'] = 'IPF Z color at each pixel'\n",
    "        ipfzdset.attrs['CLASS'] = 'IMAGE'\n",
    "        \n",
    "        grains_group = hout.create_group('grains')\n",
    "        for g in tqdm(grains):\n",
    "            gg = grains_group.create_group(str(g.gid))\n",
    "            # save stuff for sinograms\n",
    "            \n",
    "            gg.attrs.update({'ubi':g.ubi})\n",
    "            \n",
    "            save_array(gg, 'peaks_4d_indexing', g.peaks_4d).attrs['description'] = \"Strong 4D peaks that were assigned to this grain during indexing\"\n",
    "            \n",
    "            save_array(gg, 'ssino', g.ssino).attrs['description'] = 'Sinogram of peak intensities sorted by omega'\n",
    "            save_array(gg, 'sinoangles', g.sinoangles).attrs['description'] = 'Projection angles for sinogram'\n",
    "            save_array(gg, 'og_recon', g.recon).attrs['description'] = 'Original ID11 iRadon reconstruction'\n",
    "            save_array(gg, 'recon', g.recon).attrs['description'] = 'Final reconstruction'\n",
    "            save_array(gg, 'circle_mask', whole_sample_mask).attrs['description'] = 'Reconstruction mask to use for MLEM'\n",
    "            \n",
    "            # might as well save peaks stuff while we're here\n",
    "            save_array(gg, 'translation', g.translation).attrs['description'] = 'Grain translation in lab frame'\n",
    "            save_array(gg, 'peaks_2d_sinograms', g.peaks_2d).attrs['description'] = \"2D peaks from strong 4D peaks that were assigned to this grain for sinograms\"\n",
    "            save_array(gg, 'peaks_4d_sinograms', g.peaks_4d).attrs['description'] = \"Strong 4D peaks that were assigned to this grain for sinograms\"\n",
    "\n",
    "            gg.attrs['cen'] = g.cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: For old datasets before the new directory layout structure, we don't distinguish between RAW_DATA and PROCESSED_DATA\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/RAW_DATA\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "### USER: specify where you want your processed data to go\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ihma439/id11/20231211/PROCESSED_DATA/James/20240226\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"FeAu_0p5_tR_nscope\"\n",
    "dataset = \"top_250um\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "\n",
    "par_path = os.path.join(processed_data_root_dir, 'Fe_refined.par')\n",
    "\n",
    "e2dx_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dx_E-08-0173_20231127.edf')\n",
    "e2dy_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dy_E-08-0173_20231127.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset (for motor positions, not sure why these are not in peaks)\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine ring currents for sinogram row-by-row intensity correction\n",
    "\n",
    "utils.get_ring_current_per_scan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 4D peaks\n",
    "\n",
    "cf_4d = ImageD11.columnfile.columnfile(ds.col4dfile)\n",
    "\n",
    "cf_4d.parameters.loadparameters(par_path)\n",
    "cf_4d.updateGeometry()\n",
    "\n",
    "print(f\"Read {cf_4d.nrows} 4D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_name = \"Au\"\n",
    "\n",
    "ds.grainsfile_minor_phase = os.path.join(ds.analysispath, ds.dsname + f'_grains_{phase_name}.h5')\n",
    "\n",
    "grains = read_grains_minor_phase(ds)\n",
    "\n",
    "for grain in grains:\n",
    "    # print(grain.gid)\n",
    "    grain.a = np.cbrt(np.linalg.det(grain.ubi))\n",
    "    \n",
    "print(f\"{len(grains)} grains imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isolate main phase peaks, and remove them from the dataset\n",
    "main_phase_peaks_mask = utils.unitcell_peaks_mask(cf_4d, dstol=0.0075, dsmax=cf_4d.ds.max())\n",
    "\n",
    "minor_phase_peaks = cf_4d.copy()\n",
    "minor_phase_peaks.filter(~main_phase_peaks_mask)\n",
    "\n",
    "# Update geometry for minor phase peaks\n",
    "\n",
    "par_path = os.path.join(processed_data_root_dir, 'Au.par')\n",
    "minor_phase_peaks.parameters.loadparameters(par_path)\n",
    "minor_phase_peaks.updateGeometry()\n",
    "\n",
    "cf_strong = utils.selectpeaks(minor_phase_peaks, dstol=0.005, dsmax=minor_phase_peaks.ds.max(), frac=0.9, doplot=0.01)\n",
    "print(cf_strong.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the sinograms are only half-sinograms (we scanned dty across half the sample rather than the full sample), set the below to true:\n",
    "is_half_scan = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_half_scan:\n",
    "    utils.correct_half_scan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load major phase grain reconstruction\n",
    "# for pad and y0\n",
    "\n",
    "major_phase_grains = read_grains_main_phase(ds)\n",
    "whole_sample_mask = major_phase_grains[0].sample_mask\n",
    "y0 = major_phase_grains[0].y0\n",
    "\n",
    "pad = ((major_phase_grains[0].recon.shape[0] - major_phase_grains[0].ssino.shape[0]))\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tol = 0.25\n",
    "\n",
    "utils.assign_peaks_to_grains(grains, cf_strong, tol=tol)\n",
    "\n",
    "print(\"Storing peak data in grains\")\n",
    "# iterate through all the grains\n",
    "for g in tqdm(grains):\n",
    "    # store this grain's peak indices so we know which 4D peaks we used for sinograms\n",
    "    g.mask_4d = cf_strong.grain_id == g.gid\n",
    "    g.peaks_4d = cf_strong.index[g.mask_4d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "m = cf_strong.grain_id >= 0\n",
    "ax.scatter(cf_strong.omega[m], cf_strong.dty[m], c=cf_strong.grain_id[m])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_unit_cell_lengths = [grain.a for grain in grains]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_unit_cell_lengths)\n",
    "ax.set_xlabel(\"Grain ID\")\n",
    "ax.set_ylabel(\"Unit cell length\")\n",
    "plt.show()\n",
    "\n",
    "a0 = np.median(mean_unit_cell_lengths)\n",
    "    \n",
    "print(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.plot_grain_sinograms(grains, cf_strong, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for grain in tqdm(grains):\n",
    "    # grain.peaks_4d_selected, grain.cen, grain.dx, grain.dy = utils.graincen(grain.gid, cf_strong, doplot=False)\n",
    "    grain.rgb_z = utils.grain_to_rgb(grain, ax=(0,0,1),)# symmetry = Symmetry.cubic)\n",
    "    grain.rgb_y = utils.grain_to_rgb(grain, ax=(0,1,0),)# symmetry = Symmetry.cubic)\n",
    "    grain.rgb_x = utils.grain_to_rgb(grain, ax=(1,0,0),)# symmetry = Symmetry.cubic)\n",
    "    utils.fit_grain_position_from_sino(grain, cf_strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure we get cen right (centre of rotation should be the middle of dty)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([g.cen for g in grains])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c0 = np.median([g.cen for g in grains])\n",
    "\n",
    "print('Center of rotation in dty', c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.dy for g in grains]\n",
    "y = [g.dx for g in grains]\n",
    "s = [g.mask_4d.sum()/10 for g in grains]\n",
    "a[0].scatter(x, y, c=[g.rgb_z for g in grains], s=s)\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(x, y, c=[g.rgb_y for g in grains], s=s)\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(x, y, c=[g.rgb_x for g in grains], s=s)\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(x, y, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"Lab y (transverse)\")\n",
    "fig.supylabel(\"Lab x (beam)\")\n",
    "\n",
    "for a in ax.ravel():\n",
    "    a.invert_xaxis()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate translations of grains\n",
    "for g in grains:\n",
    "    g.translation = np.array([g.dx, g.dy, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Big scary block\n",
    "# Must understand what this does!\n",
    "\n",
    "# Ensure cf is sorted by spot3d_id\n",
    "# NOTE: spot3d_id should be spot4d_id, because we have merged into 4D?\n",
    "assert (np.argsort(cf_strong.spot3d_id) == np.arange(cf_strong.nrows)).all()\n",
    "\n",
    "# load the 2d peak labelling output\n",
    "pks = ImageD11.sinograms.properties.pks_table.load(ds.pksfile)\n",
    "\n",
    "# Grab the 2d peak centroids\n",
    "p2d = pks.pk2d(ds.omega, ds.dty)\n",
    "\n",
    "# NOTE: These are not spatially corrected?!\n",
    "\n",
    "numba_order, numba_histo = utils.counting_sort(p2d['spot3d_id'])\n",
    "\n",
    "grain_2d_id = utils.palloc(p2d['spot3d_id'].shape, np.dtype(int))\n",
    "\n",
    "cleanid = cf_strong.grain_id.copy()\n",
    "\n",
    "utils.find_grain_id(cf_strong.spot3d_id, cleanid, p2d['spot3d_id'], grain_2d_id, numba_order)\n",
    "\n",
    "gord, counts = utils.counting_sort(grain_2d_id)\n",
    "\n",
    "inds = np.concatenate(((0,), np.cumsum(counts)))\n",
    "\n",
    "# I think what we end up with is:\n",
    "# inds\n",
    "# this is an array which tells you which 2D spots each grain owns\n",
    "# the 2D spots are sorted by spot ID\n",
    "# inds tells you for each grain were you can find its associated 2D spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now our 2D peak assignments are known, let's populate our grain objects with our 2D peaks\n",
    "\n",
    "for grain in tqdm(grains):\n",
    "    i = grain.gid\n",
    "    grain.peaks_2d = gord[inds[i+1] : inds[i+2]]\n",
    "    # grain.mask_2d = np.isin(cf_2d.index, grain.peaks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine sinograms of all grains\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1,nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(do_sinos, grains), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can optionally correct the grain sinograms by scaling each row by the ring current:\n",
    "\n",
    "for grain in tqdm(grains):\n",
    "    utils.correct_sinogram_rows_with_ring_current(grain, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "g = grains[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow((g.ssino/g.ssino.mean(axis=0)), norm=matplotlib.colors.LogNorm(), interpolation='nearest', origin=\"lower\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can pick a grain and investigate the effects of changing y0 that gets passed to iradon\n",
    "# it' best to pick the grain AFTER reconstructing all grains, so you can pick a grain of interest\n",
    "\n",
    "g = grains[5]\n",
    "    \n",
    "vals = np.linspace(-8.5, -7.5, 9)\n",
    "\n",
    "grid_size = np.ceil(np.sqrt(len(vals))).astype(int)\n",
    "nrows = (len(vals)+grid_size-1)//grid_size\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, nrows, sharex=True, sharey=True)\n",
    "\n",
    "for inc, val in enumerate(tqdm(vals)):\n",
    "    run_iradon_id11(g, y0=val)\n",
    "    # crop = g.recon[200:240, 230:290]\n",
    "    crop = g.recon\n",
    "    \n",
    "    axs.ravel()[inc].imshow(crop, origin=\"lower\", vmin=0)\n",
    "    axs.ravel()[inc].set_title(val)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can overwrite y0 here\n",
    "\n",
    "# y0 = -7.875\n",
    "# pad = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "run_this_iradon = partial(run_iradon_id11, pad=pad, y0=y0, sample_mask=whole_sample_mask, workers=1, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor( max_workers= max(1,nthreads-1) ) as pool:\n",
    "    for i in tqdm(pool.map(run_this_iradon, grains), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "%matplotlib ipympl\n",
    "\n",
    "fig, a = plt.subplots(1,2,figsize=(10,5))\n",
    "rec = a[0].imshow(grains[8].recon, vmin=0, origin=\"lower\")\n",
    "sin = a[1].imshow(grains[8].ssino, aspect='auto')\n",
    "\n",
    "# Function to update the displayed image based on the selected frame\n",
    "def update_frame(i):\n",
    "    rec.set_array(grains[i].recon)\n",
    "    sin.set_array(grains[i].ssino)\n",
    "    a[0].set(title=str(grains[i].gid))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# Create a slider widget to select the frame number\n",
    "frame_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(grains) - 1,\n",
    "    step=1,\n",
    "    description='Grain:'\n",
    ")\n",
    "\n",
    "interact(update_frame, i=frame_slider)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1, nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(find_cens_from_recon, grains), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove bad recon grains from future analysis\n",
    "print(f\"{len(grains)} grains before filtration\")\n",
    "grains = [grain for grain in grains if not grain.bad_recon]\n",
    "print(f\"{len(grains)} grains after filtration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for g in grains:\n",
    "    g.translation = np.array([g.x_blob, -g.y_blob, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.translation[1] for g in grains]\n",
    "y = [g.translation[0] for g in grains]\n",
    "s = [g.mask_4d.sum()/10 for g in grains]\n",
    "a[0].scatter(x, y, c=[g.rgb_z for g in grains], s=s)\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(x, y, c=[g.rgb_y for g in grains], s=s)\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(x, y, c=[g.rgb_x for g in grains], s=s)\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(x, y, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"Lab y (transverse)\")\n",
    "fig.supylabel(\"Lab x (beam)\")\n",
    "\n",
    "for a in ax.ravel():\n",
    "    a.invert_xaxis()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots( 1,3, figsize=(15,5) )\n",
    "ty, tx = utils.triangle().T\n",
    "for i,title in enumerate( 'xyz' ):\n",
    "    ax = np.zeros(3)\n",
    "    ax[i] = 1.\n",
    "    hkl = [utils.crystal_direction_cubic( g.ubi, ax ) for g in grains]\n",
    "    xy = np.array([utils.hkl_to_pf_cubic(h) for h in hkl ])\n",
    "    rgb = np.array([utils.hkl_to_color_cubic(h) for h in hkl ])\n",
    "    for j in range(len(grains)):\n",
    "        grains[j].rgb = rgb[j]\n",
    "    a[i].scatter( xy[:,1], xy[:,0], c = rgb )   # Note the \"x\" axis of the plot is the 'k' direction and 'y' is h (smaller)\n",
    "    a[i].set(title=title, aspect='equal', facecolor='silver', xticks=[], yticks=[])\n",
    "    a[i].plot( tx, ty, 'k-', lw = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = utils.build_slice_arrays(grains, cutoff_level=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot initial output\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(rgb_z_array, origin=\"lower\")  # originally 1,2,0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(grain_labels_array, origin=\"lower\")  # originally 1,2,0\n",
    "ax.set_title(\"Grain label map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(raw_intensity_array, origin=\"lower\")  # originally 1,2,0\n",
    "ax.set_title(\"Raw intensity array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels, counts = np.unique(grain_labels_array, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(labels[labels > 0], counts[labels > 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter out grains with more than 25 pixels in the label map\n",
    "# this normally indicates a dodgy reconstruction for this grain\n",
    "# only really applies if the grains are very small!\n",
    "\n",
    "bad_gids = [int(label) for (label, count) in zip(labels, counts) if count > 25 and label > 0]\n",
    "bad_gids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{len(grains)} grains before filtration\")\n",
    "grains = [grain for grain in grains if grain.gid not in bad_gids]\n",
    "print(f\"{len(grains)} grains after filtration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = utils.build_slice_arrays(grains, cutoff_level=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot initial output\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(rgb_z_array, origin=\"lower\")  # originally 1,2,0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(grain_labels_array, origin=\"lower\")  # originally 1,2,0\n",
    "ax.set_title(\"Grain label map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(raw_intensity_array, origin=\"lower\")  # originally 1,2,0\n",
    "ax.set_title(\"Raw intensity array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write grains to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_grains_minor_phase(grains, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    raise ValueError(\"Change the 1 above to 0 to allow 'Run all cells' in the notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we're happy with our indexing parameters, we can run the below cell to do this in bulk for many samples/datasets\n",
    "# by default this will do all samples in sample_list, all datasets with a prefix of dset_prefix\n",
    "# you can add samples and datasets to skip in skips_dict\n",
    "\n",
    "skips_dict = {\n",
    "    \"FeAu_0p5_tR_nscope\": [\"top_-50um\", \"top_-100um\"]\n",
    "}\n",
    "\n",
    "dset_prefix = \"top\"\n",
    "\n",
    "sample_list = [\"FeAu_0p5_tR_nscope\"]\n",
    "    \n",
    "samples_dict = utils.find_datasets_to_process(rawdata_path, skips_dict, dset_prefix, sample_list)\n",
    "    \n",
    "# manual override:\n",
    "# samples_dict = {\"FeAu_0p5_tR_nscope\": [\"top_100um\", \"top_200um\"]}\n",
    "    \n",
    "# now we have our samples_dict, we can process our data:\n",
    "\n",
    "par_path = os.path.join(processed_data_root_dir, 'Fe_refined.par')\n",
    "minor_phase_par_path = os.path.join(processed_data_root_dir, 'Au.par')\n",
    "\n",
    "e2dx_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dx_E-08-0173_20231127.edf')\n",
    "e2dy_path = os.path.join(processed_data_root_dir, '../../CeO2/e2dy_E-08-0173_20231127.edf')\n",
    "\n",
    "main_phase_cf_dstol = 0.0075\n",
    "phase_name = \"Au\"\n",
    "\n",
    "cf_strong_frac = 0.9\n",
    "cf_strong_dstol = 0.005\n",
    "\n",
    "is_half_scan = False\n",
    "correct_sinos_with_ring_current = True\n",
    "\n",
    "peak_assign_tol = 0.25\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "# pad = 50\n",
    "\n",
    "cutoff_level = 0.7\n",
    "\n",
    "grain_too_many_px = 22\n",
    "\n",
    "for sample, datasets in samples_dict.items():\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing dataset {dataset} in sample {sample}\")\n",
    "        dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "        if not os.path.exists(dset_path):\n",
    "            print(f\"Missing DataSet file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(\"Importing DataSet object\")\n",
    "        \n",
    "        ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "        print(f\"I have a DataSet {ds.dset} in sample {ds.sample}\")\n",
    "        \n",
    "        ds.grainsfile_minor_phase = os.path.join(ds.analysispath, ds.dsname + f'_grains_{phase_name}.h5')\n",
    "        \n",
    "        if not os.path.exists(ds.grainsfile_minor_phase):\n",
    "            print(f\"Missing grains file for {dataset} in sample {sample}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        # check grains file for existance of slice_recon, skip if it's there\n",
    "        with h5py.File(ds.grainsfile_minor_phase, \"r\") as hin:\n",
    "            if \"slice_recon\" in hin.keys():\n",
    "                print(f\"Already reconstructed {dataset} in {sample}, skipping\")\n",
    "                continue\n",
    "        \n",
    "        # determine ring currents for sinogram row-by-row intensity correction\n",
    "        utils.get_ring_current_per_scan(ds)\n",
    "            \n",
    "        cf_4d = ImageD11.columnfile.columnfile(ds.col4dfile)\n",
    "        cf_4d.parameters.loadparameters(par_path)\n",
    "        cf_4d.updateGeometry()\n",
    "        \n",
    "        grains = read_grains_minor_phase(ds)\n",
    "        \n",
    "        main_phase_peaks_mask = utils.unitcell_peaks_mask(cf_4d, dstol=main_phase_cf_dstol, dsmax=cf_4d.ds.max())\n",
    "\n",
    "        minor_phase_peaks = cf_4d.copy()\n",
    "        minor_phase_peaks.filter(~main_phase_peaks_mask)\n",
    "\n",
    "        # Update geometry for minor phase peaks\n",
    "\n",
    "        minor_phase_peaks.parameters.loadparameters(minor_phase_par_path)\n",
    "        minor_phase_peaks.updateGeometry()\n",
    "        \n",
    "        cf_strong = utils.selectpeaks(minor_phase_peaks, frac=cf_strong_frac, dsmax=cf_4d.ds.max(), dstol=cf_strong_dstol)\n",
    "        \n",
    "        if is_half_scan:\n",
    "            utils.correct_half_scan(ds)\n",
    "        \n",
    "        main_phase_grains = read_grains_main_phase(ds)\n",
    "        whole_sample_mask = main_phase_grains[0].sample_mask\n",
    "        y0 = main_phase_grains[0].y0\n",
    "        pad = ((main_phase_grains[0].recon.shape[0] - main_phase_grains[0].ssino.shape[0]))\n",
    "            \n",
    "        utils.assign_peaks_to_grains(grains, cf_strong, tol=peak_assign_tol)\n",
    "        \n",
    "        for g in tqdm(grains):\n",
    "            g.mask_4d = cf_strong.grain_id == g.gid\n",
    "            g.peaks_4d = cf_strong.index[g.mask_4d]\n",
    "            \n",
    "        for grain in tqdm(grains):\n",
    "            # grain.peaks_4d_selected, grain.cen, grain.dx, grain.dy = utils.graincen(grain.gid, cf_strong, doplot=False)\n",
    "            grain.rgb_z = utils.grain_to_rgb(grain, ax=(0,0,1),)# symmetry = Symmetry.cubic)\n",
    "            grain.rgb_y = utils.grain_to_rgb(grain, ax=(0,1,0),)# symmetry = Symmetry.cubic)\n",
    "            grain.rgb_x = utils.grain_to_rgb(grain, ax=(1,0,0),)# symmetry = Symmetry.cubic)\n",
    "            utils.fit_grain_position_from_sino(grain, cf_strong)\n",
    "            \n",
    "        c0 = np.median([g.cen for g in grains])\n",
    "        \n",
    "        for g in grains:\n",
    "            g.translation = np.array([g.dx, g.dy, 0])\n",
    "        \n",
    "        print(\"Peak 2D organise\")\n",
    "        pks = ImageD11.sinograms.properties.pks_table.load(ds.pksfile)\n",
    "        p2d = pks.pk2d(ds.omega, ds.dty)\n",
    "        numba_order, numba_histo = utils.counting_sort(p2d['spot3d_id'])\n",
    "        grain_2d_id = utils.palloc(p2d['spot3d_id'].shape, np.dtype(int))\n",
    "        cleanid = cf_strong.grain_id.copy()\n",
    "        utils.find_grain_id(cf_strong.spot3d_id, cleanid, p2d['spot3d_id'], grain_2d_id, numba_order)\n",
    "        gord, counts = utils.counting_sort(grain_2d_id)\n",
    "        inds = np.concatenate(((0,), np.cumsum(counts)))\n",
    "        \n",
    "        for grain in tqdm(grains):\n",
    "            i = grain.gid\n",
    "            grain.peaks_2d = gord[inds[i+1] : inds[i+2]]\n",
    "        \n",
    "        print(\"Making sinograms\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers= max(1,nthreads-1)) as pool:\n",
    "            for i in tqdm(pool.map(do_sinos, grains), total=len(grains)):\n",
    "                pass\n",
    "        \n",
    "        if correct_sinos_with_ring_current:\n",
    "            for grain in tqdm(grains):\n",
    "                utils.correct_sinogram_rows_with_ring_current(grain, ds)\n",
    "        \n",
    "        print(\"Running iradon\")\n",
    "        \n",
    "        run_this_iradon = partial(run_iradon_id11, pad=pad, y0=y0, sample_mask=whole_sample_mask, workers=1, apply_halfmask=is_half_scan, mask_central_zingers=is_half_scan)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor( max_workers= max(1,nthreads-1) ) as pool:\n",
    "            for i in tqdm(pool.map(run_this_iradon, grains), total=len(grains)):\n",
    "                pass\n",
    "            \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers= max(1, nthreads-1)) as pool:\n",
    "            for i in tqdm(pool.map(find_cens_from_recon, grains), total=len(grains)):\n",
    "                pass\n",
    "        \n",
    "        grains = [grain for grain in grains if not grain.bad_recon]\n",
    "        \n",
    "        for g in grains:\n",
    "            g.translation = np.array([g.x_blob, -g.y_blob, 0])\n",
    "            \n",
    "        rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = utils.build_slice_arrays(grains, cutoff_level)\n",
    "        \n",
    "        labels, counts = np.unique(grain_labels_array, return_counts=True)\n",
    "        bad_gids = [int(label) for (label, count) in zip(labels, counts) if count > grain_too_many_px and label > 0]\n",
    "        \n",
    "        grains = [grain for grain in grains if grain.gid not in bad_gids]\n",
    "        \n",
    "        rgb_x_array, rgb_y_array, rgb_z_array, grain_labels_array, raw_intensity_array = utils.build_slice_arrays(grains, cutoff_level)\n",
    "        \n",
    "        save_grains_minor_phase(grains, ds)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
