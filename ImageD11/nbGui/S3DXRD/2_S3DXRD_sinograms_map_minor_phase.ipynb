{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook based on ImageD11 to process scanning 3DXRD data\n",
    "# Written by Haixing Fang, Jon Wright and James Ball\n",
    "## Date: 19/02/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a bug with the current version of ImageD11 in the site-wide Jupyter env.\n",
    "# This has been fixed here: https://github.com/FABLE-3DXRD/ImageD11/commit/4af88b886b1775585e868f2339a0eb975401468f\n",
    "# Until a new release has been made and added to the env, we need to get the latest version of ImageD11 from GitHub\n",
    "# Put it in your home directory\n",
    "# USER: Change the path below to point to your local copy of ImageD11:\n",
    "\n",
    "import os\n",
    "\n",
    "username = os.environ.get(\"USER\")\n",
    "\n",
    "id11_code_path = f\"/home/esrf/{username}/Code/ImageD11\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, id11_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions we need\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import timeit\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import numba\n",
    "import pprint\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "import ImageD11.refinegrains\n",
    "import ImageD11.columnfile\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.sinograms.roi_iradon\n",
    "from ImageD11.blobcorrector import eiger_spatial\n",
    "from ImageD11.grain import grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OLD DATASETS\n",
    "\n",
    "# NOTE: For old datasets before the new directory layout structure, we don't distinguish between RAW_DATA and PROCESSED_DATA\n",
    "# In this case, use this cell to specify where your experimental folder is, and do not run the cell below\n",
    "# e.g /data/visitor/4752/id11/20210513\n",
    "\n",
    "### USER: specify your experimental directory\n",
    "\n",
    "rawdata_path = \"/home/esrf/james1997a/Data/ma4752/id11/20210618\"\n",
    "\n",
    "!ls -lrt {rawdata_path}\n",
    "\n",
    "### USER: specify where you want your processed data to go\n",
    "\n",
    "processed_data_root_dir = \"/home/esrf/james1997a/Data/ma4752/id11/20240118/James\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER: pick a sample and a dataset you want to segment\n",
    "\n",
    "sample = \"MA4752_S4_2_XRD\"\n",
    "dataset = \"DTL1z90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desination of H5 files\n",
    "\n",
    "dset_path = os.path.join(processed_data_root_dir, sample, f\"{sample}_{dataset}\", f\"{sample}_{dataset}_dataset.h5\")\n",
    "\n",
    "par_path = 'nickel.par'\n",
    "\n",
    "e2dx_path = \"/data/id11/nanoscope/Eiger/spatial_20210415_JW/e2dx.edf\"\n",
    "e2dy_path = \"/data/id11/nanoscope/Eiger/spatial_20210415_JW/e2dy.edf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset (for motor positions, not sure why these are not in peaks)\n",
    "ds = ImageD11.sinograms.dataset.load(dset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import 4D peaks\n",
    "\n",
    "cf_4d = ImageD11.columnfile.columnfile(ds.col4dfile)\n",
    "\n",
    "cf_4d.parameters.loadparameters(par_path)\n",
    "cf_4d.updateGeometry()\n",
    "\n",
    "print(f\"Read {cf_4d.nrows} 4D peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_grains(ds):\n",
    "    ds.grainsfile_carbides = os.path.join(ds.analysispath, ds.dsname + '_grains_carbides.h5')\n",
    "    with h5py.File(ds.grainsfile_carbides, 'r') as hin:      \n",
    "        grains_group = 'grains'\n",
    "        \n",
    "        grains = []\n",
    "        for gid_string in tqdm(sorted(hin[grains_group].keys(), key=lambda x: int(x))):\n",
    "            gg = hin[grains_group][gid_string]\n",
    "            ubi = gg.attrs['ubi'][:]\n",
    "            g = ImageD11.grain.grain(ubi)\n",
    "            g.gid = int(gid_string)\n",
    "            g.peaks_4d = gg['peaks_4d_indexing'][:]\n",
    "            grains.append(g)\n",
    "    \n",
    "    return grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grains = read_grains(ds)\n",
    "\n",
    "for grain in grains:\n",
    "    # print(grain.gid)\n",
    "    grain.a = np.cbrt(np.linalg.det(grain.ubi))\n",
    "    \n",
    "print(f\"{len(grains)} grains imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isolate Nickel peaks, and remove them from the dataset\n",
    "ni_peaks_mask = utils.unitcell_peaks_mask(cf_4d, dstol=0.0075, dsmax=cf_4d.ds.max())\n",
    "\n",
    "carbides = cf_4d.copy()\n",
    "carbides.filter(~ni_peaks_mask)\n",
    "\n",
    "# Update geometry for carbides peaks\n",
    "\n",
    "par_path = 'carbide.par'\n",
    "carbides.parameters.loadparameters(par_path)\n",
    "carbides.updateGeometry()\n",
    "\n",
    "cf_strong = utils.selectpeaks(carbides, dstol=0.0075, dsmax=carbides.ds.max(), frac=0.9, doplot=0.01)\n",
    "print(cf_strong.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the sinograms are only half-sinograms (we scanned dty across half the sample rather than the full sample), set the below to true:\n",
    "is_half_scan = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_half_scan:\n",
    "    c0 = 0\n",
    "    # check / fix the centre of rotation\n",
    "    # get value of bin closest to c0\n",
    "    central_bin = np.argmin( abs(ds.ybincens - c0))\n",
    "    # get centre dty value of this vin\n",
    "    central_value = ds.ybincens[central_bin]\n",
    "\n",
    "    lo_side = ds.ybincens[:central_bin+1]\n",
    "    hi_side = ds.ybincens[central_bin:]\n",
    "    \n",
    "    # get the hi/lo side which is widest\n",
    "    # i.e if you go from -130 to +20, it selects -130\n",
    "    yrange = max( hi_side[-1] - hi_side[0], lo_side[-1] - lo_side[0] )\n",
    "\n",
    "    # round to nearest multiple of ds.ystep\n",
    "    yrange = np.ceil( yrange / ds.ystep ) * ds.ystep\n",
    "    \n",
    "    # make new ymin and ymax that are symmetric around central_value\n",
    "    ds.ymin = central_value - yrange\n",
    "    ds.ymax = central_value + yrange\n",
    "    \n",
    "    new_yrange = ds.ymax - ds.ymin\n",
    "    \n",
    "    # determine new number of y bins\n",
    "    ny = int(new_yrange//ds.ystep) + 1\n",
    "    \n",
    "    ds.ybincens = np.linspace(ds.ymin, ds.ymax, ny)\n",
    "    ds.ybinedges = np.linspace(ds.ymin - ds.ystep / 2, ds.ymax + ds.ystep / 2, ny + 1)\n",
    "    \n",
    "    print(len(ds.ybincens))\n",
    "    print(ds.ybincens)\n",
    "    print(ds.ystep)\n",
    "    print(yrange)\n",
    "    print(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load mask for whole sample from Ni grain reconstruction\n",
    "\n",
    "def read_ni_grains(ds):\n",
    "    with h5py.File(ds.grainsfile, 'r') as hin:      \n",
    "        grains_group = 'grains'\n",
    "        \n",
    "        grains = []\n",
    "        for gid_string in tqdm(sorted(hin[grains_group].keys(), key=lambda x: int(x))):\n",
    "            gg = hin[grains_group][gid_string]\n",
    "            ubi = gg.attrs['ubi'][:]\n",
    "            g = ImageD11.grain.grain(ubi)\n",
    "            g.gid = int(gid_string)\n",
    "            g.sample_mask = gg['circle_mask'][:]\n",
    "            # g.etasigns_4d = gg['etasigns_4d'][:]\n",
    "            # g.hkl_4d = gg['hkl_4d'][:]\n",
    "            # g.mask_4d = gg['mask_4d'][:]\n",
    "            # g.mask_4d_greedy = gg['mask_4d_greedy'][:]\n",
    "            # g.peak_indices_4d = gg['peak_indices_4d'][:]\n",
    "            # g.npks_4d = gg.attrs['npks_4d']\n",
    "            # g.npks_4d_greedy = gg.attrs['npks_4d_greedy']\n",
    "            grains.append(g)\n",
    "    \n",
    "    return grains\n",
    "\n",
    "ni_grains = read_ni_grains(ds)\n",
    "whole_sample_mask = ni_grains[0].sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tol = 0.25\n",
    "\n",
    "# column to store the grain labels\n",
    "labels_4d_strong = np.zeros(cf_strong.nrows, 'i')\n",
    "# get all g-vectors from columnfile\n",
    "gvecs_4d_strong = np.transpose((cf_strong.gx,cf_strong.gy,cf_strong.gz)).astype(float)\n",
    "# column to store drlv2 (error in hkl)\n",
    "drlv2 = np.ones(cf_strong.nrows, 'd')\n",
    "# iterate over all grains\n",
    "print(f\"Scoring and assigning {len(grains)} grains\")\n",
    "for g in tqdm(grains):\n",
    "    n = ImageD11.cImageD11.score_and_assign(g.ubi, gvecs_4d_strong, tol, drlv2, labels_4d_strong, g.gid)\n",
    "\n",
    "# add the labels column to the columnfile\n",
    "cf_strong.addcolumn(labels_4d_strong, 'grain_id')\n",
    "\n",
    "print(\"Storing peak data in grains\")\n",
    "# iterate through all the grains\n",
    "for g in tqdm(grains):\n",
    "    # store this grain's peak indices so we know which 4D peaks we used for sinograms\n",
    "    g.mask_4d = cf_strong.grain_id == g.gid\n",
    "    g.peaks_4d = cf_strong.index[g.mask_4d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "m = cf_strong.grain_id >= 0\n",
    "ax.scatter(cf_strong.omega[m], cf_strong.dty[m], c=cf_strong.grain_id[m])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_unit_cell_lengths = [grain.a for grain in grains]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_unit_cell_lengths)\n",
    "ax.set_xlabel(\"Grain ID\")\n",
    "ax.set_ylabel(\"Unit cell length\")\n",
    "plt.show()\n",
    "\n",
    "a0 = np.median(mean_unit_cell_lengths)\n",
    "    \n",
    "print(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_grains_to_plot=25\n",
    "\n",
    "grains_step = len(grains)//n_grains_to_plot + 1\n",
    "\n",
    "grid_size = np.ceil(np.sqrt(len(grains[::grains_step]))).astype(int)\n",
    "nrows = (len(grains[::grains_step])+grid_size-1)//grid_size\n",
    "\n",
    "# plt.style.use('light_background')\n",
    "fig, axs = plt.subplots(grid_size, nrows, figsize=(10,10), layout=\"constrained\", sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    if i < len(grains[::grains_step]):\n",
    "    # get corresponding grain for this axis\n",
    "        g = grains[::grains_step][i]\n",
    "        m = cf_strong.grain_id == g.gid\n",
    "        ax.scatter(cf_strong.omega[m], cf_strong.dty[m], c=cf_strong.sum_intensity[m])\n",
    "        \n",
    "fig.supxlabel(\"Omega\")\n",
    "fig.supylabel(\"Y translation (um)\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for grain in tqdm(grains):\n",
    "    grain.peaks_4d_selected, grain.cen, grain.dx, grain.dy = utils.graincen(grain.gid, cf_strong, doplot=False)\n",
    "    grain.rgb_z = utils.grain_to_rgb(grain, ax=(0,0,1),)# symmetry = Symmetry.cubic)\n",
    "    grain.rgb_y = utils.grain_to_rgb(grain, ax=(0,1,0),)# symmetry = Symmetry.cubic)\n",
    "    grain.rgb_x = utils.grain_to_rgb(grain, ax=(1,0,0),)# symmetry = Symmetry.cubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure we get cen right (centre of rotation should be the middle of dty)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([g.cen for g in grains])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c0 = np.median([g.cen for g in grains])\n",
    "\n",
    "print('Center of rotation in dty', c0)\n",
    "\n",
    "# c0 is being correctly determined\n",
    "# we know this because of the earlier single-grain dty vs omega plot\n",
    "# if g.cen was off, the fit would be shifted\n",
    "# this means we have another parameter we need to introduce\n",
    "# to account for uneven spacing either side of the center of rotation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.dx for g in grains]\n",
    "y = [g.dy for g in grains]\n",
    "s = [g.peaks_4d_selected.sum()/10 for g in grains]\n",
    "a[0].scatter(x, y, s=s, c=[g.rgb_z for g in grains])\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(x, y, s=s, c=[g.rgb_y for g in grains])\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(x, y, s=s, c=[g.rgb_x for g in grains])\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(x, y, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"Lab x\")\n",
    "fig.supylabel(\"Lab y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate translations of grains\n",
    "for g in grains:\n",
    "    g.translation = np.array([g.dx, g.dy, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Big scary block\n",
    "# Must understand what this does!\n",
    "\n",
    "# Ensure cf is sorted by spot3d_id\n",
    "# NOTE: spot3d_id should be spot4d_id, because we have merged into 4D?\n",
    "assert (np.argsort(cf_strong.spot3d_id) == np.arange(cf_strong.nrows)).all()\n",
    "\n",
    "# load the 2d peak labelling output\n",
    "pks = ImageD11.sinograms.properties.pks_table.load(ds.pksfile)\n",
    "\n",
    "# Grab the 2d peak centroids\n",
    "p2d = pks.pk2d(ds.omega, ds.dty)\n",
    "\n",
    "# NOTE: These are not spatially corrected?!\n",
    "\n",
    "numba_order, numba_histo = utils.counting_sort(p2d['spot3d_id'])\n",
    "\n",
    "grain_2d_id = utils.palloc(p2d['spot3d_id'].shape, np.dtype(int))\n",
    "\n",
    "cleanid = cf_strong.grain_id.copy()\n",
    "\n",
    "utils.find_grain_id(cf_strong.spot3d_id, cleanid, p2d['spot3d_id'], grain_2d_id, numba_order)\n",
    "\n",
    "gord, counts = utils.counting_sort(grain_2d_id)\n",
    "\n",
    "inds = np.concatenate(((0,), np.cumsum(counts)))\n",
    "\n",
    "# I think what we end up with is:\n",
    "# inds\n",
    "# this is an array which tells you which 2D spots each grain owns\n",
    "# the 2D spots are sorted by spot ID\n",
    "# inds tells you for each grain were you can find its associated 2D spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now our 2D peak assignments are known, let's populate our grain objects with our 2D peaks\n",
    "\n",
    "for grain in tqdm(grains):\n",
    "    i = grain.gid\n",
    "    grain.peaks_2d = gord[inds[i+1] : inds[i+2]]\n",
    "    # grain.mask_2d = np.isin(cf_2d.index, grain.peaks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_grain_from_peaks(g, flt, ds):\n",
    "    \"\"\"\n",
    "    Computes sinogram\n",
    "    flt is already the peaks for this grain\n",
    "    Returns angles, sino\n",
    "    \"\"\"   \n",
    "    NY = len(ds.ybincens)  # number of y translations\n",
    "    iy = np.round((flt.dty - ds.ybincens[0]) / (ds.ybincens[1]-ds.ybincens[0])).astype(int)  # flt column for y translation index\n",
    "\n",
    "    # The problem is to assign each spot to a place in the sinogram\n",
    "    hklmin = g.hkl_2d_strong.min(axis=1)  # Get minimum integer hkl (e.g -10, -9, -10)\n",
    "    dh = g.hkl_2d_strong - hklmin[:,np.newaxis]  # subtract minimum hkl from all integer hkls\n",
    "    de = (g.etasigns_2d_strong.astype(int) + 1)//2  # something signs related\n",
    "    #   4D array of h,k,l,+/-\n",
    "    # pkmsk is whether a peak has been observed with this HKL or not\n",
    "    pkmsk = np.zeros(list(dh.max(axis=1) + 1 )+[2,], int)  # make zeros-array the size of (max dh +1) and add another axis of length 2\n",
    "    pkmsk[ dh[0], dh[1], dh[2], de ] = 1  # we found these HKLs for this grain\n",
    "    #   sinogram row to hit\n",
    "    pkrow = np.cumsum(pkmsk.ravel()).reshape(pkmsk.shape) - 1  #\n",
    "    # counting where we hit an HKL position with a found peak\n",
    "    # e.g (-10, -9, -10) didn't get hit, but the next one did, so increment\n",
    "\n",
    "    npks = pkmsk.sum( )\n",
    "    destRow = pkrow[ dh[0], dh[1], dh[2], de ] \n",
    "    sino = np.zeros( ( npks, NY ), 'f' )\n",
    "    hits = np.zeros( ( npks, NY ), 'f' )\n",
    "    angs = np.zeros( ( npks, NY ), 'f' )\n",
    "    adr = destRow * NY + iy \n",
    "    # Just accumulate \n",
    "    sig = flt.sum_intensity\n",
    "    ImageD11.cImageD11.put_incr64( sino, adr, sig )\n",
    "    ImageD11.cImageD11.put_incr64( hits, adr, np.ones(len(de),dtype='f'))\n",
    "    ImageD11.cImageD11.put_incr64( angs, adr, flt.omega)\n",
    "    \n",
    "    sinoangles = angs.sum( axis = 1) / hits.sum( axis = 1 )\n",
    "    # Normalise:\n",
    "    sino = (sino.T/sino.max( axis=1 )).T\n",
    "    # Sort (cosmetic):\n",
    "    order = np.lexsort((np.arange(npks), sinoangles))\n",
    "    sinoangles = sinoangles[order]\n",
    "    ssino = sino[order].T\n",
    "    return sinoangles, ssino, hits[order].T\n",
    "\n",
    "def do_sinos(g, hkltol=0.25):\n",
    "    flt = utils.tocolf({p:p2d[p][g.peaks_2d] for p in p2d}, par_path, dxfile=e2dx_path, dyfile=e2dy_path)  # convert it to a columnfile and spatially correct\n",
    "    \n",
    "    hkl_real = np.dot(g.ubi, (flt.gx, flt.gy, flt.gz))  # calculate hkl of all assigned peaks\n",
    "    hkl_int = np.round(hkl_real).astype(int) # round to nearest integer\n",
    "    dh = ((hkl_real - hkl_int)**2).sum(axis = 0)  # calculate square of difference\n",
    "\n",
    "    # g.dherrall = dh.mean()  # mean hkl error across all assigned peaks\n",
    "    # g.npksall = flt.nrows  # total number of assigned peaks\n",
    "    flt.filter(dh < hkltol*hkltol)  # filter all assigned peaks to be less than hkltol squared\n",
    "    hkl_real = np.dot(g.ubi, (flt.gx, flt.gy, flt.gz))  # recalculate error after filtration\n",
    "    hkl_int = np.round(hkl_real).astype(int)\n",
    "    dh = ((hkl_real - hkl_int)**2).sum(axis = 0)\n",
    "    # g.dherr = dh.mean()  # dherr is mean hkl error across assigned peaks after hkltol filtering\n",
    "    # g.npks = flt.nrows  # total number of assigned peaks after hkltol filtering\n",
    "    g.etasigns_2d_strong = np.sign(flt.eta)\n",
    "    g.hkl_2d_strong = hkl_int  # integer hkl of assigned peaks after hkltol filtering\n",
    "    g.sinoangles, g.ssino, g.hits = map_grain_from_peaks(g, flt, ds)\n",
    "    return i,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine sinograms of all grains\n",
    "\n",
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1,nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(do_sinos, grains), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show sinogram of single grain\n",
    "\n",
    "g = grains[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow((g.ssino/g.ssino.mean(axis=0)), norm=matplotlib.colors.LogNorm(), interpolation='nearest', origin=\"lower\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_iradon_id11(grain, pad=20, y0=c0/2, workers=1, sample_mask=whole_sample_mask, apply_halfmask=is_half_scan, mask_central_zingers=False):\n",
    "    outsize = grain.ssino.shape[0] + pad\n",
    "    \n",
    "    if apply_halfmask:\n",
    "        halfmask = np.zeros_like(grain.ssino)\n",
    "\n",
    "        halfmask[:len(halfmask)//2-1, :] = 1\n",
    "        halfmask[len(halfmask)//2-1, :] = 0.5\n",
    "        \n",
    "        ssino_to_recon = grain.ssino * halfmask\n",
    "    else:\n",
    "        ssino_to_recon = grain.ssino\n",
    "        \n",
    "    # pad the sample mask\n",
    "    # sample_mask_padded = np.pad(sample_mask, pad//2)\n",
    "\n",
    "    \n",
    "    # Perform iradon transform of grain sinogram, store result (reconstructed grain shape) in g.recon\n",
    "    grain.recon = ImageD11.sinograms.roi_iradon.iradon(ssino_to_recon, \n",
    "                                                       theta=grain.sinoangles, \n",
    "                                                       mask=sample_mask,\n",
    "                                                       output_size=outsize,\n",
    "                                                       projection_shifts=np.full(grain.ssino.shape, -y0),\n",
    "                                                       filter_name='hamming',\n",
    "                                                       interpolation='linear',\n",
    "                                                       workers=workers)\n",
    "    \n",
    "    if mask_central_zingers:\n",
    "        grs = grain.recon.shape[0]\n",
    "        xpr, ypr = -grs//2 + np.mgrid[:grs, :grs]\n",
    "        inner_mask_radius = 25\n",
    "        outer_mask_radius = inner_mask_radius + 2\n",
    "\n",
    "        inner_circle_mask = (xpr ** 2 + ypr ** 2) < inner_mask_radius ** 2\n",
    "        outer_circle_mask = (xpr ** 2 + ypr ** 2) < outer_mask_radius ** 2\n",
    "\n",
    "        mask_ring = inner_circle_mask & outer_circle_mask\n",
    "        # we now have a mask to apply\n",
    "        fill_value = np.median(grain.recon[mask_ring])\n",
    "        grain.recon[inner_circle_mask] = fill_value\n",
    "    \n",
    "    return grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can pick a grain and investigate the effects of changing y0 that gets passed to iradon\n",
    "# it' best to pick the grain AFTER reconstructing all grains, so you can pick a grain of interest\n",
    "\n",
    "g = grains[1066]\n",
    "    \n",
    "vals = np.linspace(-2.0, -1.0, 9)\n",
    "\n",
    "grid_size = np.ceil(np.sqrt(len(vals))).astype(int)\n",
    "nrows = (len(vals)+grid_size-1)//grid_size\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, nrows, sharex=True, sharey=True)\n",
    "\n",
    "for inc, val in enumerate(tqdm.tqdm(vals)):\n",
    "    run_iradon_id11(g, y0=val)\n",
    "    # crop = g.recon[200:240, 230:290]\n",
    "    crop = g.recon\n",
    "    \n",
    "    axs.ravel()[inc].imshow(crop, origin=\"lower\")\n",
    "    axs.ravel()[inc].set_title(val)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can overwrite y0 and pad here\n",
    "\n",
    "y0 = -1.25\n",
    "pad = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nthreads = len(os.sched_getaffinity(os.getpid()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor( max_workers= max(1,nthreads-1) ) as pool:\n",
    "    for i in tqdm(pool.map(run_iradon_id11, grains, [pad]*len(grains), [y0]*len(grains)), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "%matplotlib ipympl\n",
    "\n",
    "fig, a = plt.subplots(1,2,figsize=(10,5))\n",
    "rec = a[0].imshow(grains[8].recon, vmin=0)\n",
    "sin = a[1].imshow(grains[8].ssino, aspect='auto')\n",
    "\n",
    "# Function to update the displayed image based on the selected frame\n",
    "def update_frame(i):\n",
    "    rec.set_array(grains[i].recon)\n",
    "    sin.set_array(grains[i].ssino)\n",
    "    a[0].set(title=str(i))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# Create a slider widget to select the frame number\n",
    "frame_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(grains) - 1,\n",
    "    step=1,\n",
    "    description='Grain:'\n",
    ")\n",
    "\n",
    "interact(update_frame, i=frame_slider)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.feature import blob_log\n",
    "\n",
    "def find_cens_from_recon(grain):\n",
    "    grain.bad_recon = False\n",
    "    blobs = blob_log(grain.recon, min_sigma=1, max_sigma=10, num_sigma=10, threshold=.01)\n",
    "    blobs_sorted = sorted(blobs, key=lambda x: x[2], reverse=True)\n",
    "    try:\n",
    "        largest_blob = blobs_sorted[0]\n",
    "        grain.x_blob = largest_blob[1]\n",
    "        grain.y_blob = largest_blob[0]\n",
    "    except IndexError:\n",
    "        # didn't find any blobs\n",
    "        # for small grains like these, if we didn't find a blob, normally indicates recon is bad\n",
    "        # we will exclude it from maps and export\n",
    "        grain.bad_recon = True\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers= max(1, nthreads-1)) as pool:\n",
    "    for i in tqdm(pool.map(find_cens_from_recon, grains), total=len(grains)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove bad recon grains from future analysis\n",
    "print(f\"{len(grains)} grains before filtration\")\n",
    "grains = [grain for grain in grains if not grain.bad_recon]\n",
    "print(f\"{len(grains)} grains after filtration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for g in grains:\n",
    "    g.translation = np.array([g.x_blob, g.y_blob, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "a = ax.ravel()\n",
    "x = [g.x_blob for g in grains]\n",
    "y = [g.y_blob for g in grains]\n",
    "s = [g.peaks_4d_selected.sum()/10 for g in grains]\n",
    "a[0].scatter(x, y, s=s, c=[g.rgb_z for g in grains])\n",
    "a[0].set(title='IPF color Z',  aspect='equal')\n",
    "a[1].scatter(x, y, s=s, c=[g.rgb_y for g in grains])\n",
    "a[1].set(title='IPF color Y', aspect='equal')\n",
    "a[2].scatter(x, y, s=s, c=[g.rgb_x for g in grains])\n",
    "a[2].set(title='IPF color X',  aspect='equal')\n",
    "a[3].scatter(x, y, c=s)\n",
    "a[3].set(title='Number of 4D peaks', aspect='equal')\n",
    "\n",
    "fig.supxlabel(\"Lab x\")\n",
    "fig.supylabel(\"Lab y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots( 1,3, figsize=(15,5) )\n",
    "ty, tx = utils.triangle().T\n",
    "for i,title in enumerate( 'xyz' ):\n",
    "    ax = np.zeros(3)\n",
    "    ax[i] = 1.\n",
    "    hkl = [utils.crystal_direction_cubic( g.ubi, ax ) for g in grains]\n",
    "    xy = np.array([utils.hkl_to_pf_cubic(h) for h in hkl ])\n",
    "    rgb = np.array([utils.hkl_to_color_cubic(h) for h in hkl ])\n",
    "    for j in range(len(grains)):\n",
    "        grains[j].rgb = rgb[j]\n",
    "    a[i].scatter( xy[:,1], xy[:,0], c = rgb )   # Note the \"x\" axis of the plot is the 'k' direction and 'y' is h (smaller)\n",
    "    a[i].set(title=title, aspect='equal', facecolor='silver', xticks=[], yticks=[])\n",
    "    a[i].plot( tx, ty, 'k-', lw = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grain_labels_array = np.zeros_like(grains[0].recon) - 1\n",
    "red = np.zeros_like(grains[0].recon)\n",
    "grn = np.zeros_like(grains[0].recon)\n",
    "blu = np.zeros_like(grains[0].recon)\n",
    "\n",
    "raw_intensity_array = np.zeros_like(grains[0].recon)\n",
    "\n",
    "cutoff_level = 0.5\n",
    "\n",
    "raw_intensity_array.fill(cutoff_level)\n",
    "\n",
    "# ignore the centre when determining r.max()???\n",
    "\n",
    "def norm(r):\n",
    "    m = r > r.max()*0.2\n",
    "    return (r/r[m].mean()).clip(0,1)\n",
    "\n",
    "for g in tqdm(grains):\n",
    "    i = g.gid\n",
    "    \n",
    "    g_raw_intensity = norm(g.recon)\n",
    "    \n",
    "    g_raw_intensity_mask = g_raw_intensity > raw_intensity_array\n",
    "    \n",
    "    g_raw_intenstiy_map = g_raw_intensity[g_raw_intensity_mask]\n",
    "    \n",
    "    raw_intensity_array[g_raw_intensity_mask] = g_raw_intenstiy_map\n",
    "    \n",
    "    red[g_raw_intensity_mask] = g_raw_intenstiy_map*g.rgb_z[0]\n",
    "    grn[g_raw_intensity_mask] = g_raw_intenstiy_map*g.rgb_z[1]\n",
    "    blu[g_raw_intensity_mask] = g_raw_intenstiy_map*g.rgb_z[2]\n",
    "    \n",
    "    grain_labels_array[g_raw_intensity_mask] = i\n",
    "    \n",
    "raw_intensity_array[raw_intensity_array == cutoff_level] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot initial output\n",
    "\n",
    "image_to_show = np.transpose((red, grn, blu), axes=(1, 2, 0))\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(image_to_show)  # originally 1,2,0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(grain_labels_array)  # originally 1,2,0\n",
    "ax.set_title(\"Grain label map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.imshow(raw_intensity_array)  # originally 1,2,0\n",
    "ax.set_title(\"Raw intensity array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write grains to disk\n",
    "\n",
    "cmp = {'compression':'gzip',\n",
    "       'compression_opts': 2,\n",
    "       'shuffle' : True }\n",
    "\n",
    "def save_array(grp, name, ary):\n",
    "    hds = grp.require_dataset(name, \n",
    "                              shape=ary.shape,\n",
    "                              dtype=ary.dtype,\n",
    "                              **cmp)\n",
    "    hds[:] = ary\n",
    "    return hds\n",
    "\n",
    "def save_grains(grains, ds):\n",
    "    \n",
    "    # delete existing file, because our grain numbers have changed\n",
    "    if os.path.exists(ds.grainsfile_carbides):\n",
    "        os.remove(ds.grainsfile_carbides)\n",
    "    \n",
    "    with h5py.File(ds.grainsfile_carbides, 'w-') as hout:  # fail if exists\n",
    "        try:\n",
    "            grp = hout.create_group('peak_assignments')\n",
    "        except ValueError:\n",
    "            grp = hout['peak_assignments']\n",
    "\n",
    "        ds_gord = save_array( grp, 'gord', gord )\n",
    "        ds_gord.attrs['description'] = 'Grain ordering: g[i].pks = gord[ inds[i] : inds[i+1] ]'\n",
    "        ds_inds = save_array( grp, 'inds', inds )\n",
    "        ds_inds.attrs['description'] = 'Grain indices: g[i].pks = gord[ inds[i] : inds[i+1] ]'\n",
    "        \n",
    "        try:\n",
    "            grp = hout.create_group('slice_recon')\n",
    "        except ValueError:\n",
    "            grp = hout['slice_recon']\n",
    "        save_array(grp, 'intensity', raw_intensity_array).attrs['description'] = 'Raw intensity array for all grains'\n",
    "        save_array(grp, 'labels', grain_labels_array).attrs['description'] = 'Grain labels array for all grains'\n",
    "        \n",
    "        grains_group = hout.create_group('grains')\n",
    "        for g in tqdm(grains):\n",
    "            gg = grains_group.create_group(str(g.gid))\n",
    "            # save stuff for sinograms\n",
    "            \n",
    "            gg.attrs.update({'ubi':g.ubi})\n",
    "            \n",
    "            save_array(gg, 'peaks_4d_indexing', g.peaks_4d).attrs['description'] = \"Strong 4D peaks that were assigned to this grain during indexing\"\n",
    "            \n",
    "            save_array(gg, 'ssino', g.ssino).attrs['description'] = 'Sinogram of peak intensities sorted by omega'\n",
    "            save_array(gg, 'sinoangles', g.sinoangles).attrs['description'] = 'Projection angles for sinogram'\n",
    "            save_array(gg, 'og_recon', g.recon).attrs['description'] = 'Original ID11 iRadon reconstruction'\n",
    "            save_array(gg, 'recon', g.recon).attrs['description'] = 'Final reconstruction'\n",
    "            save_array(gg, 'circle_mask', whole_sample_mask).attrs['description'] = 'Reconstruction mask to use for MLEM'\n",
    "            \n",
    "            # might as well save peaks stuff while we're here\n",
    "            save_array(gg, 'translation', g.translation).attrs['description'] = 'Grain translation in lab frame'\n",
    "            save_array(gg, 'peaks_2d_sinograms', g.peaks_2d).attrs['description'] = \"2D peaks from strong 4D peaks that were assigned to this grain for sinograms\"\n",
    "            save_array(gg, 'peaks_4d_sinograms', g.peaks_4d).attrs['description'] = \"Strong 4D peaks that were assigned to this grain for sinograms\"\n",
    "\n",
    "            gg.attrs['cen'] = g.cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_grains(grains, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
