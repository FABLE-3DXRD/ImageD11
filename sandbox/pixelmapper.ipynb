{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given:\n",
    "- sparseframe pixels file (s, f, omega, intensity)\n",
    "- parameters file\n",
    "- spatial distortion images (sraw -> sc, fraw -> fc)\n",
    "- ubi file for list of grains\n",
    "    \n",
    "ForEach pixel:\n",
    "- assign it to one or more grains with h,k,l,sign(eta) label\n",
    "- best grain + hklid\n",
    "- second best grain + hklid -> to determine whether this is an overlap problem / twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "start = time.time()\n",
    "import numpy as np, pylab as pl\n",
    "from ImageD11 import transform, parameters, cImageD11, indexing, columnfile, sym_u, blobcorrector, grain\n",
    "import fabio, h5py\n",
    "\n",
    "\n",
    "PLOT = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in transform or blobcorrector ?\n",
    "\n",
    "class Lut( object ):\n",
    "                 \n",
    "    pnames = ( \"y_center\", \"z_center\", \"y_size\", \"z_size\",\n",
    "               \"distance\", \"wavelength\",\n",
    "               \"tilt_x\",\"tilt_y\",\"tilt_z\",\n",
    "               \"o11\", \"o12\", \"o21\", \"o22\",\n",
    "               \"wedge\", \"chi\", \"dxfile\", \"dyfile\", \"spline\", \"shape\" )\n",
    "                 \n",
    "    def __init__( self, pars ):\n",
    "        \n",
    "        self.pars = {}\n",
    "        for p in self.pnames:\n",
    "            if p in pars:\n",
    "                self.pars[p] = pars[p] # make a copy\n",
    "        if 'dxfile' in pars:\n",
    "            # slow/fast coordinates on image at pixel centers\n",
    "            self.df = fabio.open( pars['dxfile'] ).data\n",
    "            self.ds = fabio.open( pars['dyfile'] ).data\n",
    "            self.shape = s = self.ds.shape\n",
    "            self.pars['shape'] = s\n",
    "            slow, fast = np.mgrid[ 0:s[0], 0:s[1] ]\n",
    "            self.sc = slow + self.ds\n",
    "            self.fc = fast + self.df\n",
    "        elif 'spline' in pars: # need to test this...\n",
    "            b = blobcorrector.correctorclass( self.pars['spline'] )\n",
    "            s = self.pars['shape']\n",
    "            self.fc, self.sc = b.make_pixel_lut( s ) \n",
    "            slow, fast = np.mgrid[ 0:s[0], 0:s[1] ]\n",
    "            self.df = self.fc - fast\n",
    "            self.ds = self.sc - slow\n",
    "        # scattering angles:\n",
    "        self.tth, self.eta = transform.compute_tth_eta( \n",
    "            (self.sc.ravel(), self.fc.ravel()), **self.pars )\n",
    "        # scattering vectors:\n",
    "        self.k = transform.compute_k_vectors( self.tth, self.eta, \n",
    "                                              self.pars.get('wavelength') )\n",
    "        self.tth.shape = s\n",
    "        self.eta.shape = s\n",
    "        self.k.shape = (3, s[0], s[1])\n",
    "    \n",
    "    def spatial(self, sraw, fraw):\n",
    "        \"\"\" applies a spatial distortion to sraw, fraw (for peak centroids) \"\"\"\n",
    "        si = np.round(sraw.astype(int)).clip( 0, self.shape[1] - 1 )\n",
    "        fi = np.round(fraw.astype(int)).clip( 0, self.shape[1] - 1 )\n",
    "        sc = sraw + self.ds[ si, fi ]\n",
    "        fc = fraw + self.df[ si, fi ]\n",
    "        return sc, fc     \n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" print yourself in a way we can use for eval \"\"\"\n",
    "        sp = \"\\n\".join( [ \"%s : %s,\"%(repr(p), repr(self.pars[p])) for p in self.pnames\n",
    "                         if p in self.pars ] )\n",
    "        return \"Lut( { %s } )\"%(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "pars = parameters.read_par_file( \"../test/pixelmapper/CeO2.par\" ).parameters\n",
    "pars['dxfile'] = \"/data/id11/nanoscope/Eiger/spatial_20210415_JW/e2dx.edf\"\n",
    "pars['dyfile'] = \"/data/id11/nanoscope/Eiger/spatial_20210415_JW/e2dy.edf\"\n",
    "tabl = Lut( pars )\n",
    "print(tabl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si, fi = int( tabl.pars['z_center'] ), int( tabl.pars['y_center'])\n",
    "ref = tabl.k[:,si,fi]\n",
    "sub_pixel_factor = 0\n",
    "nfac = 0\n",
    "for i in range(-1,2):\n",
    "    for j in range(-1,2):\n",
    "        dk = (tabl.k[:,si+i,fi+j]-ref)\n",
    "        if i!=0 or j!=0:\n",
    "            # actual distance will be from the center to 1/4 and 3/4 points\n",
    "            sf = np.dot(dk,dk)/(i*i+j*j)/16\n",
    "            sub_pixel_factor += sf\n",
    "            nfac += 1\n",
    "\n",
    "sub_pixel_factor /= 8\n",
    "print(sub_pixel_factor)   # FIXME : do the integral!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MB(num):\n",
    "    return \"%.3f MB\"%(num / (1024*1024) )\n",
    "\n",
    "with h5py.File(\"../test/pixelmapper/silicon_fullscan_sparse.h5\" ,\"r\") as hin:\n",
    "    for scan in hin:\n",
    "        s = hin[scan]\n",
    "        print(scan,list(s))\n",
    "        print(dict(s.attrs))\n",
    "        for column in list(s['measurement']):\n",
    "            print(column, s['measurement'][column].shape)\n",
    "        nnz = s['nnz'][:]\n",
    "        ipt = np.cumsum(nnz)\n",
    "        print(\"pixels\",ipt[-1],\"per frame avg:\", ipt[-1]/len(nnz))\n",
    "        nbytes = 0\n",
    "        for name in 'row','col','frame','intensity','measurement/rot_center':\n",
    "            a = s[name]\n",
    "            b = a.dtype.itemsize * a.size\n",
    "            print(name, a.shape, a.dtype, a.size, MB(b))\n",
    "            nbytes += b\n",
    "        print(MB(nbytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tocolf(pks):\n",
    "    titles = list(pks.keys())\n",
    "    colf = columnfile.newcolumnfile( titles=titles )\n",
    "    nrows = len(pks[titles[0]])\n",
    "    colf.nrows = nrows\n",
    "    colf.set_bigarray( [ pks[t] for t in titles ] )\n",
    "    return colf\n",
    "\n",
    "class SparseScan( object ):\n",
    "    \n",
    "    omeganames = ['measurement/rot_center', 'measurement/rot',\n",
    "                  'measurement/diffrz_center', 'measurement/diffrz']\n",
    "    dtynames   = ['measurement/dty_center', 'measurement/dty',\n",
    "                  'measurement/diffty_center', 'measurement/diffty']\n",
    "    \n",
    "    def __init__( self, hname, scan ):\n",
    "        \"\"\"\n",
    "        hname : file coming from a sparse segmentation\n",
    "        scan : a scan within that file\n",
    "        motors : which motor channels to (try) to read\n",
    "        \n",
    "        assumes the scan fits into memory (could be problematic)\n",
    "        \"\"\"\n",
    "        with h5py.File(hname,\"r\") as hin:\n",
    "            grp = hin[scan]\n",
    "            self.shape = ( int(v) for v in ( grp.attrs['nframes'], \n",
    "                                            grp.attrs['shape0'], \n",
    "                                            grp.attrs['shape1'] ) )\n",
    "            self.motors = {}\n",
    "            for name, motors in [ ('omega',self.omeganames),\n",
    "                                  ('dty',self.dtynames) ]:\n",
    "                for motor in motors:\n",
    "                    if motor in grp:\n",
    "                        self.motors[ name ] = grp[motor][:]\n",
    "                        break\n",
    "                \n",
    "            self.nnz = grp['nnz'][:]\n",
    "            self.ipt = np.concatenate( ( (0,) , np.cumsum(self.nnz, dtype=int) ) )\n",
    "            self.frame  = grp['frame'][:]\n",
    "            self.row = grp['row'][:]\n",
    "            self.col = grp['col'][:]\n",
    "            self.intensity = grp['intensity'][:]\n",
    "            \n",
    "    def cplabel(self, threshold = 0 ):\n",
    "        \"\"\" Label pixels using the connectedpixels assigment code\n",
    "        Fills in:\n",
    "           self.nlabels = number of peaks per frame\n",
    "           self.labels  = peak labels (should be unique)\n",
    "           self.total_labels = total number of peaks\n",
    "        \"\"\"\n",
    "        self.nlabels = np.zeros( len(self.nnz), np.int32 )\n",
    "        self.labels = np.zeros( len(self.row), \"i\")\n",
    "        nl = 0\n",
    "        for i, npx in enumerate( self.nnz ):\n",
    "            s = self.ipt[i]\n",
    "            e = self.ipt[i+1]\n",
    "            if npx > 0:\n",
    "                self.nlabels[i] = cImageD11.sparse_connectedpixels(\n",
    "                    self.intensity[ s : e ],\n",
    "                    self.row[ s : e ],\n",
    "                    self.col[ s : e ],\n",
    "                    threshold,\n",
    "                    self.labels[ s : e ] )\n",
    "                assert (self.labels[ s : e ] > 0).all()\n",
    "                self.labels[ s : e ] += nl\n",
    "            else:\n",
    "                self.nlabels[i] = 0\n",
    "            nl += self.nlabels[i]\n",
    "        self.total_labels = nl\n",
    "\n",
    "                \n",
    "    def lmlabel(self, threshold = 0 ):\n",
    "        \"\"\" Label pixels using the localmax assigment code\n",
    "        Fills in:\n",
    "           self.nlabels = number of peaks per frame\n",
    "           self.labels  = peak labels (should be unique)\n",
    "           self.total_labels = total number of peaks\n",
    "        \"\"\"\n",
    "        self.nlabels = np.zeros( len(self.nnz), np.int32 )\n",
    "        self.labels = np.zeros( len(self.row), \"i\")\n",
    "        # temporary workspaces\n",
    "        npxmax = self.nnz.max()\n",
    "        vmx = np.zeros( npxmax, np.float32 )\n",
    "        imx = np.zeros( npxmax, 'i' )\n",
    "        nl = 0\n",
    "        for i, npx in enumerate( self.nnz ):\n",
    "            s = self.ipt[i]\n",
    "            e = self.ipt[i+1]\n",
    "            if npx > 0:\n",
    "                self.nlabels[i] = cImageD11.sparse_localmaxlabel(\n",
    "                    self.intensity[ s : e ],\n",
    "                    self.row[ s : e ],\n",
    "                    self.col[ s : e ],\n",
    "                    vmx[:npx],\n",
    "                    imx[:npx],\n",
    "                    self.labels[s : e] )\n",
    "                assert (self.labels[s:e] > 0).all()\n",
    "                self.labels[ s : e ] += nl\n",
    "            else:\n",
    "                self.nlabels[i] = 0\n",
    "            nl += self.nlabels[i]\n",
    "        self.total_labels = nl\n",
    "\n",
    "            \n",
    "    def moments(self):\n",
    "        \"\"\" Computes the center of mass in s/f/omega \n",
    "        returns a columnfile\n",
    "        \"\"\"\n",
    "        pks = {}\n",
    "        for name , weights in [ ('Number_of_pixels', None),\n",
    "                                ('s_raw', self.row ),\n",
    "                                ('f_raw', self.col ),\n",
    "                                ('omega', self.motors['omega'][self.frame]) ]:\n",
    "            pks[name] = np.bincount( self.labels, weights,\n",
    "                                     minlength = self.total_labels+1 )[1:]\n",
    "            if weights is not None:\n",
    "                pks[name] /= pks['Number_of_pixels']\n",
    "        return tocolf(pks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SparseScan( \"../test/pixelmapper/silicon_fullscan_sparse.h5\", \"1.1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s.cplabel()\n",
    "if PLOT:\n",
    "    pl.figure()\n",
    "    pl.plot(s.nlabels)\n",
    "print(s.total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "c = s.moments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc, fc = tabl.spatial( c.s_raw, c.f_raw )\n",
    "c.addcolumn( sc, 'sc')\n",
    "c.addcolumn( fc, 'fc')\n",
    "c.parameters.loadparameters(\"../test/pixelmapper/CeO2.par\")\n",
    "c.updateGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    pl.figure()\n",
    "    pl.plot(c.tth, c.Number_of_pixels * c.tth,\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (c.tth * c.Number_of_pixels) > 1000\n",
    "c.filter(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = 5.43094\n",
    "[c.parameters.set(\"cell__%s\"%(abc), a0) for abc in 'abc']\n",
    "i = indexing.indexer_from_colfile( c )\n",
    "i.assigntorings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.minpks = 10000\n",
    "i.hkl_tol = 0.1\n",
    "i.ring_1 = i.ring_2 = 21\n",
    "i.find()\n",
    "i.scorethem()\n",
    "print(\"Got\",len(i.ubis),\"grains\")\n",
    "i.histogram_drlv_fit()\n",
    "if PLOT:\n",
    "    pl.figure()\n",
    "    for j in range(len(i.ubis)):\n",
    "        pl.plot(i.bins[1:], i.histogram[j],\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubic = sym_u.cubic()\n",
    "ubis = i.ubis = [ sym_u.find_uniq_u( ubi, cubic ) for ubi in i.ubis]\n",
    "ubis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing.ubitocellpars(ubis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabl.k.shape, len(s.row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pomega = s.motors['omega'][s.frame]\n",
    "gve = transform.compute_g_from_k( tabl.k[:, s.row, s.col] , \n",
    "                                  s.motors['omega'][s.frame] )\n",
    "gve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "ga = np.empty( s.col.shape )\n",
    "ga.fill(-1)\n",
    "ge = np.ones( s.col.shape )\n",
    "for k, ubi in enumerate( i.ubis ):\n",
    "    hkl = np.dot( ubi, gve )\n",
    "    print(hkl.shape)\n",
    "    gcalc = np.dot( np.linalg.inv(ubi), np.round(hkl) )\n",
    "    gerr = gcalc - gve\n",
    "    modge = (gerr**2).sum(axis=0)\n",
    "    best = (modge < ge)\n",
    "    ga[best] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptth = tabl.tth[ s.row, s.col ]\n",
    "peta = tabl.eta[ s.row, s.col ]\n",
    "if PLOT:\n",
    "    pl.figure()\n",
    "    pl.plot( ptth, modge, \",\" )\n",
    "    pl.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = modge<0.001\n",
    "if PLOT:\n",
    "    pl.figure()\n",
    "    pl.plot( ptth[  m ], peta[ m], \",\")\n",
    "    pl.plot( ptth[ ~m ], peta[~m], \",\")\n",
    "    pl.figure()\n",
    "    pl.plot( pomega[m], s.intensity[m], ',')\n",
    "    pl.plot( pomega[~m], s.intensity[~m], ',')\n",
    "    pl.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can now have all the pixels assigned to their grain and hkls \n",
    "\n",
    "... to do next:\n",
    "- build a refinement engine using intensity weighting\n",
    "- deal with saturated peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total time\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubi = i.ubis[0]\n",
    "print(gve.shape)\n",
    "h,k,l = np.round( np.dot( ubi, gve ) ).astype(int)\n",
    "gcalc = np.dot( np.linalg.inv(ubi), (h,k,l) )\n",
    "mgerr  = ((gve - gcalc)**2).sum(axis=0)\n",
    "m = mgerr < 0.001\n",
    "se = np.sign(peta).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sortkeys = ( h,k,l,se )\n",
    "order = np.lexsort( sortkeys )\n",
    "print(order.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# indexing from 0 -> h.max() ...  -h.min()->end\n",
    "nh = h.max() - h.min() + 1\n",
    "nk = k.max() - k.min() + 1\n",
    "nl = l.max() - l.min() + 1\n",
    "ne = 3\n",
    "gvar = np.zeros( (3, 3, nh, nk, nl, ne), float )\n",
    "gavg = np.zeros( (3, nh, nk, nl, ne), float )\n",
    "f = np.zeros( (nh, nk, nl, ne), float )\n",
    "e = np.zeros( (9,) ,dtype=np.float).reshape(3,3)\n",
    "# this does not accumulate !\n",
    "# f[h[m],k[m],l[m],se[m]] += s.intensity[m]\n",
    "# gavg[:, h[m], k[m], l[m], se[m]] += gve[:,m]*s.intensity[m]\n",
    "import numba\n",
    "@numba.njit\n",
    "def incr( m, h, k, l, se, gve, sig, gavg, f, gvar, e  ):\n",
    "    # Compute the mean g-vectors in mask:\n",
    "    for p in range(len(m)):\n",
    "        if m[p]:\n",
    "            gavg[:, h[p],k[p],l[p],se[p]] += sig[p] * gve[:,p]\n",
    "            f[ h[p],k[p],l[p],se[p]] += sig[p]\n",
    "    # Get the mean\n",
    "    for i in range(f.size):\n",
    "        v = f.flat[i] \n",
    "        if v > 0:\n",
    "            gavg[0].flat[i] /= v\n",
    "            gavg[1].flat[i] /= v\n",
    "            gavg[2].flat[i] /= v\n",
    "    # Now get the variances:\n",
    "    #       subpixel_factor = 1.7e-6     # From above. This is the in-plane error\n",
    "    #                                    # not rotational, which depends on omega step.\n",
    "    #                 FIXME - not entirely correct yet. Problem goes back a long time.\n",
    "    for p in range(len(m)):\n",
    "        if m[p]:\n",
    "            dg = gve[:,p] - gavg[:,h[p],k[p],l[p],se[p]]\n",
    "            # this loop is np.outer( dg, dg )\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    gvar[i, j, h[p],k[p],l[p],se[p]]  += (dg[i]*dg[j])*sig[p]\n",
    "            for i in range(3):\n",
    "                gvar[ i, i, h[p], k[p], l[p], se[p]]  += sub_pixel_factor*sig[p]\n",
    "            # We are missing a pixel size contribution here. The pixel \n",
    "            # is not a point in space. This wants to sum up over, for \n",
    "            # example 2 subpixels as (sig/2 times:)\n",
    "            #    outer( dg + p, dg + p ) + ...->    dg(x)dg + 2 dg(x)p + p(x)p\n",
    "            #    outer( dg - p, dg - p ) + ...->    dg(x)dg - 2 dx(x)p + p(x)p\n",
    "                    \n",
    "    for p in range(f.size):\n",
    "        v = f.flat[p]\n",
    "        if v > 0:\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    e[i,j] = gvar[i,j].flat[p] / v\n",
    "            d = np.linalg.det(e)\n",
    "            if d <= 0:\n",
    "                print('error')\n",
    "                print(e, p, v, d)\n",
    "                return None\n",
    "            ie = np.linalg.inv(e)\n",
    "            if ie[0,0] < 0:\n",
    "                print('error -ve')\n",
    "                print( e, p, v, d )\n",
    "                print(ie)\n",
    "                print( 'y',gvar[:,:].flat[p] )\n",
    "                return None\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                     gvar[i,j].flat[p] = ie[i,j]\n",
    "            \n",
    "\n",
    "incr( m, h, k, l, se, gve, s.intensity, gavg, f, gvar, e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gvar = np.zeros( (3, 3, nh, nk, nl, ne), float )\n",
    "gavg = np.zeros( (3, nh, nk, nl, ne), float )\n",
    "f = np.zeros( (nh, nk, nl, ne), float )\n",
    "incr( m, h, k, l, se, gve, s.intensity, gavg, f, gvar, e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1: take the average of the observed pixels\n",
    "np.dot(ubi, gavg[:,1,1,1,1]),np.dot(ubi, gavg[:,3,1,1,-1]),\n",
    "# option 2: take the computed gcalc position\n",
    "gcalc = np.dot( np.linalg.inv( ubi ), np.round( np.dot( ubi, gve ) ) )\n",
    "gerr = gcalc - gve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "gvar[:,:,3,1,1,1], gavg[:,3,1,1,1], f[3,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "dg = np.dot( np.linalg.inv(ubi), (3,1,1) ) - gavg[:,3,1,1,1]\n",
    "np.dot(dg, np.dot( gvar[:,:,3,1,1,1], dg ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "dg = np.dot( np.linalg.inv(ubi), (5,3,3) ) - gavg[:,5,3,3,1]\n",
    "print(dg,'\\n', gvar[:,:,5,3,3,1], f[5,3,3,1])\n",
    "np.dot(dg, np.dot( gvar[:,:,5,3,3,1], dg ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gouter = np.einsum( 'ik,jk->ijk', gerr, gerr )\n",
    "assert gouter.shape == (3,3,gerr.shape[1])\n",
    "assert np.allclose( np.outer( gerr[:,3], gerr[:,3] ), gouter[:,:,3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAM'x = MAd\n",
    "#  ... A  == gvar               3x3\n",
    "#  ... d  == gobs - gcalc       3\n",
    "#  ... M' == dg/dvariable       9x3\n",
    "#  ... x  == variables          9\n",
    "#\n",
    "#  9x3.3x3.3x9.9 = 9x3.3x3.3\n",
    "\n",
    "\n",
    "M = np.zeros( (9,3), float )\n",
    "LSM = np.zeros( (9,9), float )\n",
    "RHS = np.zeros( (9,), float)\n",
    "\n",
    "def dg_dUB( M, h, k, l ):\n",
    "    \"\"\" \n",
    "    dg_dUB :\n",
    "      gx = UB_00.h UB_01.h UB_02.l\n",
    "      gy = UB_10.h UB_11.h UB_12.l\n",
    "      gz = UB_20.h UB_21.h UB_22.l\n",
    "    M is 9x3 :\n",
    "      UB, g\n",
    "    \"\"\"\n",
    "    #          x y z\n",
    "    M[:,:] = ((h,0,0),\n",
    "              (k,0,0),\n",
    "              (l,0,0),\n",
    "              (0,h,0),\n",
    "              (0,k,0),\n",
    "              (0,l,0),\n",
    "              (0,0,h),\n",
    "              (0,0,k),\n",
    "              (0,0,l) )\n",
    "    return M\n",
    "        \n",
    "ub = np.zeros((3,3), float) # Linear problem. hkl already assigned\n",
    "ub = np.linalg.inv( ubis[0]) # not for error estimation - need chi^2\n",
    "npk = 0\n",
    "g_to_fit = []\n",
    "h_to_fit = []\n",
    "XI2 = []\n",
    "fsum = f.sum()\n",
    "for ih in  range(h.min(), h.max()+1):\n",
    "    for ik in  range(k.min(), k.max()+1):\n",
    "        for il in  range(l.min(), l.max()+1):\n",
    "            for sign_eta in (-1,1):\n",
    "                # total intensity for this peak\n",
    "                signal = f[ih,ik,il,sign_eta]/fsum\n",
    "                if signal == 0:\n",
    "                    continue\n",
    "                npk += 1\n",
    "                # This matrix already carries an intensity weighting factor\n",
    "                A = gvar[:,:,ih,ik,il,sign_eta]   # 3x3\n",
    "                # A = np.eye(3)\n",
    "                gobs = gavg[:,ih,ik,il,sign_eta]  # 3\n",
    "                gcalc = np.dot( ub, (ih,ik,il) )  # 3\n",
    "                ge = gobs - gcalc\n",
    "                # Contribution to fit\n",
    "                scor = np.dot(ge, np.dot( A, ge ) ) \n",
    "                assert scor >= 0\n",
    "                cut = 2 * 10\n",
    "                weight = cut*cut/(cut*cut+scor*scor) # weight goes down as scor goes up\n",
    "                XI2.append( scor*weight )\n",
    "                # For later debugging\n",
    "                if 1:\n",
    "                    g_to_fit.append( gobs )\n",
    "                    h_to_fit.append( (ih,ik,il) )\n",
    "                M   = dg_dUB( M, ih, ik, il )\n",
    "                MA   = np.dot( M , A )\n",
    "                LSM += np.dot( MA,  M.T ) * weight\n",
    "                RHS += np.dot( MA, ge )   * weight\n",
    "                # import pdb;pdb.set_trace()\n",
    "#LSM *= npk/XI2\n",
    "#RHS *= npk/XI2\n",
    "iMAT = np.linalg.inv( LSM )\n",
    "ecorfac = np.sum( XI2 ) / (npk - len(RHS) )   # potentially a factor of 2 here in scipy?\n",
    "pCOV = iMAT * ecorfac\n",
    "shifts = np.dot( iMAT, RHS) + ub.ravel()\n",
    "print(npk)\n",
    "print(shifts)\n",
    "print(np.sqrt(np.diag(pCOV)))\n",
    "pl.figure()\n",
    "pl.hist( XI2, bins=128 )\n",
    "pl.ylabel(\"Number of peaks\")\n",
    "pl.xlabel(\"chi^2 contribution\")\n",
    "pl.figure()\n",
    "pl.imshow(pCOV)\n",
    "pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubfit = shifts.reshape(3,3)\n",
    "ubi_fit = np.linalg.inv( ubfit )\n",
    "print(ubi_fit)\n",
    "print(indexing.ubitocellpars(ubi_fit))\n",
    "afit = pow(np.linalg.det(ubi_fit),1/3)\n",
    "print(grain.grain( ubi_fit ).eps_grain( [afit,afit,afit,90,90,90] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_to_fit = np.array(g_to_fit, float)\n",
    "h_to_fit = np.array(h_to_fit, float)\n",
    "sum_h_outer_h = np.einsum( 'ki,kj->ij', h_to_fit, h_to_fit )\n",
    "sum_h_outer_g = np.einsum( 'ki,kj->ij', h_to_fit, g_to_fit )\n",
    "ubi_fit2 = np.dot( np.linalg.inv( sum_h_outer_g ), sum_h_outer_h ).T\n",
    "print(ubi_fit2)\n",
    "print(indexing.ubitocellpars(ubi_fit2))\n",
    "afit = pow(np.linalg.det( ubi_fit2 ),1/3)\n",
    "print(grain.grain( ubi_fit2 ).eps_grain( [afit,afit,afit,90,90,90] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.ubis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubi_fit3 = indexing.refine( ubi_fit, g_to_fit, 0.4 )\n",
    "print(ubi_fit3)\n",
    "print(indexing.ubitocellpars(ubi_fit3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
